{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0 Project Barley"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Along this project we will work on various Barley's cultivar starting from Hv_Morex. The aim of this project is to further understand the importance of introns within genes and within Untranslated Regions (UTRs) and their differences. \n",
    "\n",
    "Another not secondary objective is to build a pipeline as much reproducible as possible. This notebook is meant to give readers a crystal clear view of how we proceeded to implement our work. \n",
    "\n",
    "All the work has been performed on a Linux machine running _Ubuntu 20.04.2 LTS x86_64_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Working environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Before running the notebook** be sure to activate the conda environment shared with you:\n",
    "- $ conda activate Pedroni_Thesis.yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- This command can be installed with: $ sudo apt-get install neofetch\n",
    "### --- It is used to show the software/hardware characteristics of the machine used to complete this project.\n",
    "! neofetch | grep \"OS\\|Shell\\|DE\\|CPU\\|GPU\\|Memory\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### --- This command can be installed using \n",
    "### --- This command is used to show you how directories should be organized to better be able to follow this work.\n",
    "### --- The root directory of this project is called 'Project Barley'\n",
    "! tree -d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Implementing an intron analysis on data from a long-read sequence assembly in Barley"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The study I am referring to can be found [here](https://academic.oup.com/plcell/advance-article/doi/10.1093/plcell/koab077/6169005) while all the data can be found [here](https://doi.ipk-gatersleben.de/DOI/b2f47dfb-47ff-4114-89ae-bad8dcc515a1/21172880-2956-4cbb-ab2c-5c00bceb08a2/0). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Hv_Morex HC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1 Collecting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 863,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-09-04 12:39:51--  https://doi.ipk-gatersleben.de/DOI/b2f47dfb-47ff-4114-89ae-bad8dcc515a1/2492a5a9-08a8-4022-b6ad-9b056a00f64f/1/DOWNLOAD\n",
      "Resolving doi.ipk-gatersleben.de (doi.ipk-gatersleben.de)... 194.94.136.144\n",
      "Connecting to doi.ipk-gatersleben.de (doi.ipk-gatersleben.de)|194.94.136.144|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 59307477 (57M) [text/plain]\n",
      "Saving to: ‘Data/raw/Hv_Morex.pgsb.Jul2020.HC.gff3’\n",
      "\n",
      "w/Hv_Morex.pgsb.Jul  25%[====>               ]  14,46M   828KB/s    eta 48s    ^C\n"
     ]
    }
   ],
   "source": [
    "### --- This will download the raw data to the subdirectory raw under the directory Data\n",
    "! wget -O Data/raw/Hv_Morex.pgsb.Jul2020.HC.gff3 https://doi.ipk-gatersleben.de/DOI/b2f47dfb-47ff-4114-89ae-bad8dcc515a1/2492a5a9-08a8-4022-b6ad-9b056a00f64f/1/DOWNLOAD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2 Processing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 864,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Importing the libraries needed to handle data and visualize them\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 865,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Removing all hashtags from the gff3 file\n",
    "! sed '/#/d' Data/raw/Hv_Morex.pgsb.Jul2020.HC.gff3  > Data/Hv_Morex_nohashtag.pgsb.Jul2020.HC.gff3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 866,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Changing the gff3 file to a csv format file to import it with pandas\n",
    "! cat Data/Hv_Morex_nohashtag.pgsb.Jul2020.HC.gff3 | sed 's/,/--/g' | sed 's/;/--/g' | sed 's/\\t/,/g' | awk -F '--' '{print $1}' > Data/Hv_Morex_nohashtag.pgsb.Jul2020.HC.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 867,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chr</th>\n",
       "      <th>source</th>\n",
       "      <th>type</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>score</th>\n",
       "      <th>strand</th>\n",
       "      <th>phase</th>\n",
       "      <th>attributes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chr1H</td>\n",
       "      <td>pgsb</td>\n",
       "      <td>gene</td>\n",
       "      <td>76744</td>\n",
       "      <td>77373.0</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=HORVU.MOREX.r3.1HG0000030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chr1H</td>\n",
       "      <td>pgsb</td>\n",
       "      <td>mRNA</td>\n",
       "      <td>76744</td>\n",
       "      <td>77373.0</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=HORVU.MOREX.r3.1HG0000030.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chr1H</td>\n",
       "      <td>pgsb</td>\n",
       "      <td>exon</td>\n",
       "      <td>76744</td>\n",
       "      <td>77373.0</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=HORVU.MOREX.r3.1HG0000030.1.exon1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chr1H</td>\n",
       "      <td>pgsb</td>\n",
       "      <td>CDS</td>\n",
       "      <td>76744</td>\n",
       "      <td>77373.0</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>0</td>\n",
       "      <td>ID=HORVU.MOREX.r3.1HG0000030.1.CDS1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chr1H</td>\n",
       "      <td>pgsb</td>\n",
       "      <td>gene</td>\n",
       "      <td>78284</td>\n",
       "      <td>81892.0</td>\n",
       "      <td>.</td>\n",
       "      <td>-</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=HORVU.MOREX.r3.1HG0000040</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     chr source  type  start      end score strand phase  \\\n",
       "0  chr1H   pgsb  gene  76744  77373.0     .      +     .   \n",
       "1  chr1H   pgsb  mRNA  76744  77373.0     .      +     .   \n",
       "2  chr1H   pgsb  exon  76744  77373.0     .      +     .   \n",
       "3  chr1H   pgsb   CDS  76744  77373.0     .      +     0   \n",
       "4  chr1H   pgsb  gene  78284  81892.0     .      -     .   \n",
       "\n",
       "                             attributes  \n",
       "0          ID=HORVU.MOREX.r3.1HG0000030  \n",
       "1        ID=HORVU.MOREX.r3.1HG0000030.1  \n",
       "2  ID=HORVU.MOREX.r3.1HG0000030.1.exon1  \n",
       "3   ID=HORVU.MOREX.r3.1HG0000030.1.CDS1  \n",
       "4          ID=HORVU.MOREX.r3.1HG0000040  "
      ]
     },
     "execution_count": 867,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### --- Transforming the gff3 file to a pandas dataframe to better handle it\n",
    "df_Hv_MorexHC = pd.read_csv('Data/Hv_Morex_nohashtag.pgsb.Jul2020.HC.csv', header=None, names = ['chr', 'source', 'type','start','end','score','strand','phase','attributes'])\n",
    "df_Hv_MorexHC.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 868,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chr</th>\n",
       "      <th>source</th>\n",
       "      <th>type</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>score</th>\n",
       "      <th>strand</th>\n",
       "      <th>phase</th>\n",
       "      <th>attributes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chr1H</td>\n",
       "      <td>pgsb</td>\n",
       "      <td>exon</td>\n",
       "      <td>76744</td>\n",
       "      <td>77373.0</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=HORVU.MOREX.r3.1HG0000030.1.exon1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>chr1H</td>\n",
       "      <td>pgsb</td>\n",
       "      <td>exon</td>\n",
       "      <td>78284</td>\n",
       "      <td>78954.0</td>\n",
       "      <td>.</td>\n",
       "      <td>-</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=HORVU.MOREX.r3.1HG0000040.1.exon1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>chr1H</td>\n",
       "      <td>pgsb</td>\n",
       "      <td>exon</td>\n",
       "      <td>79063</td>\n",
       "      <td>79104.0</td>\n",
       "      <td>.</td>\n",
       "      <td>-</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=HORVU.MOREX.r3.1HG0000040.1.exon2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>chr1H</td>\n",
       "      <td>pgsb</td>\n",
       "      <td>exon</td>\n",
       "      <td>79609</td>\n",
       "      <td>79676.0</td>\n",
       "      <td>.</td>\n",
       "      <td>-</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=HORVU.MOREX.r3.1HG0000040.1.exon3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>chr1H</td>\n",
       "      <td>pgsb</td>\n",
       "      <td>exon</td>\n",
       "      <td>79757</td>\n",
       "      <td>79799.0</td>\n",
       "      <td>.</td>\n",
       "      <td>-</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=HORVU.MOREX.r3.1HG0000040.1.exon4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      chr source  type  start      end score strand phase  \\\n",
       "2   chr1H   pgsb  exon  76744  77373.0     .      +     .   \n",
       "7   chr1H   pgsb  exon  78284  78954.0     .      -     .   \n",
       "9   chr1H   pgsb  exon  79063  79104.0     .      -     .   \n",
       "11  chr1H   pgsb  exon  79609  79676.0     .      -     .   \n",
       "13  chr1H   pgsb  exon  79757  79799.0     .      -     .   \n",
       "\n",
       "                              attributes  \n",
       "2   ID=HORVU.MOREX.r3.1HG0000030.1.exon1  \n",
       "7   ID=HORVU.MOREX.r3.1HG0000040.1.exon1  \n",
       "9   ID=HORVU.MOREX.r3.1HG0000040.1.exon2  \n",
       "11  ID=HORVU.MOREX.r3.1HG0000040.1.exon3  \n",
       "13  ID=HORVU.MOREX.r3.1HG0000040.1.exon4  "
      ]
     },
     "execution_count": 868,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### --- Building a separate dataframe containing all exons\n",
    "exon_Hv_MorexHC = df_Hv_MorexHC.loc[df_Hv_MorexHC['type'].isin(['exon'])]\n",
    "exon_Hv_MorexHC.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 869,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Exporting the exon dataframe to a tsv file \n",
    "exon_Hv_MorexHC.to_csv('Data/Hv_MorexHC_exon.tsv',sep='\\t',index=False,header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 870,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chr</th>\n",
       "      <th>source</th>\n",
       "      <th>type</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>score</th>\n",
       "      <th>strand</th>\n",
       "      <th>phase</th>\n",
       "      <th>attributes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chr1H</td>\n",
       "      <td>pgsb</td>\n",
       "      <td>gene</td>\n",
       "      <td>76744</td>\n",
       "      <td>77373.0</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=HORVU.MOREX.r3.1HG0000030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chr1H</td>\n",
       "      <td>pgsb</td>\n",
       "      <td>mRNA</td>\n",
       "      <td>76744</td>\n",
       "      <td>77373.0</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=HORVU.MOREX.r3.1HG0000030.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chr1H</td>\n",
       "      <td>pgsb</td>\n",
       "      <td>exon</td>\n",
       "      <td>76744</td>\n",
       "      <td>77373.0</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=HORVU.MOREX.r3.1HG0000030.1.exon1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chr1H</td>\n",
       "      <td>pgsb</td>\n",
       "      <td>CDS</td>\n",
       "      <td>76744</td>\n",
       "      <td>77373.0</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>0</td>\n",
       "      <td>ID=HORVU.MOREX.r3.1HG0000030.1.CDS1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>chr1H</td>\n",
       "      <td>pgsb</td>\n",
       "      <td>gene</td>\n",
       "      <td>132221</td>\n",
       "      <td>138736.0</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=HORVU.MOREX.r3.1HG0000060</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      chr source  type   start       end score strand phase  \\\n",
       "0   chr1H   pgsb  gene   76744   77373.0     .      +     .   \n",
       "1   chr1H   pgsb  mRNA   76744   77373.0     .      +     .   \n",
       "2   chr1H   pgsb  exon   76744   77373.0     .      +     .   \n",
       "3   chr1H   pgsb   CDS   76744   77373.0     .      +     0   \n",
       "48  chr1H   pgsb  gene  132221  138736.0     .      +     .   \n",
       "\n",
       "                              attributes  \n",
       "0           ID=HORVU.MOREX.r3.1HG0000030  \n",
       "1         ID=HORVU.MOREX.r3.1HG0000030.1  \n",
       "2   ID=HORVU.MOREX.r3.1HG0000030.1.exon1  \n",
       "3    ID=HORVU.MOREX.r3.1HG0000030.1.CDS1  \n",
       "48          ID=HORVU.MOREX.r3.1HG0000060  "
      ]
     },
     "execution_count": 870,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### --- Keeping in a separated dataframe the forward strands\n",
    "forw_Hv_MorexHC = df_Hv_MorexHC.loc[df_Hv_MorexHC['strand'].isin(['+'])]\n",
    "forw_Hv_MorexHC.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 871,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chr</th>\n",
       "      <th>source</th>\n",
       "      <th>type</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>score</th>\n",
       "      <th>strand</th>\n",
       "      <th>phase</th>\n",
       "      <th>attributes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chr1H</td>\n",
       "      <td>pgsb</td>\n",
       "      <td>gene</td>\n",
       "      <td>78284</td>\n",
       "      <td>81892.0</td>\n",
       "      <td>.</td>\n",
       "      <td>-</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=HORVU.MOREX.r3.1HG0000040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>chr1H</td>\n",
       "      <td>pgsb</td>\n",
       "      <td>mRNA</td>\n",
       "      <td>78284</td>\n",
       "      <td>81892.0</td>\n",
       "      <td>.</td>\n",
       "      <td>-</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=HORVU.MOREX.r3.1HG0000040.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>chr1H</td>\n",
       "      <td>pgsb</td>\n",
       "      <td>three_prime_UTR</td>\n",
       "      <td>78284</td>\n",
       "      <td>78510.0</td>\n",
       "      <td>.</td>\n",
       "      <td>-</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=HORVU.MOREX.r3.1HG0000040.1.three_prime_UTR1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>chr1H</td>\n",
       "      <td>pgsb</td>\n",
       "      <td>exon</td>\n",
       "      <td>78284</td>\n",
       "      <td>78954.0</td>\n",
       "      <td>.</td>\n",
       "      <td>-</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=HORVU.MOREX.r3.1HG0000040.1.exon1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>chr1H</td>\n",
       "      <td>pgsb</td>\n",
       "      <td>CDS</td>\n",
       "      <td>78511</td>\n",
       "      <td>78954.0</td>\n",
       "      <td>.</td>\n",
       "      <td>-</td>\n",
       "      <td>0</td>\n",
       "      <td>ID=HORVU.MOREX.r3.1HG0000040.1.CDS1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     chr source             type  start      end score strand phase  \\\n",
       "4  chr1H   pgsb             gene  78284  81892.0     .      -     .   \n",
       "5  chr1H   pgsb             mRNA  78284  81892.0     .      -     .   \n",
       "6  chr1H   pgsb  three_prime_UTR  78284  78510.0     .      -     .   \n",
       "7  chr1H   pgsb             exon  78284  78954.0     .      -     .   \n",
       "8  chr1H   pgsb              CDS  78511  78954.0     .      -     0   \n",
       "\n",
       "                                        attributes  \n",
       "4                     ID=HORVU.MOREX.r3.1HG0000040  \n",
       "5                   ID=HORVU.MOREX.r3.1HG0000040.1  \n",
       "6  ID=HORVU.MOREX.r3.1HG0000040.1.three_prime_UTR1  \n",
       "7             ID=HORVU.MOREX.r3.1HG0000040.1.exon1  \n",
       "8              ID=HORVU.MOREX.r3.1HG0000040.1.CDS1  "
      ]
     },
     "execution_count": 871,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### --- Keeping in a separated dataframe the reverse strands\n",
    "rev_Hv_MorexHC = df_Hv_MorexHC.loc[df_Hv_MorexHC['strand'].isin(['-'])]\n",
    "rev_Hv_MorexHC.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 872,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chr</th>\n",
       "      <th>source</th>\n",
       "      <th>type</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>score</th>\n",
       "      <th>strand</th>\n",
       "      <th>phase</th>\n",
       "      <th>attributes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>chr1H</td>\n",
       "      <td>pgsb</td>\n",
       "      <td>five_prime_UTR</td>\n",
       "      <td>132221</td>\n",
       "      <td>132375.0</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=HORVU.MOREX.r3.1HG0000060.1.five_prime_UTR1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>chr1H</td>\n",
       "      <td>pgsb</td>\n",
       "      <td>three_prime_UTR</td>\n",
       "      <td>138505</td>\n",
       "      <td>138736.0</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=HORVU.MOREX.r3.1HG0000060.1.three_prime_UTR2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>chr1H</td>\n",
       "      <td>pgsb</td>\n",
       "      <td>five_prime_UTR</td>\n",
       "      <td>146607</td>\n",
       "      <td>146749.0</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=HORVU.MOREX.r3.1HG0000070.1.five_prime_UTR1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>chr1H</td>\n",
       "      <td>pgsb</td>\n",
       "      <td>five_prime_UTR</td>\n",
       "      <td>146981</td>\n",
       "      <td>146996.0</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=HORVU.MOREX.r3.1HG0000070.1.five_prime_UTR2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>chr1H</td>\n",
       "      <td>pgsb</td>\n",
       "      <td>three_prime_UTR</td>\n",
       "      <td>148229</td>\n",
       "      <td>148562.0</td>\n",
       "      <td>.</td>\n",
       "      <td>+</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=HORVU.MOREX.r3.1HG0000070.1.three_prime_UTR3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       chr source             type   start       end score strand phase  \\\n",
       "50   chr1H   pgsb   five_prime_UTR  132221  132375.0     .      +     .   \n",
       "93   chr1H   pgsb  three_prime_UTR  138505  138736.0     .      +     .   \n",
       "97   chr1H   pgsb   five_prime_UTR  146607  146749.0     .      +     .   \n",
       "98   chr1H   pgsb   five_prime_UTR  146981  146996.0     .      +     .   \n",
       "103  chr1H   pgsb  three_prime_UTR  148229  148562.0     .      +     .   \n",
       "\n",
       "                                          attributes  \n",
       "50    ID=HORVU.MOREX.r3.1HG0000060.1.five_prime_UTR1  \n",
       "93   ID=HORVU.MOREX.r3.1HG0000060.1.three_prime_UTR2  \n",
       "97    ID=HORVU.MOREX.r3.1HG0000070.1.five_prime_UTR1  \n",
       "98    ID=HORVU.MOREX.r3.1HG0000070.1.five_prime_UTR2  \n",
       "103  ID=HORVU.MOREX.r3.1HG0000070.1.three_prime_UTR3  "
      ]
     },
     "execution_count": 872,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### --- Keeping in a separated dataframe the UTR regions on the forward strands\n",
    "UTR_forw_Hv_MorexHC = forw_Hv_MorexHC.loc[df_Hv_MorexHC['type'].isin(['three_prime_UTR','five_prime_UTR'])]\n",
    "UTR_forw_Hv_MorexHC.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 873,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Writing to a tsv formatted file the UTR_df_forw dataframe\n",
    "UTR_forw_Hv_MorexHC.to_csv('Data/Hv_MorexHC_UTRforw.tsv',sep='\\t',index=False,header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 874,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chr</th>\n",
       "      <th>source</th>\n",
       "      <th>type</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>score</th>\n",
       "      <th>strand</th>\n",
       "      <th>phase</th>\n",
       "      <th>attributes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>chr1H</td>\n",
       "      <td>pgsb</td>\n",
       "      <td>three_prime_UTR</td>\n",
       "      <td>78284</td>\n",
       "      <td>78510.0</td>\n",
       "      <td>.</td>\n",
       "      <td>-</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=HORVU.MOREX.r3.1HG0000040.1.three_prime_UTR1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>chr1H</td>\n",
       "      <td>pgsb</td>\n",
       "      <td>five_prime_UTR</td>\n",
       "      <td>81706</td>\n",
       "      <td>81892.0</td>\n",
       "      <td>.</td>\n",
       "      <td>-</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=HORVU.MOREX.r3.1HG0000040.1.five_prime_UTR2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>chr1H</td>\n",
       "      <td>pgsb</td>\n",
       "      <td>three_prime_UTR</td>\n",
       "      <td>84091</td>\n",
       "      <td>84317.0</td>\n",
       "      <td>.</td>\n",
       "      <td>-</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=HORVU.MOREX.r3.1HG0000050.1.three_prime_UTR1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>chr1H</td>\n",
       "      <td>pgsb</td>\n",
       "      <td>five_prime_UTR</td>\n",
       "      <td>86846</td>\n",
       "      <td>87063.0</td>\n",
       "      <td>.</td>\n",
       "      <td>-</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=HORVU.MOREX.r3.1HG0000050.1.five_prime_UTR2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>chr1H</td>\n",
       "      <td>pgsb</td>\n",
       "      <td>three_prime_UTR</td>\n",
       "      <td>156767</td>\n",
       "      <td>157203.0</td>\n",
       "      <td>.</td>\n",
       "      <td>-</td>\n",
       "      <td>.</td>\n",
       "      <td>ID=HORVU.MOREX.r3.1HG0000090.1.three_prime_UTR1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       chr source             type   start       end score strand phase  \\\n",
       "6    chr1H   pgsb  three_prime_UTR   78284   78510.0     .      -     .   \n",
       "27   chr1H   pgsb   five_prime_UTR   81706   81892.0     .      -     .   \n",
       "30   chr1H   pgsb  three_prime_UTR   84091   84317.0     .      -     .   \n",
       "47   chr1H   pgsb   five_prime_UTR   86846   87063.0     .      -     .   \n",
       "126  chr1H   pgsb  three_prime_UTR  156767  157203.0     .      -     .   \n",
       "\n",
       "                                          attributes  \n",
       "6    ID=HORVU.MOREX.r3.1HG0000040.1.three_prime_UTR1  \n",
       "27    ID=HORVU.MOREX.r3.1HG0000040.1.five_prime_UTR2  \n",
       "30   ID=HORVU.MOREX.r3.1HG0000050.1.three_prime_UTR1  \n",
       "47    ID=HORVU.MOREX.r3.1HG0000050.1.five_prime_UTR2  \n",
       "126  ID=HORVU.MOREX.r3.1HG0000090.1.three_prime_UTR1  "
      ]
     },
     "execution_count": 874,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### --- Keeping in a separated dataframe the UTR regions on the reverse strands\n",
    "UTR_rev_Hv_MorexHC = rev_Hv_MorexHC.loc[df_Hv_MorexHC['type'].isin(['three_prime_UTR','five_prime_UTR'])]\n",
    "UTR_rev_Hv_MorexHC.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 875,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Writing to a tsv formatted file the UTR_df_rev dataframe\n",
    "UTR_rev_Hv_MorexHC.to_csv('Data/Hv_MorexHC_UTRrev.tsv',sep='\\t',index=False,header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.3 Extracting introns from the whole genome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 876,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Function to extract introns from the whole genome\n",
    "### --- Infile is a file like Hv_MorexHC_exon.tsv \n",
    "### --- Outfile will be written thanks to this function\n",
    "### --- If there are two or more exons belonging to the same mRNA one after the other it compute the introns separating them\n",
    "def extract_tot_introns(infile, outfile):\n",
    "    introns = open(outfile, 'a') # Output/Hv_Morex_introns.tsv\n",
    "    introns.write('ID'+'\\t'+'type'+'\\t'+'start'+'\\t'+'end'+'\\t'+'length') \n",
    "    with open(infile) as f: # Data/Hv_Morex_exon.tsv\n",
    "        lines = f.readlines()\n",
    "        for i in range(0, len(lines)):\n",
    "            if i+1 == len(lines): # This is to avoid out of range error\n",
    "                break \n",
    "            else:\n",
    "                line = lines[i]\n",
    "                line = line.rstrip()\n",
    "                line = line.split()\n",
    "                next_line = lines[i+1]\n",
    "                next_line = lines[i+1].rstrip()\n",
    "                next_line = lines[i+1].split()\n",
    "                if '.'.join(line[8].split('.')[0:5]) != '.'.join(next_line[8].split('.')[0:5]): continue # Checking if the next exon has the same ID of the one we are at\n",
    "                #print('The intron coordinates at %s are from %d to %d and the intron length is %d.' % (line[8][:30], int(line[4])+1, int(next_line[3])-1, int(next_line[3])-1 - int(line[4])+1))\n",
    "                introns.write('\\n'+'.'.join(line[8].split('.')[0:5])+'\\t'+ 'intron ' +'\\t'+str(int(line[4])+1)+'\\t'+str(int(next_line[3])-1)+'\\t'+str(int(next_line[3])-1-int(line[4])+1))\n",
    "    introns.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 877,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: '78954.0'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-877-3918e334f1ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m### --- Extracting introns from Hv_MorexHC\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mextract_tot_introns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Data/Hv_MorexHC_exon.tsv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Output/Hv_MorexHC_introns.tsv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-876-06304b742e2c>\u001b[0m in \u001b[0;36mextract_tot_introns\u001b[0;34m(infile, outfile)\u001b[0m\n\u001b[1;32m     20\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m'.'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'.'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_line\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mcontinue\u001b[0m \u001b[0;31m# Checking if the next exon has the same ID of the one we are at\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m                 \u001b[0;31m#print('The intron coordinates at %s are from %d to %d and the intron length is %d.' % (line[8][:30], int(line[4])+1, int(next_line[3])-1, int(next_line[3])-1 - int(line[4])+1))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m                 \u001b[0mintrons\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0;34m'intron '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_line\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_line\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mintrons\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: '78954.0'"
     ]
    }
   ],
   "source": [
    "### --- Extracting introns from Hv_MorexHC\n",
    "extract_tot_introns('Data/Hv_MorexHC_exon.tsv', 'Output/Hv_MorexHC_introns.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "introns_Hv_MorexHC = pd.read_csv('Output/Hv_MorexHC_introns.tsv', sep = '\\t')\n",
    "introns_Hv_MorexHC[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Function to count introns within a dataframe made of exons formatted like exon_Hv_MorexHC\n",
    "### --- If I use i[:28] I consider the gene, If I use i[:31] I'm at level of mRNA\n",
    "### --- Actually using 31 I would avoid the problem of certain genes having >= 10 transcripts\n",
    "def counting_introns_type(in_dataframe):\n",
    "    counts = dict()\n",
    "    for i in in_dataframe['attributes']:\n",
    "        counts['.'.join(i.split('.')[0:5])] = counts.get('.'.join(i.split('.')[0:5]), 0) + 1\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Counting introns type in Hv_MorexHC\n",
    "introns_dictionary_Hv_MorexHC = counting_introns_type(exon_Hv_MorexHC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### --- Function to check intronless (no introns), intronpoor (<= 3 introns) and intron rich (> 3 introns)\n",
    "### --- This division is made on the following assumption: n° introns = n° exons - 1\n",
    "def splitting_introns_type(dictionary):\n",
    "    intronless = 0\n",
    "    intronpoor = 0\n",
    "    intronrich = 0\n",
    "    intronless_list = []\n",
    "    intronpoor_list = []\n",
    "    intronrich_list = []\n",
    "    for i in dictionary:\n",
    "        if dictionary[i] == 1:\n",
    "            intronless += 1\n",
    "            intronless_list.append(i)\n",
    "        elif dictionary[i]>1 and dictionary[i]<= 4:\n",
    "            intronpoor += 1\n",
    "            intronpoor_list.append(i)\n",
    "        elif dictionary[i] > 4:\n",
    "            intronrich += 1\n",
    "            intronrich_list.append(i)\n",
    "\n",
    "    print('Intronless are: %d' % intronless)\n",
    "    print('Intronpoor are: %d' % intronpoor)\n",
    "    print('Intronrich are: %d' % intronrich)\n",
    "    \n",
    "    return (intronless, intronpoor, intronrich, intronless_list, intronpoor_list, intronrich_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n_intronless_Hv_MorexHC, n_intronpoor_Hv_MorexHC, n_intronrich_Hv_MorexHC, intronless_Hv_MorexHC, intronpoor_Hv_MorexHC, intronrich_Hv_MorexHC = splitting_introns_type(introns_dictionary_Hv_MorexHC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genes = ['Intronless', 'Intronpoor', 'Intronrich']\n",
    "data = [11537, 12997, 11293]\n",
    "fig = plt.figure(figsize =(10, 7))\n",
    "plt.pie(data, labels = genes, autopct='%1.0f%%')\n",
    "plt.title(\"Genes Hv_MorexHC Distribution\", bbox={'facecolor':'0.8', 'pad':5})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Creating the list of Hv_MorexHC gene IDs to check the number of transcripts using command line\n",
    "intronless_file = open('Output/Hv_MorexHC_intronlessIDs.txt', 'a')\n",
    "intronpoor_file = open('Output/Hv_MorexHC_intronpoorIDs.txt', 'a')\n",
    "intronrich_file = open('Output/Hv_MorexHC_intronrichIDs.txt', 'a')\n",
    "for i in range(len(intronless_Hv_MorexHC)):\n",
    "    if i == len(intronless_Hv_MorexHC) -1:\n",
    "        intronless_file.write(intronless_Hv_MorexHC[i])\n",
    "    else:\n",
    "        intronless_file.write(intronless_Hv_MorexHC[i] + '\\n')\n",
    "intronless_file.close()\n",
    "\n",
    "for i in range(len(intronpoor_Hv_MorexHC)):\n",
    "    if i == len(intronpoor_Hv_MorexHC) -1:\n",
    "        intronpoor_file.write(intronpoor_Hv_MorexHC[i])\n",
    "    else:\n",
    "        intronpoor_file.write(intronpoor_Hv_MorexHC[i] + '\\n')\n",
    "intronpoor_file.close()\n",
    "\n",
    "for i in range(len(intronrich_Hv_MorexHC)):\n",
    "    if i == len(intronrich_Hv_MorexHC) -1:\n",
    "        intronrich_file.write(intronrich_Hv_MorexHC[i])\n",
    "    else:\n",
    "        intronrich_file.write(intronrich_Hv_MorexHC[i]+'\\n')\n",
    "intronrich_file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Storing the number of transcripts in intron-less/poor/rich genes within a variable \n",
    "n_mRNA_intronless_Hv_MorexHC = ! grep -f Output/Hv_MorexHC_intronlessIDs.txt Data/Hv_Morex_nohashtag.pgsb.Jul2020.HC.gff3 | awk -F '\\t' '{print $3}' | grep -w 'mRNA' | wc -l\n",
    "n_mRNA_intronpoor_Hv_MorexHC = ! grep -f Output/Hv_MorexHC_intronpoorIDs.txt Data/Hv_Morex_nohashtag.pgsb.Jul2020.HC.gff3 | awk -F '\\t' '{print $3}' | grep -w 'mRNA' | wc -l\n",
    "n_mRNA_intronrich_Hv_MorexHC = ! grep -f Output/Hv_MorexHC_intronrichIDs.txt Data/Hv_Morex_nohashtag.pgsb.Jul2020.HC.gff3 | awk -F '\\t' '{print $3}' | grep -w 'mRNA' | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Checking the average number of transcripts for each gene-type\n",
    "avg_mRNA_intronless_Hv_MorexHC = int(n_mRNA_intronless_Hv_MorexHC[0])/n_intronless_Hv_MorexHC\n",
    "print(avg_mRNA_intronless_Hv_MorexHC)\n",
    "avg_mRNA_intronpoor_Hv_MorexHC = int(n_mRNA_intronpoor_Hv_MorexHC[0])/n_intronpoor_Hv_MorexHC\n",
    "print(avg_mRNA_intronpoor_Hv_MorexHC)\n",
    "avg_mRNA_intronrich_Hv_MorexHC = int(n_mRNA_intronrich_Hv_MorexHC[0])/n_intronrich_Hv_MorexHC\n",
    "print(avg_mRNA_intronrich_Hv_MorexHC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.4 Extracting introns from UTR regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Function to extract introns from UTR regions.\n",
    "### --- Infile is a file like Hv_Morex_UTRforw_introns.tsv \n",
    "### --- Outfile will be written thanks to this function\n",
    "### --- Being all on the same strand when two or more UTRs of the same type are one row after the other it means there is a intron separating them\n",
    "def extract_UTR_introns(infile, outfile):\n",
    "    UTR_introns_forw = open(outfile, 'a')\n",
    "    UTR_introns_forw.write('ID'+'\\t'+'type'+'\\t'+'start'+'\\t'+'end'+'\\t'+'length') # Defining the header\n",
    "    with open(infile) as f:\n",
    "        lines = f.readlines()\n",
    "        for i in range(0, len(lines)):\n",
    "            if i+1 == len(lines):\n",
    "                break\n",
    "            else:\n",
    "                line = lines[i]\n",
    "                line = line.rstrip()\n",
    "                line = line.split()\n",
    "                next_line = lines[i+1]\n",
    "                next_line = lines[i+1].rstrip()\n",
    "                next_line = lines[i+1].split()\n",
    "                if line[2] != next_line[2] or '.'.join(line[8].split('.')[0:5]) != '.'.join(next_line[8].split('.')[0:5]): continue\n",
    "                #print('The intron coordinates at %s are from %d to %d and the intron length is %d.' % ('.'.join(line[8].split('.')[0:5]), int(line[4])+1, int(next_line[3])-1, int(next_line[3])-1 - int(line[4])+1))\n",
    "                UTR_introns_forw.write('\\n'+'.'.join(line[8].split('.')[0:5])+'\\t'+ 'intron '+line[2]+'\\t'+str(int(line[4])+1)+'\\t'+str(int(next_line[3])-1)+'\\t'+str(int(next_line[3])-1-int(line[4])+1))\n",
    "    UTR_introns_forw.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Extracting introns from UTR forward Hv_MorexHC\n",
    "extract_UTR_introns('Data/Hv_MorexHC_UTRforw.tsv', 'Output/Hv_MorexHC_UTRforw_introns.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Extracting introns from UTR reverse Hv_MorexHC\n",
    "extract_UTR_introns('Data/Hv_MorexHC_UTRrev.tsv', 'Output/Hv_MorexHC_UTRrev_introns.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "introns_UTR_forw_Hv_MorexHC = pd.read_csv('Output/Hv_MorexHC_UTRforw_introns.tsv', sep='\\t')\n",
    "introns_UTR_forw_Hv_MorexHC.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "introns_UTR_rev_Hv_MorexHC = pd.read_csv('Output/Hv_MorexHC_UTRrev_introns.tsv', sep = '\\t')\n",
    "introns_UTR_rev_Hv_MorexHC.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Concatenating the UTR_introns to build a unique dataframe\n",
    "frames = [introns_UTR_forw_Hv_MorexHC, introns_UTR_rev_Hv_MorexHC]\n",
    "introns_UTR_Hv_MorexHC = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Setting figure and font size\n",
    "plt.rcParams[\"figure.figsize\"] = (20, 20)\n",
    "plt.rcParams[\"font.size\"] = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Performing some basic statistics \n",
    "introns_UTR_Hv_MorexHC['length'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Plotting the distribution of UTR introns length\n",
    "introns_UTR_Hv_MorexHC['length'].plot.density()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Plotting the boxplot of UTR introns length without outliers\n",
    "introns_UTR_Hv_MorexHC.boxplot(column='length', return_type='axes', showfliers=False) # showfliers = False -> discard outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- splitting in introns 3'UTR and 5'UTR to eventually if there are differences among the two\n",
    "introns_UTR3_Hv_MorexHC = introns_UTR_Hv_MorexHC.loc[introns_UTR_Hv_MorexHC['type'].isin(['intron three_prime_UTR'])]\n",
    "introns_UTR5_Hv_MorexHC = introns_UTR_Hv_MorexHC.loc[introns_UTR_Hv_MorexHC['type'].isin(['intron five_prime_UTR'])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "introns_UTR3_Hv_MorexHC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "introns_UTR3_Hv_MorexHC['length'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "introns_UTR5_Hv_MorexHC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "introns_UTR5_Hv_MorexHC['length'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Plotting the distribution of introns_UTR vs total UTRs\n",
    "labels_Hv_MorexHC = ['UTRs', 'Introns_5UTR', 'Introns_3UTR']\n",
    "UTR_data_Hv_MorexHC = [ 20666+19938-(3417+1632), 3417, 1632]\n",
    "fig = plt.figure(figsize =(10, 7))\n",
    "plt.pie(UTR_data_Hv_MorexHC, labels = labels_Hv_MorexHC, autopct='%1.0f%%')\n",
    "plt.title(\"UTRs Hv_MorexHC Distribution\", bbox={'facecolor':'0.8', 'pad':5})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.5 Removing UTR introns from the whole introns dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Checking total introns dataframe \n",
    "introns_Hv_MorexHC.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Checking UTR introns dataframe\n",
    "introns_UTR_Hv_MorexHC.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Function to create remove from the total introns the one within UTRs and create a dataframe with introns within cds\n",
    "### --- The indataframe must be formatted like introns_Hv_MorexHC\n",
    "### --- The assumption is to use pd.concat() to concatenate the two dataframes and then drop the duplicates\n",
    "def cds_introns_dataframe(indataframe1, indataframe2):\n",
    "    total_introns_df = pd.concat([indataframe1,indataframe2])\n",
    "    #print(len(total_introns_df))\n",
    "    #print(len(introns_UTR))\n",
    "    #print(len(introns_df))\n",
    "    #print(len(total_introns_df.drop_duplicates(['ID','start','end'],keep=False))) \n",
    "    introns_cds_df = total_introns_df.drop_duplicates(['ID','start','end'],keep=False)\n",
    "    return introns_cds_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Extracting introns from cds within Hv_MorexHC\n",
    "introns_cds_Hv_MorexHC = cds_introns_dataframe(introns_Hv_MorexHC, introns_UTR_Hv_MorexHC)\n",
    "introns_cds_Hv_MorexHC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Checking if there are not introns UTR within the created dataframe\n",
    "introns_cds_Hv_MorexHC.loc[introns_cds_Hv_MorexHC['type'].isin(['intron three_prime_UTR','intron five_prime_UTR'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Basic statistics of Hv_MorexHC introns cds\n",
    "introns_cds_Hv_MorexHC['length'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Plotting the distribution of Hv_MorexHC cds introns length\n",
    "introns_cds_Hv_MorexHC['length'].plot.density()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Plotting the boxplot of Hv_MorexHC cds introns length without outliers\n",
    "introns_cds_Hv_MorexHC.boxplot(column='length', return_type='axes', showfliers=False) # showfliers = False -> discard outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.6 Re-organizing files and directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "! ls Data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir Data/Hv_Morex_longread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mv Data/Hv_MorexHC* Data/Hv_Morex_longread/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls Data/Hv_Morex_longread/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls Output/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir Output/Hv_Morex_longread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mv Output/Hv_MorexHC* Output/Hv_Morex_longread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls Output/Hv_Morex_longread/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2 Reproducing on Hv_Morex LC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1 Collecting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- This will download the raw data to the subdirectory raw under the directory Data\n",
    "! wget -O Data/raw/Hv_Morex.pgsb.Jul2020.LC.gff3 https://doi.ipk-gatersleben.de/DOI/b2f47dfb-47ff-4114-89ae-bad8dcc515a1/e27077bd-fa0b-4c20-ba87-5c84b9d0641c/1/DOWNLOAD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2 Processing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- There is no need to import the libraries again\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Removing all hashtags from the gff3 file\n",
    "! sed '/#/d' Data/raw/Hv_Morex.pgsb.Jul2020.LC.gff3  > Data/Hv_Morex_nohashtag.pgsb.Jul2020.LC.gff3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Changing the gff3 file to a csv format file to import it with pandas\n",
    "! cat Data/Hv_Morex_nohashtag.pgsb.Jul2020.LC.gff3 | sed 's/,/--/g' | sed 's/;/--/g' | sed 's/\\t/,/g' | awk -F '--' '{print $1}' > Data/Hv_Morex_nohashtag.pgsb.Jul2020.LC.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### --- Transforming the gff3 file to a pandas dataframe to better handle it\n",
    "df_Hv_MorexLC = pd.read_csv('Data/Hv_Morex_nohashtag.pgsb.Jul2020.LC.csv', header=None, names = ['chr', 'source', 'type','start','end','score','strand','phase','attributes'])\n",
    "df_Hv_MorexLC.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Building a separate dataframe containing all exons\n",
    "exon_Hv_MorexLC = df_Hv_MorexLC.loc[df_Hv_MorexLC['type'].isin(['exon'])]\n",
    "exon_Hv_MorexLC.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Exporting the exon dataframe to a tsv file \n",
    "exon_Hv_MorexLC.to_csv('Data/Hv_MorexLC_exon.tsv',sep='\\t',index=False,header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### --- Keeping in a separated dataframe the forward strands\n",
    "forw_Hv_MorexLC = df_Hv_MorexLC.loc[df_Hv_MorexLC['strand'].isin(['+'])]\n",
    "forw_Hv_MorexLC.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### --- Keeping in a separated dataframe the reverse strands\n",
    "rev_Hv_MorexLC = df_Hv_MorexLC.loc[df_Hv_MorexLC['strand'].isin(['-'])]\n",
    "rev_Hv_MorexLC.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Keeping in a separated dataframe the UTR regions on the forward strands\n",
    "UTR_forw_Hv_MorexLC = forw_Hv_MorexLC.loc[df_Hv_MorexLC['type'].isin(['three_prime_UTR','five_prime_UTR'])]\n",
    "UTR_forw_Hv_MorexLC.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Writing to a tsv formatted file the UTR_df_forw dataframe\n",
    "UTR_forw_Hv_MorexLC.to_csv('Data/Hv_MorexLC_UTRforw.tsv',sep='\\t',index=False,header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### --- Keeping in a separated dataframe the UTR regions on the reverse strands\n",
    "UTR_rev_Hv_MorexLC = rev_Hv_MorexLC.loc[df_Hv_MorexLC['type'].isin(['three_prime_UTR','five_prime_UTR'])]\n",
    "UTR_rev_Hv_MorexLC.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Writing to a tsv formatted file the UTR_df_rev dataframe\n",
    "UTR_rev_Hv_MorexLC.to_csv('Data/Hv_MorexLC_UTRrev.tsv',sep='\\t',index=False,header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.3 Extracting introns from the whole genome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Extracting introns from Hv_MorexLC\n",
    "extract_tot_introns('Data/Hv_MorexLC_exon.tsv', 'Output/Hv_MorexLC_introns.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "introns_Hv_MorexLC = pd.read_csv('Output/Hv_MorexLC_introns.tsv', sep = '\\t')\n",
    "introns_Hv_MorexLC[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Counting introns type in Hv_MorexHC\n",
    "introns_dictionary_Hv_MorexLC = counting_introns_type(exon_Hv_MorexLC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_intronless_Hv_MorexLC, n_intronpoor_Hv_MorexLC, n_intronrich_Hv_MorexLC, intronless_Hv_MorexLC, intronpoor_Hv_MorexLC, intronrich_Hv_MorexLC = splitting_introns_type(introns_dictionary_Hv_MorexLC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_Hv_MorexLC = [34638, 9345, 1877]\n",
    "fig = plt.figure(figsize =(10, 7))\n",
    "plt.pie(data_Hv_MorexLC, labels = genes, autopct='%1.0f%%')\n",
    "plt.title(\"Genes Hv_MorexLC Distribution\", bbox={'facecolor':'0.8', 'pad':5})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Creating the list of Hv_MorexLC gene IDs to check the number of transcripts using command line\n",
    "intronless_file_Hv_Morex_LC = open('Output/Hv_MorexLC_intronlessIDs.txt', 'a')\n",
    "intronpoor_file_Hv_Morex_LC = open('Output/Hv_MorexLC_intronpoorIDs.txt', 'a')\n",
    "intronrich_file_Hv_Morex_LC = open('Output/Hv_MorexLC_intronrichIDs.txt', 'a')\n",
    "for i in range(len(intronless_Hv_MorexLC)):\n",
    "    if i == len(intronless_Hv_MorexLC) -1:\n",
    "        intronless_file_Hv_Morex_LC.write(intronless_Hv_MorexLC[i])\n",
    "    else:\n",
    "        intronless_file_Hv_Morex_LC.write(intronless_Hv_MorexLC[i] + '\\n')\n",
    "intronless_file_Hv_Morex_LC.close()\n",
    "\n",
    "for i in range(len(intronpoor_Hv_MorexLC)):\n",
    "    if i == len(intronpoor_Hv_MorexLC) -1:\n",
    "        intronpoor_file_Hv_Morex_LC.write(intronpoor_Hv_MorexLC[i])\n",
    "    else:\n",
    "        intronpoor_file_Hv_Morex_LC.write(intronpoor_Hv_MorexLC[i] + '\\n')\n",
    "intronpoor_file_Hv_Morex_LC.close()\n",
    "\n",
    "for i in range(len(intronrich_Hv_MorexLC)):\n",
    "    if i == len(intronrich_Hv_MorexLC) -1:\n",
    "        intronrich_file_Hv_Morex_LC.write(intronrich_Hv_MorexLC[i])\n",
    "    else:\n",
    "        intronrich_file_Hv_Morex_LC.write(intronrich_Hv_MorexLC[i]+'\\n')\n",
    "intronrich_file_Hv_Morex_LC.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Storing the number of transcripts in intron-less/poor/rich genes within a variable \n",
    "n_mRNA_intronless_Hv_MorexLC = ! grep -f Output/Hv_MorexLC_intronlessIDs.txt Data/Hv_Morex_nohashtag.pgsb.Jul2020.LC.gff3 | awk -F '\\t' '{print $3}' | grep -w 'mRNA' | wc -l\n",
    "n_mRNA_intronpoor_Hv_MorexLC = ! grep -f Output/Hv_MorexLC_intronpoorIDs.txt Data/Hv_Morex_nohashtag.pgsb.Jul2020.LC.gff3 | awk -F '\\t' '{print $3}' | grep -w 'mRNA' | wc -l\n",
    "n_mRNA_intronrich_Hv_MorexLC = ! grep -f Output/Hv_MorexLC_intronrichIDs.txt Data/Hv_Morex_nohashtag.pgsb.Jul2020.LC.gff3 | awk -F '\\t' '{print $3}' | grep -w 'mRNA' | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Checking the average number of transcripts for each gene-type\n",
    "avg_mRNA_intronless_Hv_MorexLC = int(n_mRNA_intronless_Hv_MorexLC[0])/n_intronless_Hv_MorexLC\n",
    "print(avg_mRNA_intronless_Hv_MorexLC)\n",
    "avg_mRNA_intronpoor_Hv_MorexLC = int(n_mRNA_intronpoor_Hv_MorexLC[0])/n_intronpoor_Hv_MorexLC\n",
    "print(avg_mRNA_intronpoor_Hv_MorexLC)\n",
    "avg_mRNA_intronrich_Hv_MorexLC = int(n_mRNA_intronrich_Hv_MorexLC[0])/n_intronrich_Hv_MorexLC\n",
    "print(avg_mRNA_intronrich_Hv_MorexLC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.4 Extracting introns from UTR regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Extracting introns from UTR forward Hv_MorexLC\n",
    "extract_UTR_introns('Data/Hv_MorexLC_UTRforw.tsv', 'Output/Hv_MorexLC_UTRforw_introns.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Extracting introns from UTR reverse Hv_MorexLC\n",
    "extract_UTR_introns('Data/Hv_MorexLC_UTRrev.tsv', 'Output/Hv_MorexLC_UTRrev_introns.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "introns_UTR_forw_Hv_MorexLC = pd.read_csv('Output/Hv_MorexLC_UTRforw_introns.tsv', sep='\\t')\n",
    "introns_UTR_forw_Hv_MorexLC.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "introns_UTR_rev_Hv_MorexLC = pd.read_csv('Output/Hv_MorexLC_UTRrev_introns.tsv', sep = '\\t')\n",
    "introns_UTR_rev_Hv_MorexLC.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Concatenating the UTR_introns to build a unique dataframe\n",
    "frames_Hv_MorexLC = [introns_UTR_forw_Hv_MorexLC, introns_UTR_rev_Hv_MorexLC]\n",
    "introns_UTR_Hv_MorexLC = pd.concat(frames_Hv_MorexLC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Performing some basic statistics \n",
    "introns_UTR_Hv_MorexLC['length'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Plotting the distribution of UTR introns length\n",
    "introns_UTR_Hv_MorexLC['length'].plot.density()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### --- Plotting the boxplot of UTR introns length without outliers\n",
    "introns_UTR_Hv_MorexLC.boxplot(column='length', return_type='axes', showfliers=False) # showfliers = False -> discard outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- splitting in introns 3'UTR and 5'UTR to eventually if there are differences among the two\n",
    "introns_UTR3_Hv_MorexLC = introns_UTR_Hv_MorexLC.loc[introns_UTR_Hv_MorexLC['type'].isin(['intron three_prime_UTR'])]\n",
    "introns_UTR5_Hv_MorexLC = introns_UTR_Hv_MorexLC.loc[introns_UTR_Hv_MorexLC['type'].isin(['intron five_prime_UTR'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "introns_UTR3_Hv_MorexLC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "introns_UTR3_Hv_MorexLC['length'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "introns_UTR5_Hv_MorexLC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "introns_UTR5_Hv_MorexLC['length'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Plotting the distribution of introns_UTR vs total UTRs\n",
    "labels_Hv_MorexLC = ['UTRs', 'Introns_5UTR', 'Introns_3UTR']\n",
    "UTR_data_Hv_MorexLC = [ 1800+1964-(282+380), 282, 380]\n",
    "fig = plt.figure(figsize =(10, 7))\n",
    "plt.pie(UTR_data_Hv_MorexLC, labels = labels_Hv_MorexLC, autopct='%1.0f%%')\n",
    "plt.title(\"UTRs Hv_MorexLC Distribution\", bbox={'facecolor':'0.8', 'pad':5})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.5 Removing UTR introns from the whole introns dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Checking total introns dataframe \n",
    "introns_Hv_MorexLC.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Checking UTR introns dataframe\n",
    "introns_UTR_Hv_MorexLC.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Extracting introns from cds within Hv_MorexHC\n",
    "introns_cds_Hv_MorexLC = cds_introns_dataframe(introns_Hv_MorexLC, introns_UTR_Hv_MorexLC)\n",
    "introns_cds_Hv_MorexLC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Checking if there are not introns UTR within the created dataframe\n",
    "introns_cds_Hv_MorexLC.loc[introns_cds_Hv_MorexLC['type'].isin(['intron three_prime_UTR','intron five_prime_UTR'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Basic statistics of Hv_MorexLC introns cds\n",
    "introns_cds_Hv_MorexLC['length'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### --- Plotting the distribution of Hv_MorexLC cds introns length\n",
    "introns_cds_Hv_MorexLC['length'].plot.density()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### --- Plotting the boxplot of Hv_MorexLC cds introns length without outliers\n",
    "introns_cds_Hv_MorexLC.boxplot(column='length', return_type='axes', showfliers=False) # showfliers = False -> discard outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.6 Re-organizing files and directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls Data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mv Data/Hv_MorexLC* Data/Hv_Morex_longread/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls Data/Hv_Morex_longread/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls Output/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mv Output/Hv_MorexLC* Output/Hv_Morex_longread/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls Output/Hv_Morex_longread/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.3 Reproducing on Hv_Morex total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.1 Collecting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- This will download the raw data to the subdirectory raw under the directory Data\n",
    "! wget -O Data/raw/Hv_Morex.pgsb.Jul2020.gff3 https://doi.ipk-gatersleben.de/DOI/b2f47dfb-47ff-4114-89ae-bad8dcc515a1/5d16cc17-c37f-417f-855d-c5e72c721f6c/1/DOWNLOAD "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.2 Processing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- There is no need to import the libraries again\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Removing all hashtags from the gff3 file\n",
    "! sed '/#/d' Data/raw/Hv_Morex.pgsb.Jul2020.gff3  > Data/Hv_Morex_nohashtag.pgsb.Jul2020.gff3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Changing the gff3 file to a csv format file to import it with pandas\n",
    "! cat Data/Hv_Morex_nohashtag.pgsb.Jul2020.gff3 | sed 's/,/--/g' | sed 's/;/--/g' | sed 's/\\t/,/g' | awk -F '--' '{print $1}' > Data/Hv_Morex_nohashtag.pgsb.Jul2020.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Transforming the gff3 file to a pandas dataframe to better handle it\n",
    "df_Hv_Morex = pd.read_csv('Data/Hv_Morex_nohashtag.pgsb.Jul2020.csv', header=None, names = ['chr', 'source', 'type','start','end','score','strand','phase','attributes'])\n",
    "df_Hv_Morex.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### --- Building a separate dataframe containing all exons\n",
    "exon_Hv_Morex = df_Hv_Morex.loc[df_Hv_Morex['type'].isin(['exon'])]\n",
    "exon_Hv_Morex.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Exporting the exon dataframe to a tsv file \n",
    "exon_Hv_Morex.to_csv('Data/Hv_Morex_exon.tsv',sep='\\t',index=False,header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### --- Keeping in a separated dataframe the forward strands\n",
    "forw_Hv_Morex = df_Hv_Morex.loc[df_Hv_Morex['strand'].isin(['+'])]\n",
    "forw_Hv_Morex.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Keeping in a separated dataframe the reverse strands\n",
    "rev_Hv_Morex = df_Hv_Morex.loc[df_Hv_Morex['strand'].isin(['-'])]\n",
    "rev_Hv_Morex.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Keeping in a separated dataframe the UTR regions on the forward strands\n",
    "UTR_forw_Hv_Morex = forw_Hv_Morex.loc[df_Hv_Morex['type'].isin(['three_prime_UTR','five_prime_UTR'])]\n",
    "UTR_forw_Hv_Morex.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Writing to a tsv formatted file the UTR_df_rev dataframe\n",
    "UTR_forw_Hv_Morex.to_csv('Data/Hv_Morex_UTRforw.tsv',sep='\\t',index=False,header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### --- Keeping in a separated dataframe the UTR regions on the reverse strands\n",
    "UTR_rev_Hv_Morex = rev_Hv_Morex.loc[df_Hv_Morex['type'].isin(['three_prime_UTR','five_prime_UTR'])]\n",
    "UTR_rev_Hv_Morex.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Writing to a tsv formatted file the UTR_df_rev dataframe\n",
    "UTR_rev_Hv_Morex.to_csv('Data/Hv_Morex_UTRrev.tsv',sep='\\t',index=False,header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.3 Extracting introns from the whole genome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Extracting introns from Hv_Morex\n",
    "extract_tot_introns('Data/Hv_Morex_exon.tsv', 'Output/Hv_Morex_introns.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "introns_Hv_Morex = pd.read_csv('Output/Hv_Morex_introns.tsv', sep = '\\t')\n",
    "introns_Hv_Morex[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Counting introns type in Hv_MorexHC\n",
    "introns_dictionary_Hv_Morex = counting_introns_type(exon_Hv_Morex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_intronless_Hv_Morex, n_intronpoor_Hv_Morex, n_intronrich_Hv_Morex, intronless_Hv_Morex, intronpoor_Hv_Morex, intronrich_Hv_Morex = splitting_introns_type(introns_dictionary_Hv_Morex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genes = ['Intronless', 'Intronpoor', 'Intronrich']\n",
    "data_Hv_Morex = [46175, 22342, 13170]\n",
    "fig = plt.figure(figsize =(10, 7))\n",
    "plt.pie(data_Hv_Morex, labels = genes, autopct='%1.0f%%')\n",
    "plt.title(\"Genes Hv_Morex Distribution\", bbox={'facecolor':'0.8', 'pad':5})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Creating the list of Hv_Morex gene IDs to check the number of transcripts using command line\n",
    "intronless_file_Hv_Morex = open('Output/Hv_Morex_intronlessIDs.txt', 'a')\n",
    "intronpoor_file_Hv_Morex = open('Output/Hv_Morex_intronpoorIDs.txt', 'a')\n",
    "intronrich_file_Hv_Morex = open('Output/Hv_Morex_intronrichIDs.txt', 'a')\n",
    "for i in range(len(intronless_Hv_Morex)):\n",
    "    if i == len(intronless_Hv_Morex) -1:\n",
    "        intronless_file_Hv_Morex.write(intronless_Hv_Morex[i])\n",
    "    else:\n",
    "        intronless_file_Hv_Morex.write(intronless_Hv_Morex[i] + '\\n')\n",
    "intronless_file_Hv_Morex.close()\n",
    "\n",
    "for i in range(len(intronpoor_Hv_Morex)):\n",
    "    if i == len(intronpoor_Hv_Morex) -1:\n",
    "        intronpoor_file_Hv_Morex.write(intronpoor_Hv_Morex[i])\n",
    "    else:\n",
    "        intronpoor_file_Hv_Morex.write(intronpoor_Hv_Morex[i] + '\\n')\n",
    "intronpoor_file_Hv_Morex.close()\n",
    "\n",
    "for i in range(len(intronrich_Hv_Morex)):\n",
    "    if i == len(intronrich_Hv_Morex) -1:\n",
    "        intronrich_file_Hv_Morex.write(intronrich_Hv_Morex[i])\n",
    "    else:\n",
    "        intronrich_file_Hv_Morex.write(intronrich_Hv_Morex[i]+'\\n')\n",
    "intronrich_file_Hv_Morex.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Storing the number of transcripts in intron-less/poor/rich genes within a variable \n",
    "n_mRNA_intronless_Hv_Morex = ! grep -f Output/Hv_Morex_intronlessIDs.txt Data/Hv_Morex_nohashtag.pgsb.Jul2020.gff3 | awk -F '\\t' '{print $3}' | grep -w 'mRNA' | wc -l\n",
    "n_mRNA_intronpoor_Hv_Morex = ! grep -f Output/Hv_Morex_intronpoorIDs.txt Data/Hv_Morex_nohashtag.pgsb.Jul2020.gff3 | awk -F '\\t' '{print $3}' | grep -w 'mRNA' | wc -l\n",
    "n_mRNA_intronrich_Hv_Morex = ! grep -f Output/Hv_Morex_intronrichIDs.txt Data/Hv_Morex_nohashtag.pgsb.Jul2020.gff3 | awk -F '\\t' '{print $3}' | grep -w 'mRNA' | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Checking the average number of transcripts for each gene-type\n",
    "avg_mRNA_intronless_Hv_Morex = int(n_mRNA_intronless_Hv_Morex[0])/n_intronless_Hv_Morex\n",
    "print(avg_mRNA_intronless_Hv_Morex)\n",
    "avg_mRNA_intronpoor_Hv_Morex = int(n_mRNA_intronpoor_Hv_Morex[0])/n_intronpoor_Hv_Morex\n",
    "print(avg_mRNA_intronpoor_Hv_Morex)\n",
    "avg_mRNA_intronrich_Hv_Morex = int(n_mRNA_intronrich_Hv_Morex[0])/n_intronrich_Hv_Morex\n",
    "print(avg_mRNA_intronrich_Hv_Morex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.4 Extracting introns from UTR regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Extracting introns from UTR forward Hv_Morex\n",
    "extract_UTR_introns('Data/Hv_Morex_UTRforw.tsv', 'Output/Hv_Morex_UTRforw_introns.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Extracting introns from UTR reverse Hv_Morex\n",
    "extract_UTR_introns('Data/Hv_Morex_UTRrev.tsv', 'Output/Hv_Morex_UTRrev_introns.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "introns_UTR_forw_Hv_Morex = pd.read_csv('Output/Hv_Morex_UTRforw_introns.tsv', sep='\\t')\n",
    "introns_UTR_forw_Hv_Morex.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "introns_UTR_rev_Hv_Morex = pd.read_csv('Output/Hv_Morex_UTRrev_introns.tsv', sep = '\\t')\n",
    "introns_UTR_rev_Hv_Morex.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Concatenating the UTR_introns to build a unique dataframe\n",
    "frames_Hv_Morex = [introns_UTR_forw_Hv_Morex, introns_UTR_rev_Hv_Morex]\n",
    "introns_UTR_Hv_Morex = pd.concat(frames_Hv_Morex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Performing some basic statistics \n",
    "introns_UTR_Hv_Morex['length'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Plotting the distribution of UTR introns length\n",
    "introns_UTR_Hv_Morex['length'].plot.density()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Plotting the boxplot of UTR introns length without outliers\n",
    "introns_UTR_Hv_Morex.boxplot(column='length', return_type='axes', showfliers=False) # showfliers = False -> discard outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- splitting in introns 3'UTR and 5'UTR to eventually if there are differences among the two\n",
    "introns_UTR3_Hv_Morex = introns_UTR_Hv_Morex.loc[introns_UTR_Hv_Morex['type'].isin(['intron three_prime_UTR'])]\n",
    "introns_UTR5_Hv_Morex = introns_UTR_Hv_Morex.loc[introns_UTR_Hv_Morex['type'].isin(['intron five_prime_UTR'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "introns_UTR3_Hv_Morex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "introns_UTR3_Hv_Morex['length'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "introns_UTR5_Hv_Morex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "introns_UTR5_Hv_Morex['length'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Plotting the distribution of introns_UTR vs total UTRs\n",
    "labels_Hv_Morex = ['UTRs', 'Introns_5UTR', 'Introns_3UTR']\n",
    "UTR_data_Hv_Morex = [22630 + 21738 -(3699+2012), 3699, 2012]\n",
    "fig = plt.figure(figsize =(10, 7))\n",
    "plt.pie(UTR_data_Hv_Morex, labels = labels_Hv_Morex, autopct='%1.0f%%')\n",
    "plt.title(\"UTRs Hv_Morex Distribution\", bbox={'facecolor':'0.8', 'pad':5})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.5 Removing UTR introns from the whole introns dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Checking total introns dataframe \n",
    "introns_Hv_Morex.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Checking UTR introns dataframe\n",
    "introns_UTR_Hv_Morex.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Extracting introns from cds within Hv_MorexHC\n",
    "introns_cds_Hv_Morex = cds_introns_dataframe(introns_Hv_Morex, introns_UTR_Hv_Morex)\n",
    "introns_cds_Hv_Morex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Checking if there are not introns UTR within the created dataframe\n",
    "introns_cds_Hv_Morex.loc[introns_cds_Hv_Morex['type'].isin(['intron three_prime_UTR','intron five_prime_UTR'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Basic statistics of Hv_Morex introns cds\n",
    "introns_cds_Hv_Morex['length'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Plotting the distribution of Hv_Morex cds introns length\n",
    "introns_cds_Hv_Morex['length'].plot.density()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Plotting the boxplot of Hv_Morex cds introns length without outliers\n",
    "introns_cds_Hv_Morex.boxplot(column='length', return_type='axes', showfliers=False) # showfliers = False -> discard outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.6 Re-organizing files and directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls Data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mv Data/*tsv Data/Hv_Morex_longread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mv Data/Hv_Morex_n* Data/Hv_Morex_longread/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls Data/Hv_Morex_longread/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls Output/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mv Output/*tsv Output/Hv_Morex_longread/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mv Output/*txt Output/Hv_Morex_longread/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls Output/Hv_Morex_longread/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Reproducing the same analysis using data of a Pan Genome study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Pan Genome study I am referring to can be found [here](https://www.nature.com/articles/s41586-020-2947-8). All the data can be found [here](https://doi.ipk-gatersleben.de/DOI/c4d433dc-bf7c-4ad9-9368-69bb77837ca5/3490162b-3d76-4ba1-b6ee-3eaed5f6b644/2/).\n",
    "\n",
    "I will firstly perform the analysis on the data within the _Denovo_gene_annotation_ directory and then on the ones within the _Gene_projection_ directory. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Barke - De novo gene annotation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.1 Collecting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- This will download the raw data to the subdirectory raw under the directory Data\n",
    "! wget -O Data/raw/Barke.gff3 https://doi.ipk-gatersleben.de/DOI/c4d433dc-bf7c-4ad9-9368-69bb77837ca5/1f736b6a-20f5-4e48-83c9-a308a51221ee/1/DOWNLOAD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.2 Processing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- There is no need to import the libraries again\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Removing all hashtags from the gff3 file\n",
    "! sed '/#/d' Data/raw/Barke.gff3  > Data/Barke_nohashtag.gff3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Changing the gff3 file to a csv format file to import it with pandas\n",
    "! cat Data/Barke_nohashtag.gff3 | sed 's/,/--/g' | sed 's/;/--/g' | sed 's/\\t/,/g' | awk -F '--' '{print $1}' > Data/Barke_nohashtag.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### --- Transforming the gff3 file to a pandas dataframe to better handle it\n",
    "df_Barke = pd.read_csv('Data/Barke_nohashtag.csv', header=None, names = ['chr', 'source', 'type','start','end','score','strand','phase','attributes'])\n",
    "df_Barke.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Building a separate dataframe containing all exons\n",
    "exon_Barke = df_Barke.loc[df_Barke['type'].isin(['exon'])]\n",
    "exon_Barke.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Exporting the exon dataframe to a tsv file \n",
    "exon_Barke.to_csv('Data/Barke_exon.tsv',sep='\\t',index=False,header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Keeping in a separated dataframe the forward strands\n",
    "forw_Barke = df_Barke.loc[df_Barke['strand'].isin(['+'])]\n",
    "forw_Barke.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Keeping in a separated dataframe the reverse strands\n",
    "rev_Barke = df_Barke.loc[df_Barke['strand'].isin(['-'])]\n",
    "rev_Barke.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Keeping in a separated dataframe the UTR regions on the forward strands\n",
    "UTR_forw_Barke = forw_Barke.loc[df_Barke['type'].isin(['three_prime_UTR','five_prime_UTR'])]\n",
    "UTR_forw_Barke.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Keeping in a separated dataframe the UTR regions on the reverse strands\n",
    "UTR_rev_Barke = rev_Barke.loc[df_Barke['type'].isin(['three_prime_UTR','five_prime_UTR'])]\n",
    "UTR_rev_Barke.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see UTRs are not reported within this annotation so we cannot analyze them. We will just focus on the total number of introns. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.3 Extracting introns from the whole genome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Extracting introns from Barke\n",
    "extract_tot_introns('Data/Barke_exon.tsv', 'Output/Barke_introns.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "introns_Barke = pd.read_csv('Output/Barke_introns.tsv', sep = '\\t')\n",
    "introns_Barke[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Counting introns type in Barke\n",
    "introns_dictionary_Barke = counting_introns_type(exon_Barke)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_intronless_Barke, n_intronpoor_Barke, n_intronrich_Barke, intronless_Barke, intronpoor_Barke, intronrich_Barke = splitting_introns_type(introns_dictionary_Barke)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genes = ['Intronless', 'Intronpoor', 'Intronrich']\n",
    "data_Barke = [25166, 14852, 11019]\n",
    "fig = plt.figure(figsize =(10, 7))\n",
    "plt.pie(data_Barke, labels = genes, autopct='%1.0f%%')\n",
    "plt.title(\"Genes Barke Distribution\", bbox={'facecolor':'0.8', 'pad':5})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Creating the list of Barke gene IDs to check the number of transcripts using command line\n",
    "intronless_file_Barke = open('Output/Barke_intronlessIDs.txt', 'a')\n",
    "intronpoor_file_Barke = open('Output/Barke_intronpoorIDs.txt', 'a')\n",
    "intronrich_file_Barke = open('Output/Barke_intronrichIDs.txt', 'a')\n",
    "for i in range(len(intronless_Barke)):\n",
    "    if i == len(intronless_Barke) -1:\n",
    "        intronless_file_Barke.write(intronless_Barke[i])\n",
    "    else:\n",
    "        intronless_file_Barke.write(intronless_Barke[i] + '\\n')\n",
    "intronless_file_Barke.close()\n",
    "\n",
    "for i in range(len(intronpoor_Barke)):\n",
    "    if i == len(intronpoor_Barke) -1:\n",
    "        intronpoor_file_Barke.write(intronpoor_Barke[i])\n",
    "    else:\n",
    "        intronpoor_file_Barke.write(intronpoor_Barke[i] + '\\n')\n",
    "intronpoor_file_Barke.close()\n",
    "\n",
    "for i in range(len(intronrich_Barke)):\n",
    "    if i == len(intronrich_Barke) -1:\n",
    "        intronrich_file_Barke.write(intronrich_Barke[i])\n",
    "    else:\n",
    "        intronrich_file_Barke.write(intronrich_Barke[i]+'\\n')\n",
    "intronrich_file_Barke.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Storing the number of transcripts in intron-less/poor/rich genes within a variable \n",
    "n_mRNA_intronless_Barke = ! grep -f Output/Barke_intronlessIDs.txt Data/Barke_nohashtag.gff3 | awk -F '\\t' '{print $3}' | grep -w 'mRNA' | wc -l\n",
    "n_mRNA_intronpoor_Barke = ! grep -f Output/Barke_intronpoorIDs.txt Data/Barke_nohashtag.gff3 | awk -F '\\t' '{print $3}' | grep -w 'mRNA' | wc -l\n",
    "n_mRNA_intronrich_Barke = ! grep -f Output/Barke_intronrichIDs.txt Data/Barke_nohashtag.gff3 | awk -F '\\t' '{print $3}' | grep -w 'mRNA' | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Checking the average number of transcripts for each gene-type\n",
    "avg_mRNA_intronless_Barke = int(n_mRNA_intronless_Barke[0])/n_intronless_Barke\n",
    "print(avg_mRNA_intronless_Barke)\n",
    "avg_mRNA_intronpoor_Barke = int(n_mRNA_intronpoor_Barke[0])/n_intronpoor_Barke\n",
    "print(avg_mRNA_intronpoor_Barke)\n",
    "avg_mRNA_intronrich_Barke = int(n_mRNA_intronrich_Barke[0])/n_intronrich_Barke\n",
    "print(avg_mRNA_intronrich_Barke)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems there are no transcripts undergoing alternative splicing. This is probably due to a poor annotation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Basic statistics of Barke introns\n",
    "introns_Barke['length'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Plotting the distribution of Barke introns length\n",
    "introns_Barke['length'].plot.density()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Plotting the boxplot of Barke introns length without outliers\n",
    "introns_Barke.boxplot(column='length', return_type='axes', showfliers=False) # showfliers = False -> discard outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.4 Re-organizing files and directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "! ls Data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir Data/Barke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mv Data/Barke_* Data/Barke/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls Data/Barke/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls Output/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir Output/Barke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mv Output/Barke_* Output/Barke/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls Output/Barke/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 HOR10350 - De novo gene annotation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1 Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### --- This will download the raw data to the subdirectory raw under the directory Data\n",
    "! wget -O Data/raw/HOR10350.gff3 https://doi.ipk-gatersleben.de/DOI/c4d433dc-bf7c-4ad9-9368-69bb77837ca5/4435ac3e-52f1-47df-9709-4c30e4d21131/1/DOWNLOAD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2 Processing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Removing all hashtags from the gff3 file\n",
    "! sed '/#/d' Data/raw/HOR10350.gff3  > Data/HOR10350_nohashtag.gff3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Changing the gff3 file to a csv format file to import it with pandas\n",
    "! cat Data/HOR10350_nohashtag.gff3 | sed 's/,/--/g' | sed 's/;/--/g' | sed 's/\\t/,/g' | awk -F '--' '{print $1}' > Data/HOR10350_nohashtag.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Transforming the gff3 file to a pandas dataframe to better handle it\n",
    "df_HOR10350 = pd.read_csv('Data/HOR10350_nohashtag.csv', header=None, names = ['chr', 'source', 'type','start','end','score','strand','phase','attributes'])\n",
    "df_HOR10350.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Building a separate dataframe containing all exons\n",
    "exon_HOR10350 = df_HOR10350.loc[df_HOR10350['type'].isin(['exon'])]\n",
    "exon_HOR10350.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Exporting the exon dataframe to a tsv file \n",
    "exon_HOR10350.to_csv('Data/HOR10350_exon.tsv',sep='\\t',index=False,header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Keeping in a separated dataframe the forward strands\n",
    "forw_HOR10350 = df_HOR10350.loc[df_HOR10350['strand'].isin(['+'])]\n",
    "forw_HOR10350.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Keeping in a separated dataframe the reverse strands\n",
    "rev_HOR10350 = df_HOR10350.loc[df_HOR10350['strand'].isin(['-'])]\n",
    "rev_HOR10350.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Keeping in a separated dataframe the UTR regions on the forward strands\n",
    "UTR_forw_HOR10350 = forw_HOR10350.loc[df_HOR10350['type'].isin(['three_prime_UTR','five_prime_UTR'])]\n",
    "UTR_forw_HOR10350.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### --- Keeping in a separated dataframe the UTR regions on the reverse strands\n",
    "UTR_rev_HOR10350 = rev_HOR10350.loc[df_HOR10350['type'].isin(['three_prime_UTR','five_prime_UTR'])]\n",
    "UTR_rev_HOR10350.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before there are no UTRs due to a poor annotation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.3 Extracting introns from the whole genome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Extracting introns from HOR10350\n",
    "extract_tot_introns('Data/HOR10350_exon.tsv', 'Output/HOR10350_introns.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "introns_HOR10350 = pd.read_csv('Output/HOR10350_introns.tsv', sep = '\\t')\n",
    "introns_HOR10350[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Counting introns type in HOR10350\n",
    "introns_dictionary_HOR10350 = counting_introns_type(exon_HOR10350)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n_intronless_HOR10350, n_intronpoor_HOR10350, n_intronrich_HOR10350, intronless_HOR10350, intronpoor_HOR10350, intronrich_HOR10350 = splitting_introns_type(introns_dictionary_HOR10350)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genes = ['Intronless', 'Intronpoor', 'Intronrich']\n",
    "data_HOR10350 = [24866, 14709, 11126]\n",
    "fig = plt.figure(figsize =(10, 7))\n",
    "plt.pie(data_HOR10350, labels = genes, autopct='%1.0f%%')\n",
    "plt.title(\"Genes HOR10350 Distribution\", bbox={'facecolor':'0.8', 'pad':5})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Creating the list of HOR10350 gene IDs to check the number of transcripts using command line\n",
    "intronless_file_HOR10350 = open('Output/HOR10350_intronlessIDs.txt', 'a')\n",
    "intronpoor_file_HOR10350 = open('Output/HOR10350_intronpoorIDs.txt', 'a')\n",
    "intronrich_file_HOR10350 = open('Output/HOR10350_intronrichIDs.txt', 'a')\n",
    "for i in range(len(intronless_HOR10350)):\n",
    "    if i == len(intronless_HOR10350) -1:\n",
    "        intronless_file_HOR10350.write(intronless_HOR10350[i])\n",
    "    else:\n",
    "        intronless_file_HOR10350.write(intronless_HOR10350[i] + '\\n')\n",
    "intronless_file_HOR10350.close()\n",
    "\n",
    "for i in range(len(intronpoor_HOR10350)):\n",
    "    if i == len(intronpoor_HOR10350) -1:\n",
    "        intronpoor_file_HOR10350.write(intronpoor_HOR10350[i])\n",
    "    else:\n",
    "        intronpoor_file_HOR10350.write(intronpoor_HOR10350[i] + '\\n')\n",
    "intronpoor_file_HOR10350.close()\n",
    "\n",
    "for i in range(len(intronrich_HOR10350)):\n",
    "    if i == len(intronrich_HOR10350) -1:\n",
    "        intronrich_file_HOR10350.write(intronrich_HOR10350[i])\n",
    "    else:\n",
    "        intronrich_file_HOR10350.write(intronrich_HOR10350[i]+'\\n')\n",
    "intronrich_file_HOR10350.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Storing the number of transcripts in intron-less/poor/rich genes within a variable \n",
    "n_mRNA_intronless_HOR10350 = ! grep -f Output/HOR10350_intronlessIDs.txt Data/HOR10350_nohashtag.gff3 | awk -F '\\t' '{print $3}' | grep -w 'mRNA' | wc -l\n",
    "n_mRNA_intronpoor_HOR10350 = ! grep -f Output/HOR10350_intronpoorIDs.txt Data/HOR10350_nohashtag.gff3 | awk -F '\\t' '{print $3}' | grep -w 'mRNA' | wc -l\n",
    "n_mRNA_intronrich_HOR10350 = ! grep -f Output/HOR10350_intronrichIDs.txt Data/HOR10350_nohashtag.gff3 | awk -F '\\t' '{print $3}' | grep -w 'mRNA' | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### --- Checking the average number of transcripts for each gene-type\n",
    "avg_mRNA_intronless_HOR10350 = int(n_mRNA_intronless_HOR10350[0])/n_intronless_HOR10350\n",
    "print(avg_mRNA_intronless_HOR10350)\n",
    "avg_mRNA_intronpoor_HOR10350 = int(n_mRNA_intronpoor_HOR10350[0])/n_intronpoor_HOR10350\n",
    "print(avg_mRNA_intronpoor_HOR10350)\n",
    "avg_mRNA_intronrich_HOR10350 = int(n_mRNA_intronrich_HOR10350[0])/n_intronrich_HOR10350\n",
    "print(avg_mRNA_intronrich_HOR10350)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again no more than 1 transcript/gene annotated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Basic statistics of HOR10350 introns\n",
    "introns_HOR10350['length'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Plotting the distribution of HOR10350 introns length\n",
    "introns_HOR10350['length'].plot.density()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Plotting the boxplot of HOR10350 introns length without outliers\n",
    "introns_HOR10350.boxplot(column='length', return_type='axes', showfliers=False) # showfliers = False -> discard outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.4 Re-organizing files and directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "! ls Data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir Data/HOR10350"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mv Data/HOR10350_* Data/HOR10350/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "! ls Data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls Output/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir Output/HOR10350"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mv Output/HOR10350_* Output/HOR10350/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "! ls Output/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Morex - De novo gene annotation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.1 Data collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- This will download the raw data to the subdirectory raw under the directory Data\n",
    "! wget -O Data/raw/Morex.gff3 https://doi.ipk-gatersleben.de/DOI/c4d433dc-bf7c-4ad9-9368-69bb77837ca5/f937d01e-f9cf-415a-961b-c490db136f92/1/DOWNLOAD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.2 Processing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- There is no need to import the libraries again\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Removing all hashtags from the gff3 file\n",
    "! sed '/#/d' Data/raw/Morex.gff3  > Data/Morex_nohashtag.gff3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Changing the gff3 file to a csv format file to import it with pandas\n",
    "! cat Data/Morex_nohashtag.gff3 | sed 's/,/--/g' | sed 's/;/--/g' | sed 's/\\t/,/g' | awk -F '--' '{print $1}' > Data/Morex_nohashtag.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Transforming the gff3 file to a pandas dataframe to better handle it\n",
    "df_Morex = pd.read_csv('Data/Morex_nohashtag.csv', header=None, names = ['chr', 'source', 'type','start','end','score','strand','phase','attributes'])\n",
    "df_Morex.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Building a separate dataframe containing all exons\n",
    "exon_Morex = df_Morex.loc[df_Morex['type'].isin(['exon'])]\n",
    "exon_Morex.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Exporting the exon dataframe to a tsv file \n",
    "exon_Morex.to_csv('Data/Morex_exon.tsv',sep='\\t',index=False,header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Keeping in a separated dataframe the forward strands\n",
    "forw_Morex = df_Morex.loc[df_Morex['strand'].isin(['+'])]\n",
    "forw_Morex.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Keeping in a separated dataframe the reverse strands\n",
    "rev_Morex = df_Morex.loc[df_Morex['strand'].isin(['-'])]\n",
    "rev_Morex.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Keeping in a separated dataframe the UTR regions on the forward strands\n",
    "UTR_forw_Morex = forw_Morex.loc[df_Morex['type'].isin(['three_prime_UTR','five_prime_UTR'])]\n",
    "UTR_forw_Morex.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Keeping in a separated dataframe the UTR regions on the reverse strands\n",
    "UTR_rev_Morex = rev_Morex.loc[df_Morex['type'].isin(['three_prime_UTR','five_prime_UTR'])]\n",
    "UTR_rev_Morex.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in the other cases no UTRs annotated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.3 Extracting introns from the whole genome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Extracting introns from Morex\n",
    "extract_tot_introns('Data/Morex_exon.tsv', 'Output/Morex_introns.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "introns_Morex = pd.read_csv('Output/Morex_introns.tsv', sep = '\\t')\n",
    "introns_Morex[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Counting introns type in Morex\n",
    "introns_dictionary_Morex = counting_introns_type(exon_Morex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_intronless_Morex, n_intronpoor_Morex, n_intronrich_Morex, intronless_Morex, intronpoor_Morex, intronrich_Morex = splitting_introns_type(introns_dictionary_Morex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genes = ['Intronless', 'Intronpoor', 'Intronrich']\n",
    "data_Morex = [33663, 17811, 12184]\n",
    "fig = plt.figure(figsize =(10, 7))\n",
    "plt.pie(data_Morex, labels = genes, autopct='%1.0f%%')\n",
    "plt.title(\"Genes Morex Distribution\", bbox={'facecolor':'0.8', 'pad':5})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Creating the list of Morex gene IDs to check the number of transcripts using command line\n",
    "intronless_file_Morex = open('Output/Morex_intronlessIDs.txt', 'a')\n",
    "intronpoor_file_Morex = open('Output/Morex_intronpoorIDs.txt', 'a')\n",
    "intronrich_file_Morex = open('Output/Morex_intronrichIDs.txt', 'a')\n",
    "for i in range(len(intronless_Morex)):\n",
    "    if i == len(intronless_Morex) -1:\n",
    "        intronless_file_Morex.write(intronless_Morex[i])\n",
    "    else:\n",
    "        intronless_file_Morex.write(intronless_Morex[i] + '\\n')\n",
    "intronless_file_Morex.close()\n",
    "\n",
    "for i in range(len(intronpoor_Morex)):\n",
    "    if i == len(intronpoor_Morex) -1:\n",
    "        intronpoor_file_Morex.write(intronpoor_Morex[i])\n",
    "    else:\n",
    "        intronpoor_file_Morex.write(intronpoor_Morex[i] + '\\n')\n",
    "intronpoor_file_Morex.close()\n",
    "\n",
    "for i in range(len(intronrich_Morex)):\n",
    "    if i == len(intronrich_Morex) -1:\n",
    "        intronrich_file_Morex.write(intronrich_Morex[i])\n",
    "    else:\n",
    "        intronrich_file_Morex.write(intronrich_Morex[i]+'\\n')\n",
    "intronrich_file_Morex.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Storing the number of transcripts in intron-less/poor/rich genes within a variable \n",
    "n_mRNA_intronless_Morex = ! grep -f Output/Morex_intronlessIDs.txt Data/Morex_nohashtag.gff3 | awk -F '\\t' '{print $3}' | grep -w 'mRNA' | wc -l\n",
    "n_mRNA_intronpoor_Morex = ! grep -f Output/Morex_intronpoorIDs.txt Data/Morex_nohashtag.gff3 | awk -F '\\t' '{print $3}' | grep -w 'mRNA' | wc -l\n",
    "n_mRNA_intronrich_Morex = ! grep -f Output/Morex_intronrichIDs.txt Data/Morex_nohashtag.gff3 | awk -F '\\t' '{print $3}' | grep -w 'mRNA' | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### --- Checking the average number of transcripts for each gene-type\n",
    "avg_mRNA_intronless_Morex = int(n_mRNA_intronless_Morex[0])/n_intronless_Morex\n",
    "print(avg_mRNA_intronless_Morex)\n",
    "avg_mRNA_intronpoor_Morex = int(n_mRNA_intronpoor_Morex[0])/n_intronpoor_Morex\n",
    "print(avg_mRNA_intronpoor_Morex)\n",
    "avg_mRNA_intronrich_Morex = int(n_mRNA_intronrich_Morex[0])/n_intronrich_Morex\n",
    "print(avg_mRNA_intronrich_Morex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poor annotation once again. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Basic statistics of Morex introns\n",
    "introns_Morex['length'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Plotting the distribution of Morex introns length\n",
    "introns_Morex['length'].plot.density()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Plotting the boxplot of Morex introns length without outliers\n",
    "introns_Morex.boxplot(column='length', return_type='axes', showfliers=False) # showfliers = False -> discard outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.4 Re-organizing files and directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls Data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir Data/Morex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mv Data/Morex_* Data/Morex/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls Data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls Output/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir Output/Morex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mv Output/Morex_* Output/Morex/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls Output/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Re-defining the functions due to a different 9th field format of the genomes within the Gene_projection directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Function to extract introns from the whole genome\n",
    "### --- Infile is a file like Akashinriki_exon.tsv \n",
    "### --- Outfile will be written thanks to this function\n",
    "### --- If there are two or more exons belonging to the same mRNA one after the other it compute the introns separating them\n",
    "def extract_tot_introns_gp(infile, outfile):\n",
    "    introns = open(outfile, 'a') \n",
    "    introns.write('ID'+'\\t'+'type'+'\\t'+'start'+'\\t'+'end'+'\\t'+'length') \n",
    "    with open(infile) as f: \n",
    "        lines = f.readlines()\n",
    "        for i in range(0, len(lines)):\n",
    "            if i+1 == len(lines): # This is to avoid out of range error\n",
    "                break \n",
    "            else:\n",
    "                line = lines[i]\n",
    "                line = line.rstrip()\n",
    "                line = line.split()\n",
    "                next_line = lines[i+1]\n",
    "                next_line = lines[i+1].rstrip()\n",
    "                next_line = lines[i+1].split()\n",
    "                if '_'.join(line[8].split('_')[0:3]) != '_'.join(next_line[8].split('_')[0:3]): continue # Checking if the next exon has the same ID of the one we are at\n",
    "                \n",
    "                introns.write('\\n'+'_'.join(line[8].split('_')[0:3])+'\\t'+ 'intron ' +'\\t'+str(int(line[4])+1)+'\\t'+str(int(next_line[3])-1)+'\\t'+str(int(next_line[3])-1-int(line[4])+1))\n",
    "    introns.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Function to count introns within a dataframe made of exons formatted like exon_Akashinriki\n",
    "\n",
    "def counting_introns_type_gp(in_dataframe):\n",
    "    counts = dict()\n",
    "    for i in in_dataframe['attributes']:\n",
    "        counts['_'.join(i.split('_')[0:3])] = counts.get('_'.join(i.split('_')[0:3]), 0) + 1\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Function to extract introns from UTR regions.\n",
    "### --- Infile is a file like Akashinriki_UTRforw_introns.tsv \n",
    "### --- Outfile will be written thanks to this function\n",
    "### --- Being all on the same strand when two or more UTRs of the same type are one row after the other it means there is a intron separating them\n",
    "def extract_UTR_introns_gp(infile, outfile):\n",
    "    UTR_introns_forw = open(outfile, 'a')\n",
    "    UTR_introns_forw.write('ID'+'\\t'+'type'+'\\t'+'start'+'\\t'+'end'+'\\t'+'length') # Defining the header\n",
    "    with open(infile) as f:\n",
    "        lines = f.readlines()\n",
    "        for i in range(0, len(lines)):\n",
    "            if i+1 == len(lines):\n",
    "                break\n",
    "            else:\n",
    "                line = lines[i]\n",
    "                line = line.rstrip()\n",
    "                line = line.split()\n",
    "                next_line = lines[i+1]\n",
    "                next_line = lines[i+1].rstrip()\n",
    "                next_line = lines[i+1].split()\n",
    "                if line[2] != next_line[2] or '_'.join(line[8].split('_')[0:3]) != '_'.join(next_line[8].split('_')[0:3]): continue\n",
    "                \n",
    "                UTR_introns_forw.write('\\n'+'_'.join(line[8].split('_')[0:3])+'\\t'+ 'intron '+line[2]+'\\t'+str(int(line[4])+1)+'\\t'+str(int(next_line[3])-1)+'\\t'+str(int(next_line[3])-1-int(line[4])+1))\n",
    "    UTR_introns_forw.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 Akashinriki - Gene projection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5.1 Data collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- This will download the raw data to the subdirectory raw under the directory Data\n",
    "! wget -O Data/raw/Akashinriki.gff3 https://doi.ipk-gatersleben.de/DOI/c4d433dc-bf7c-4ad9-9368-69bb77837ca5/325492c0-89ef-4beb-87ef-c2372093a918/1/DOWNLOAD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5.2 Processing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- There is no need to import the libraries again\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Removing all hashtags from the gff3 file\n",
    "! sed '/#/d' Data/raw/Akashinriki.gff3  > Data/Akashinriki_nohashtag.gff3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Changing the gff3 file to a csv format file to import it with pandas\n",
    "! cat Data/Akashinriki_nohashtag.gff3 | sed 's/,/--/g' | sed 's/;/--/g' | sed 's/\\t/,/g' | awk -F '--' '{print $1}' > Data/Akashinriki_nohashtag.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Transforming the gff3 file to a pandas dataframe to better handle it\n",
    "df_Akashinriki = pd.read_csv('Data/Akashinriki_nohashtag.csv', header=None, names = ['chr', 'source', 'type','start','end','score','strand','phase','attributes'])\n",
    "df_Akashinriki.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Building a separate dataframe containing all exons\n",
    "exon_Akashinriki = df_Akashinriki.loc[df_Akashinriki['type'].isin(['exon'])]\n",
    "exon_Akashinriki.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Exporting the exon dataframe to a tsv file \n",
    "exon_Akashinriki.to_csv('Data/Akashinriki_exon.tsv',sep='\\t',index=False,header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Keeping in a separated dataframe the forward strands\n",
    "forw_Akashinriki = df_Akashinriki.loc[df_Akashinriki['strand'].isin(['+'])]\n",
    "forw_Akashinriki.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Keeping in a separated dataframe the reverse strands\n",
    "rev_Akashinriki = df_Akashinriki.loc[df_Akashinriki['strand'].isin(['-'])]\n",
    "rev_Akashinriki.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Keeping in a separated dataframe the UTR regions on the forward strands\n",
    "UTR_forw_Akashinriki = forw_Akashinriki.loc[df_Akashinriki['type'].isin(['three_prime_UTR','five_prime_UTR'])]\n",
    "UTR_forw_Akashinriki.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Keeping in a separated dataframe the UTR regions on the reverse strands\n",
    "UTR_rev_Akashinriki = rev_Akashinriki.loc[df_Akashinriki['type'].isin(['three_prime_UTR','five_prime_UTR'])]\n",
    "UTR_rev_Akashinriki.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still no UTRs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5.3 Extracting introns from the whole genome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Extracting introns from Akashinriki\n",
    "extract_tot_introns_gp('Data/Akashinriki_exon.tsv', 'Output/Akashinriki_introns.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "introns_Akashinriki = pd.read_csv('Output/Akashinriki_introns.tsv', sep = '\\t')\n",
    "introns_Akashinriki[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Counting introns type in Akashinriki\n",
    "introns_dictionary_Akashinriki = counting_introns_type_gp(exon_Akashinriki)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_intronless_Akashinriki, n_intronpoor_Akashinriki, n_intronrich_Akashinriki, intronless_Akashinriki, intronpoor_Akashinriki, intronrich_Akashinriki = splitting_introns_type(introns_dictionary_Akashinriki)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genes = ['Intronless', 'Intronpoor', 'Intronrich']\n",
    "data_Akashinriki = [16635, 18474, 12050]\n",
    "fig = plt.figure(figsize =(10, 7))\n",
    "plt.pie(data_Akashinriki, labels = genes, autopct='%1.0f%%')\n",
    "plt.title(\"Genes Akashinriki Distribution\", bbox={'facecolor':'0.8', 'pad':5})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Creating the list of Akashinriki gene IDs to check the number of transcripts using command line\n",
    "intronless_file_Akashinriki = open('Output/Akashinriki_intronlessIDs.txt', 'a')\n",
    "intronpoor_file_Akashinriki = open('Output/Akashinriki_intronpoorIDs.txt', 'a')\n",
    "intronrich_file_Akashinriki = open('Output/Akashinriki_intronrichIDs.txt', 'a')\n",
    "for i in range(len(intronless_Akashinriki)):\n",
    "    if i == len(intronless_Akashinriki) -1:\n",
    "        intronless_file_Akashinriki.write(intronless_Akashinriki[i])\n",
    "    else:\n",
    "        intronless_file_Akashinriki.write(intronless_Akashinriki[i] + '\\n')\n",
    "intronless_file_Akashinriki.close()\n",
    "\n",
    "for i in range(len(intronpoor_Akashinriki)):\n",
    "    if i == len(intronpoor_Akashinriki) -1:\n",
    "        intronpoor_file_Akashinriki.write(intronpoor_Akashinriki[i])\n",
    "    else:\n",
    "        intronpoor_file_Akashinriki.write(intronpoor_Akashinriki[i] + '\\n')\n",
    "intronpoor_file_Akashinriki.close()\n",
    "\n",
    "for i in range(len(intronrich_Akashinriki)):\n",
    "    if i == len(intronrich_Akashinriki) -1:\n",
    "        intronrich_file_Akashinriki.write(intronrich_Akashinriki[i])\n",
    "    else:\n",
    "        intronrich_file_Akashinriki.write(intronrich_Akashinriki[i]+'\\n')\n",
    "intronrich_file_Akashinriki.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Storing the number of transcripts in intron-less/poor/rich genes within a variable \n",
    "n_mRNA_intronless_Akashinriki = ! grep -f Output/Akashinriki_intronlessIDs.txt Data/Akashinriki_nohashtag.gff3 | awk -F '\\t' '{print $3}' | grep -w 'mRNA' | wc -l\n",
    "n_mRNA_intronpoor_Akashinriki = ! grep -f Output/Akashinriki_intronpoorIDs.txt Data/Akashinriki_nohashtag.gff3 | awk -F '\\t' '{print $3}' | grep -w 'mRNA' | wc -l\n",
    "n_mRNA_intronrich_Akashinriki = ! grep -f Output/Akashinriki_intronrichIDs.txt Data/Akashinriki_nohashtag.gff3 | awk -F '\\t' '{print $3}' | grep -w 'mRNA' | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### --- Checking the average number of transcripts for each gene-type\n",
    "avg_mRNA_intronless_Akashinriki = int(n_mRNA_intronless_Akashinriki[0])/n_intronless_Akashinriki\n",
    "print(avg_mRNA_intronless_Akashinriki)\n",
    "avg_mRNA_intronpoor_Akashinriki = int(n_mRNA_intronpoor_Akashinriki[0])/n_intronpoor_Akashinriki\n",
    "print(avg_mRNA_intronpoor_Akashinriki)\n",
    "avg_mRNA_intronrich_Akashinriki = int(n_mRNA_intronrich_Akashinriki[0])/n_intronrich_Akashinriki\n",
    "print(avg_mRNA_intronrich_Akashinriki)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still no alternative splicing annotated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Basic statistics of Akashinriki introns\n",
    "introns_Akashinriki['length'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Plotting the distribution of Akashinriki introns length\n",
    "introns_Akashinriki['length'].plot.density()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Plotting the boxplot of Akashinriki introns length without outliers\n",
    "introns_Akashinriki.boxplot(column='length', return_type='axes', showfliers=False) # showfliers = False -> discard outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5.4 Re-organizing files and directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls Data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir Data/Akashinriki "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mv Data/Akashinriki_* Data/Akashinriki/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls Data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls Output/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir Output/Akashinriki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mv Output/Akashinriki_* Output/Akashinriki/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls Output/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6 B1K_04_12 - Gene projection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6.1 Data collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- This will download the raw data to the subdirectory raw under the directory Data\n",
    "! wget -O Data/raw/B1K.gff3 https://doi.ipk-gatersleben.de/DOI/c4d433dc-bf7c-4ad9-9368-69bb77837ca5/0ae99eec-5c46-41b6-83ab-f7f4b4e2f86c/1/DOWNLOAD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6.2 Processing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- There is no need to import the libraries again\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Removing all hashtags from the gff3 file\n",
    "! sed '/#/d' Data/raw/B1K.gff3  > Data/B1K_nohashtag.gff3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Changing the gff3 file to a csv format file to import it with pandas\n",
    "! cat Data/B1K_nohashtag.gff3 | sed 's/,/--/g' | sed 's/;/--/g' | sed 's/\\t/,/g' | awk -F '--' '{print $1}' > Data/B1K_nohashtag.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Transforming the gff3 file to a pandas dataframe to better handle it\n",
    "df_B1K = pd.read_csv('Data/B1K_nohashtag.csv', header=None, names = ['chr', 'source', 'type','start','end','score','strand','phase','attributes'])\n",
    "df_B1K.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Building a separate dataframe containing all exons\n",
    "exon_B1K = df_B1K.loc[df_B1K['type'].isin(['exon'])]\n",
    "exon_B1K.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Exporting the exon dataframe to a tsv file \n",
    "exon_B1K.to_csv('Data/B1K_exon.tsv',sep='\\t',index=False,header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Keeping in a separated dataframe the forward strands\n",
    "forw_B1K = df_B1K.loc[df_B1K['strand'].isin(['+'])]\n",
    "forw_B1K.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Keeping in a separated dataframe the reverse strands\n",
    "rev_B1K = df_B1K.loc[df_B1K['strand'].isin(['-'])]\n",
    "rev_B1K.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Keeping in a separated dataframe the UTR regions on the forward strands\n",
    "UTR_forw_B1K = forw_B1K.loc[df_B1K['type'].isin(['three_prime_UTR','five_prime_UTR'])]\n",
    "UTR_forw_B1K.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Keeping in a separated dataframe the UTR regions on the reverse strands\n",
    "UTR_rev_B1K = rev_B1K.loc[df_B1K['type'].isin(['three_prime_UTR','five_prime_UTR'])]\n",
    "UTR_rev_B1K.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No UTRs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6.3 Extracting introns from the whole genome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Extracting introns from B1K\n",
    "extract_tot_introns_gp('Data/B1K_exon.tsv', 'Output/B1K_introns.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "introns_B1K = pd.read_csv('Output/B1K_introns.tsv', sep = '\\t')\n",
    "introns_B1K[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Counting introns type in B1K\n",
    "introns_dictionary_B1K = counting_introns_type_gp(exon_B1K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_intronless_B1K, n_intronpoor_B1K, n_intronrich_B1K, intronless_B1K, intronpoor_B1K, intronrich_B1K = splitting_introns_type(introns_dictionary_B1K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genes = ['Intronless', 'Intronpoor', 'Intronrich']\n",
    "data_B1K = [17002, 18551, 12034]\n",
    "fig = plt.figure(figsize =(10, 7))\n",
    "plt.pie(data_B1K, labels = genes, autopct='%1.0f%%')\n",
    "plt.title(\"Genes B1K Distribution\", bbox={'facecolor':'0.8', 'pad':5})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Creating the list of B1K gene IDs to check the number of transcripts using command line\n",
    "intronless_file_B1K = open('Output/B1K_intronlessIDs.txt', 'a')\n",
    "intronpoor_file_B1K = open('Output/B1K_intronpoorIDs.txt', 'a')\n",
    "intronrich_file_B1K = open('Output/B1K_intronrichIDs.txt', 'a')\n",
    "for i in range(len(intronless_B1K)):\n",
    "    if i == len(intronless_B1K) -1:\n",
    "        intronless_file_B1K.write(intronless_B1K[i])\n",
    "    else:\n",
    "        intronless_file_B1K.write(intronless_B1K[i] + '\\n')\n",
    "intronless_file_B1K.close()\n",
    "\n",
    "for i in range(len(intronpoor_B1K)):\n",
    "    if i == len(intronpoor_B1K) -1:\n",
    "        intronpoor_file_B1K.write(intronpoor_B1K[i])\n",
    "    else:\n",
    "        intronpoor_file_B1K.write(intronpoor_B1K[i] + '\\n')\n",
    "intronpoor_file_B1K.close()\n",
    "\n",
    "for i in range(len(intronrich_B1K)):\n",
    "    if i == len(intronrich_B1K) -1:\n",
    "        intronrich_file_B1K.write(intronrich_B1K[i])\n",
    "    else:\n",
    "        intronrich_file_B1K.write(intronrich_B1K[i]+'\\n')\n",
    "intronrich_file_B1K.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Storing the number of transcripts in intron-less/poor/rich genes within a variable \n",
    "n_mRNA_intronless_B1K = ! grep -f Output/B1K_intronlessIDs.txt Data/B1K_nohashtag.gff3 | awk -F '\\t' '{print $3}' | grep -w 'mRNA' | wc -l\n",
    "n_mRNA_intronpoor_B1K = ! grep -f Output/B1K_intronpoorIDs.txt Data/B1K_nohashtag.gff3 | awk -F '\\t' '{print $3}' | grep -w 'mRNA' | wc -l\n",
    "n_mRNA_intronrich_B1K = ! grep -f Output/B1K_intronrichIDs.txt Data/B1K_nohashtag.gff3 | awk -F '\\t' '{print $3}' | grep -w 'mRNA' | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Checking the average number of transcripts for each gene-type\n",
    "avg_mRNA_intronless_B1K = int(n_mRNA_intronless_B1K[0])/n_intronless_B1K\n",
    "print(avg_mRNA_intronless_B1K)\n",
    "avg_mRNA_intronpoor_B1K = int(n_mRNA_intronpoor_B1K[0])/n_intronpoor_B1K\n",
    "print(avg_mRNA_intronpoor_B1K)\n",
    "avg_mRNA_intronrich_B1K = int(n_mRNA_intronrich_B1K[0])/n_intronrich_B1K\n",
    "print(avg_mRNA_intronrich_B1K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### --- Basic statistics of B1K introns\n",
    "introns_B1K['length'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Plotting the distribution of B1K introns length\n",
    "introns_B1K['length'].plot.density()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Plotting the boxplot of B1K introns length without outliers\n",
    "introns_B1K.boxplot(column='length', return_type='axes', showfliers=False) # showfliers = False -> discard outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6.4 Re-organizing files and directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls Data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir Data/B1K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mv Data/B1K_* Data/B1K/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls Data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls Output/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir Output/B1K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mv Output/B1K_* Output/B1K/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls Output/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.7 Barke - Gene projection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.7.1 Data collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- This will download the raw data to the subdirectory raw under the directory Data\n",
    "! wget -O Data/raw/Barke_gp.gff3 https://doi.ipk-gatersleben.de/DOI/c4d433dc-bf7c-4ad9-9368-69bb77837ca5/005e26c4-051b-4fd4-8538-2abe31706449/1/DOWNLOAD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.7.2 Processing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- There is no need to import the libraries again\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Removing all hashtags from the gff3 file\n",
    "! sed '/#/d' Data/raw/Barke_gp.gff3  > Data/Barke_gp_nohashtag.gff3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Changing the gff3 file to a csv format file to import it with pandas\n",
    "! cat Data/Barke_gp_nohashtag.gff3 | sed 's/,/--/g' | sed 's/;/--/g' | sed 's/\\t/,/g' | awk -F '--' '{print $1}' > Data/Barke_gp_nohashtag.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Transforming the gff3 file to a pandas dataframe to better handle it\n",
    "df_Barke_gp = pd.read_csv('Data/Barke_gp_nohashtag.csv', header=None, names = ['chr', 'source', 'type','start','end','score','strand','phase','attributes'])\n",
    "df_Barke_gp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Building a separate dataframe containing all exons\n",
    "exon_Barke_gp = df_Barke_gp.loc[df_Barke_gp['type'].isin(['exon'])]\n",
    "exon_Barke_gp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Exporting the exon dataframe to a tsv file \n",
    "exon_Barke_gp.to_csv('Data/Barke_gp_exon.tsv',sep='\\t',index=False,header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Keeping in a separated dataframe the forward strands\n",
    "forw_Barke_gp = df_Barke_gp.loc[df_Barke_gp['strand'].isin(['+'])]\n",
    "forw_Barke_gp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Keeping in a separated dataframe the reverse strands\n",
    "rev_Barke_gp = df_Barke_gp.loc[df_Barke_gp['strand'].isin(['-'])]\n",
    "rev_Barke_gp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Keeping in a separated dataframe the UTR regions on the forward strands\n",
    "UTR_forw_Barke_gp = forw_Barke_gp.loc[df_Barke_gp['type'].isin(['three_prime_UTR','five_prime_UTR'])]\n",
    "UTR_forw_Barke_gp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Keeping in a separated dataframe the UTR regions on the reverse strands\n",
    "UTR_rev_Barke_gp = rev_Barke_gp.loc[df_Barke_gp['type'].isin(['three_prime_UTR','five_prime_UTR'])]\n",
    "UTR_rev_Barke_gp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No UTRs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.7.3 Extracting introns from the whole genome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Extracting introns from Barke_gp\n",
    "extract_tot_introns_gp('Data/Barke_gp_exon.tsv', 'Output/Barke_gp_introns.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "introns_Barke_gp = pd.read_csv('Output/Barke_gp_introns.tsv', sep = '\\t')\n",
    "introns_Barke_gp[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Counting introns type in Barke_gp\n",
    "introns_dictionary_Barke_gp = counting_introns_type_gp(exon_Barke_gp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_intronless_Barke_gp, n_intronpoor_Barke_gp, n_intronrich_Barke_gp, intronless_Barke_gp, intronpoor_Barke_gp, intronrich_Barke_gp = splitting_introns_type(introns_dictionary_Barke_gp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genes = ['Intronless', 'Intronpoor', 'Intronrich']\n",
    "data_Barke_gp = [17546, 18588, 12078]\n",
    "fig = plt.figure(figsize =(10, 7))\n",
    "plt.pie(data_Barke_gp, labels = genes, autopct='%1.0f%%')\n",
    "plt.title(\"Genes Barke_gp Distribution\", bbox={'facecolor':'0.8', 'pad':5})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Creating the list of Barke_gp gene IDs to check the number of transcripts using command line\n",
    "intronless_file_Barke_gp = open('Output/Barke_gp_intronlessIDs.txt', 'a')\n",
    "intronpoor_file_Barke_gp = open('Output/Barke_gp_intronpoorIDs.txt', 'a')\n",
    "intronrich_file_Barke_gp = open('Output/Barke_gp_intronrichIDs.txt', 'a')\n",
    "for i in range(len(intronless_Barke_gp)):\n",
    "    if i == len(intronless_Barke_gp) -1:\n",
    "        intronless_file_Barke_gp.write(intronless_Barke_gp[i])\n",
    "    else:\n",
    "        intronless_file_Barke_gp.write(intronless_Barke_gp[i] + '\\n')\n",
    "intronless_file_Barke_gp.close()\n",
    "\n",
    "for i in range(len(intronpoor_Barke_gp)):\n",
    "    if i == len(intronpoor_Barke_gp) -1:\n",
    "        intronpoor_file_Barke_gp.write(intronpoor_Barke_gp[i])\n",
    "    else:\n",
    "        intronpoor_file_Barke_gp.write(intronpoor_Barke_gp[i] + '\\n')\n",
    "intronpoor_file_Barke_gp.close()\n",
    "\n",
    "for i in range(len(intronrich_Barke_gp)):\n",
    "    if i == len(intronrich_Barke_gp) -1:\n",
    "        intronrich_file_Barke_gp.write(intronrich_Barke_gp[i])\n",
    "    else:\n",
    "        intronrich_file_Barke_gp.write(intronrich_Barke_gp[i]+'\\n')\n",
    "intronrich_file_Barke_gp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Storing the number of transcripts in intron-less/poor/rich genes within a variable \n",
    "n_mRNA_intronless_Barke_gp = ! grep -f Output/Barke_gp_intronlessIDs.txt Data/Barke_gp_nohashtag.gff3 | awk -F '\\t' '{print $3}' | grep -w 'mRNA' | wc -l\n",
    "n_mRNA_intronpoor_Barke_gp = ! grep -f Output/Barke_gp_intronpoorIDs.txt Data/Barke_gp_nohashtag.gff3 | awk -F '\\t' '{print $3}' | grep -w 'mRNA' | wc -l\n",
    "n_mRNA_intronrich_Barke_gp = ! grep -f Output/Barke_gp_intronrichIDs.txt Data/Barke_gp_nohashtag.gff3 | awk -F '\\t' '{print $3}' | grep -w 'mRNA' | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Checking the average number of transcripts for each gene-type\n",
    "avg_mRNA_intronless_Barke_gp = int(n_mRNA_intronless_Barke_gp[0])/n_intronless_Barke_gp\n",
    "print(avg_mRNA_intronless_Barke_gp)\n",
    "avg_mRNA_intronpoor_Barke_gp = int(n_mRNA_intronpoor_Barke_gp[0])/n_intronpoor_Barke_gp\n",
    "print(avg_mRNA_intronpoor_Barke_gp)\n",
    "avg_mRNA_intronrich_Barke_gp = int(n_mRNA_intronrich_Barke_gp[0])/n_intronrich_Barke_gp\n",
    "print(avg_mRNA_intronrich_Barke_gp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No alternative splicing annotated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Basic statistics of Barke_gp introns\n",
    "introns_Barke_gp['length'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Plotting the distribution of Barke_gp introns length\n",
    "introns_Barke_gp['length'].plot.density()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Plotting the boxplot of Barke_gp introns length without outliers\n",
    "introns_Barke_gp.boxplot(column='length', return_type='axes', showfliers=False) # showfliers = False -> discard outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.7.4 Re-organizing files and directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls Data/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir Data/Barke_gp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mv Data/Barke_gp_* Data/Barke_gp/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "! ls Data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "! ls Output/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 903,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir Output/Barke_gp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mv Output/Barke_gp* Output/Barke_gp/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "! ls Output/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.8 Golden_Promise - Gene projection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.8.1 Data collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### --- This will download the raw data to the subdirectory raw under the directory Data\n",
    "! wget -O Data/raw/Golden_Promise.gff3 https://doi.ipk-gatersleben.de/DOI/c4d433dc-bf7c-4ad9-9368-69bb77837ca5/936e3aac-6846-4b46-ad7f-1432f2ed6ef8/1/DOWNLOAD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.8.2 Processing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- There is no need to import the libraries again\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Removing all hashtags from the gff3 file\n",
    "! sed '/#/d' Data/raw/Golden_Promise.gff3  > Data/Golden_Promise_nohashtag.gff3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Changing the gff3 file to a csv format file to import it with pandas\n",
    "! cat Data/Golden_Promise_nohashtag.gff3 | sed 's/,/--/g' | sed 's/;/--/g' | sed 's/\\t/,/g' | awk -F '--' '{print $1}' > Data/Golden_Promise_nohashtag.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Transforming the gff3 file to a pandas dataframe to better handle it\n",
    "df_Golden_Promise = pd.read_csv('Data/Golden_Promise_nohashtag.csv', header=None, names = ['chr', 'source', 'type','start','end','score','strand','phase','attributes'])\n",
    "df_Golden_Promise.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Building a separate dataframe containing all exons\n",
    "exon_Golden_Promise = df_Golden_Promise.loc[df_Golden_Promise['type'].isin(['exon'])]\n",
    "exon_Golden_Promise.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Exporting the exon dataframe to a tsv file \n",
    "exon_Golden_Promise.to_csv('Data/Golden_Promise_exon.tsv',sep='\\t',index=False,header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Keeping in a separated dataframe the forward strands\n",
    "forw_Golden_Promise = df_Golden_Promise.loc[df_Golden_Promise['strand'].isin(['+'])]\n",
    "forw_Golden_Promise.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Keeping in a separated dataframe the reverse strands\n",
    "rev_Golden_Promise = df_Golden_Promise.loc[df_Golden_Promise['strand'].isin(['-'])]\n",
    "rev_Golden_Promise.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Keeping in a separated dataframe the UTR regions on the forward strands\n",
    "UTR_forw_Golden_Promise = forw_Golden_Promise.loc[df_Golden_Promise['type'].isin(['three_prime_UTR','five_prime_UTR'])]\n",
    "UTR_forw_Golden_Promise.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Keeping in a separated dataframe the UTR regions on the reverse strands\n",
    "UTR_rev_Golden_Promise = rev_Golden_Promise.loc[df_Golden_Promise['type'].isin(['three_prime_UTR','five_prime_UTR'])]\n",
    "UTR_rev_Golden_Promise.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No UTRs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.8.3 Extracting introns from the whole genome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Extracting introns from Golden_Promise\n",
    "extract_tot_introns_gp('Data/Golden_Promise_exon.tsv', 'Output/Golden_Promise_introns.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "introns_Golden_Promise = pd.read_csv('Output/Golden_Promise_introns.tsv', sep = '\\t')\n",
    "introns_Golden_Promise[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Counting introns type in Golden_Promise\n",
    "introns_dictionary_Golden_Promise = counting_introns_type_gp(exon_Golden_Promise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_intronless_Golden_Promise, n_intronpoor_Golden_Promise, n_intronrich_Golden_Promise, intronless_Golden_Promise, intronpoor_Golden_Promise, intronrich_Golden_Promise = splitting_introns_type(introns_dictionary_Golden_Promise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genes = ['Intronless', 'Intronpoor', 'Intronrich']\n",
    "data_Golden_Promise = [14844, 18111, 12129]\n",
    "fig = plt.figure(figsize =(10, 7))\n",
    "plt.pie(data_Golden_Promise, labels = genes, autopct='%1.0f%%')\n",
    "plt.title(\"Genes Golden_Promise Distribution\", bbox={'facecolor':'0.8', 'pad':5})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Creating the list of Golden_Promise gene IDs to check the number of transcripts using command line\n",
    "intronless_file_Golden_Promise = open('Output/Golden_Promise_intronlessIDs.txt', 'a')\n",
    "intronpoor_file_Golden_Promise = open('Output/Golden_Promise_intronpoorIDs.txt', 'a')\n",
    "intronrich_file_Golden_Promise = open('Output/Golden_Promise_intronrichIDs.txt', 'a')\n",
    "for i in range(len(intronless_Golden_Promise)):\n",
    "    if i == len(intronless_Golden_Promise) -1:\n",
    "        intronless_file_Golden_Promise.write(intronless_Golden_Promise[i])\n",
    "    else:\n",
    "        intronless_file_Golden_Promise.write(intronless_Golden_Promise[i] + '\\n')\n",
    "intronless_file_Golden_Promise.close()\n",
    "\n",
    "for i in range(len(intronpoor_Golden_Promise)):\n",
    "    if i == len(intronpoor_Golden_Promise) -1:\n",
    "        intronpoor_file_Golden_Promise.write(intronpoor_Golden_Promise[i])\n",
    "    else:\n",
    "        intronpoor_file_Golden_Promise.write(intronpoor_Golden_Promise[i] + '\\n')\n",
    "intronpoor_file_Golden_Promise.close()\n",
    "\n",
    "for i in range(len(intronrich_Golden_Promise)):\n",
    "    if i == len(intronrich_Golden_Promise) -1:\n",
    "        intronrich_file_Golden_Promise.write(intronrich_Golden_Promise[i])\n",
    "    else:\n",
    "        intronrich_file_Golden_Promise.write(intronrich_Golden_Promise[i]+'\\n')\n",
    "intronrich_file_Golden_Promise.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Storing the number of transcripts in intron-less/poor/rich genes within a variable \n",
    "n_mRNA_intronless_Golden_Promise = ! grep -f Output/Golden_Promise_intronlessIDs.txt Data/Golden_Promise_nohashtag.gff3 | awk -F '\\t' '{print $3}' | grep -w 'mRNA' | wc -l\n",
    "n_mRNA_intronpoor_Golden_Promise = ! grep -f Output/Golden_Promise_intronpoorIDs.txt Data/Golden_Promise_nohashtag.gff3 | awk -F '\\t' '{print $3}' | grep -w 'mRNA' | wc -l\n",
    "n_mRNA_intronrich_Golden_Promise = ! grep -f Output/Golden_Promise_intronrichIDs.txt Data/Golden_Promise_nohashtag.gff3 | awk -F '\\t' '{print $3}' | grep -w 'mRNA' | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Checking the average number of transcripts for each gene-type\n",
    "avg_mRNA_intronless_Golden_Promise = int(n_mRNA_intronless_Golden_Promise[0])/n_intronless_Golden_Promise\n",
    "print(avg_mRNA_intronless_Golden_Promise)\n",
    "avg_mRNA_intronpoor_Golden_Promise = int(n_mRNA_intronpoor_Golden_Promise[0])/n_intronpoor_Golden_Promise\n",
    "print(avg_mRNA_intronpoor_Golden_Promise)\n",
    "avg_mRNA_intronrich_Golden_Promise = int(n_mRNA_intronrich_Golden_Promise[0])/n_intronrich_Golden_Promise\n",
    "print(avg_mRNA_intronrich_Golden_Promise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No alternative splicing annotated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Basic statistics of Golden_Promise introns\n",
    "introns_Golden_Promise['length'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Plotting the distribution of Golden_Promise introns length\n",
    "introns_Golden_Promise['length'].plot.density()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Plotting the boxplot of Golden_Promise introns length without outliers\n",
    "introns_Golden_Promise.boxplot(column='length', return_type='axes', showfliers=False) # showfliers = False -> discard outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.8.4 Re-organizing files and directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls Data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir Data/Golden_Promise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mv Data/Golden_Promise_* Data/Golden_Promise/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls Data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls Output/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir Output/Golden_Promise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mv Output/Golden_Promise_* Output/Golden_Promise/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls Output/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.9 Hockett - Gene projection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.9.1 Data collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- This will download the raw data to the subdirectory raw under the directory Data\n",
    "! wget -O Data/raw/Hockett.gff3 https://doi.ipk-gatersleben.de/DOI/c4d433dc-bf7c-4ad9-9368-69bb77837ca5/135d31f9-c030-4e95-9c50-bc61746d2721/1/DOWNLOAD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.9.2 Processing Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- There is no need to import the libraries again\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Removing all hashtags from the gff3 file\n",
    "! sed '/#/d' Data/raw/Hockett.gff3  > Data/Hockett_nohashtag.gff3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Changing the gff3 file to a csv format file to import it with pandas\n",
    "! cat Data/Hockett_nohashtag.gff3 | sed 's/,/--/g' | sed 's/;/--/g' | sed 's/\\t/,/g' | awk -F '--' '{print $1}' > Data/Hockett_nohashtag.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Transforming the gff3 file to a pandas dataframe to better handle it\n",
    "df_Hockett = pd.read_csv('Data/Hockett_nohashtag.csv', header=None, names = ['chr', 'source', 'type','start','end','score','strand','phase','attributes'])\n",
    "df_Hockett.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Building a separate dataframe containing all exons\n",
    "exon_Hockett = df_Hockett.loc[df_Hockett['type'].isin(['exon'])]\n",
    "exon_Hockett.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Exporting the exon dataframe to a tsv file \n",
    "exon_Hockett.to_csv('Data/Hockett_exon.tsv',sep='\\t',index=False,header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Keeping in a separated dataframe the forward strands\n",
    "forw_Hockett = df_Hockett.loc[df_Hockett['strand'].isin(['+'])]\n",
    "forw_Hockett.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Keeping in a separated dataframe the reverse strands\n",
    "rev_Hockett = df_Hockett.loc[df_Hockett['strand'].isin(['-'])]\n",
    "rev_Hockett.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Keeping in a separated dataframe the UTR regions on the forward strands\n",
    "UTR_forw_Hockett = forw_Hockett.loc[df_Hockett['type'].isin(['three_prime_UTR','five_prime_UTR'])]\n",
    "UTR_forw_Hockett.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Keeping in a separated dataframe the UTR regions on the reverse strands\n",
    "UTR_rev_Hockett = rev_Hockett.loc[df_Hockett['type'].isin(['three_prime_UTR','five_prime_UTR'])]\n",
    "UTR_rev_Hockett.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No UTRs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.9.3   Extracting introns from the whole genome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Extracting introns from Hockett\n",
    "extract_tot_introns_gp('Data/Hockett_exon.tsv', 'Output/Hockett_introns.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "introns_Hockett = pd.read_csv('Output/Hockett_introns.tsv', sep = '\\t')\n",
    "introns_Hockett[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Counting introns type in Hockett\n",
    "introns_dictionary_Hockett = counting_introns_type_gp(exon_Hockett)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_intronless_Hockett, n_intronpoor_Hockett, n_intronrich_Hockett, intronless_Hockett, intronpoor_Hockett, intronrich_Hockett = splitting_introns_type(introns_dictionary_Hockett)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- I decided to create a function to plot the pie representing the distribution of intronless/poor/rich\n",
    "def plotting_intron_types(n_intronless, n_intronpoor, n_intronrich, title):\n",
    "    genes = ['Intronless', 'Intronpoor', 'Intronrich']\n",
    "    data = [n_intronless, n_intronpoor, n_intronrich]\n",
    "    fig = plt.figure(figsize = (10,7))\n",
    "    plt.pie(data, labels = genes, autopct='%1.0f%%')\n",
    "    plt.title(title, bbox={'facecolor':'0.8', 'pad':5})\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting_intron_types(n_intronless_Hockett, n_intronpoor_Hockett, n_intronrich_Hockett, 'Genes Hockett Distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Creating the list of Hockett gene IDs to check the number of transcripts using command line\n",
    "intronless_file_Hockett = open('Output/Hockett_intronlessIDs.txt', 'a')\n",
    "intronpoor_file_Hockett = open('Output/Hockett_intronpoorIDs.txt', 'a')\n",
    "intronrich_file_Hockett = open('Output/Hockett_intronrichIDs.txt', 'a')\n",
    "for i in range(len(intronless_Hockett)):\n",
    "    if i == len(intronless_Hockett) -1:\n",
    "        intronless_file_Hockett.write(intronless_Hockett[i])\n",
    "    else:\n",
    "        intronless_file_Hockett.write(intronless_Hockett[i] + '\\n')\n",
    "intronless_file_Hockett.close()\n",
    "\n",
    "for i in range(len(intronpoor_Hockett)):\n",
    "    if i == len(intronpoor_Hockett) -1:\n",
    "        intronpoor_file_Hockett.write(intronpoor_Hockett[i])\n",
    "    else:\n",
    "        intronpoor_file_Hockett.write(intronpoor_Hockett[i] + '\\n')\n",
    "intronpoor_file_Hockett.close()\n",
    "\n",
    "for i in range(len(intronrich_Hockett)):\n",
    "    if i == len(intronrich_Hockett) -1:\n",
    "        intronrich_file_Hockett.write(intronrich_Hockett[i])\n",
    "    else:\n",
    "        intronrich_file_Hockett.write(intronrich_Hockett[i]+'\\n')\n",
    "intronrich_file_Hockett.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Storing the number of transcripts in intron-less/poor/rich genes within a variable \n",
    "n_mRNA_intronless_Hockett = ! grep -f Output/Hockett_intronlessIDs.txt Data/Hockett_nohashtag.gff3 | awk -F '\\t' '{print $3}' | grep -w 'mRNA' | wc -l\n",
    "n_mRNA_intronpoor_Hockett = ! grep -f Output/Hockett_intronpoorIDs.txt Data/Hockett_nohashtag.gff3 | awk -F '\\t' '{print $3}' | grep -w 'mRNA' | wc -l\n",
    "n_mRNA_intronrich_Hockett = ! grep -f Output/Hockett_intronrichIDs.txt Data/Hockett_nohashtag.gff3 | awk -F '\\t' '{print $3}' | grep -w 'mRNA' | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### --- Checking the average number of transcripts for each gene-type\n",
    "avg_mRNA_intronless_Hockett = int(n_mRNA_intronless_Hockett[0])/n_intronless_Hockett\n",
    "print(avg_mRNA_intronless_Hockett)\n",
    "avg_mRNA_intronpoor_Hockett = int(n_mRNA_intronpoor_Hockett[0])/n_intronpoor_Hockett\n",
    "print(avg_mRNA_intronpoor_Hockett)\n",
    "avg_mRNA_intronrich_Hockett = int(n_mRNA_intronrich_Hockett[0])/n_intronrich_Hockett\n",
    "print(avg_mRNA_intronrich_Hockett)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No alternative splicing annotated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Basic statistics of Hockett introns\n",
    "introns_Hockett['length'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Plotting the distribution of Hockett introns length\n",
    "introns_Hockett['length'].plot.density()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Plotting the boxplot of Hockett introns length without outliers\n",
    "introns_Hockett.boxplot(column='length', return_type='axes', showfliers=False) # showfliers = False -> discard outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.9.4 Re-organizing files and directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls Data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir Data/Hockett"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mv Data/Hockett_* Data/Hockett/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls Data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls Output/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir Output/Hockett"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mv Output/Hockett_* Output/Hockett/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls Output/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.10 HOR10350 - Gene projection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.10.1 Data collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- This will download the raw data to the subdirectory raw under the directory Data\n",
    "! wget -O Data/raw/HOR10350_gp.gff3 https://doi.ipk-gatersleben.de/DOI/c4d433dc-bf7c-4ad9-9368-69bb77837ca5/a909ad41-c116-4131-bf79-6e760c2cd723/1/DOWNLOAD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.10.2 Processing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- There is no need to import the libraries again\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Removing all hashtags from the gff3 file\n",
    "! sed '/#/d' Data/raw/HOR10350_gp.gff3  > Data/HOR10350_gp_nohashtag.gff3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Changing the gff3 file to a csv format file to import it with pandas\n",
    "! cat Data/HOR10350_gp_nohashtag.gff3 | sed 's/,/--/g' | sed 's/;/--/g' | sed 's/\\t/,/g' | awk -F '--' '{print $1}' > Data/HOR10350_gp_nohashtag.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Transforming the gff3 file to a pandas dataframe to better handle it\n",
    "df_HOR10350_gp = pd.read_csv('Data/HOR10350_gp_nohashtag.csv', header=None, names = ['chr', 'source', 'type','start','end','score','strand','phase','attributes'])\n",
    "df_HOR10350_gp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Building a separate dataframe containing all exons\n",
    "exon_HOR10350_gp = df_HOR10350_gp.loc[df_HOR10350_gp['type'].isin(['exon'])]\n",
    "exon_HOR10350_gp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Exporting the exon dataframe to a tsv file \n",
    "exon_HOR10350_gp.to_csv('Data/HOR10350_gp_exon.tsv',sep='\\t',index=False,header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Keeping in a separated dataframe the forward strands\n",
    "forw_HOR10350_gp = df_HOR10350_gp.loc[df_HOR10350_gp['strand'].isin(['+'])]\n",
    "forw_HOR10350_gp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Keeping in a separated dataframe the reverse strands\n",
    "rev_HOR10350_gp = df_HOR10350_gp.loc[df_HOR10350_gp['strand'].isin(['-'])]\n",
    "rev_HOR10350_gp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Keeping in a separated dataframe the UTR regions on the forward strands\n",
    "UTR_forw_HOR10350_gp = forw_HOR10350_gp.loc[df_HOR10350_gp['type'].isin(['three_prime_UTR','five_prime_UTR'])]\n",
    "UTR_forw_HOR10350_gp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Keeping in a separated dataframe the UTR regions on the reverse strands\n",
    "UTR_rev_HOR10350_gp = rev_HOR10350_gp.loc[df_HOR10350_gp['type'].isin(['three_prime_UTR','five_prime_UTR'])]\n",
    "UTR_rev_HOR10350_gp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No UTRs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.10.3 Extracting introns from the whole genome "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Extracting introns from HOR10350_gp\n",
    "extract_tot_introns_gp('Data/HOR10350_gp_exon.tsv', 'Output/HOR10350_gp_introns.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "introns_HOR10350_gp = pd.read_csv('Output/HOR10350_gp_introns.tsv', sep = '\\t')\n",
    "introns_HOR10350_gp[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Counting introns type in HOR10350_gp\n",
    "introns_dictionary_HOR10350_gp = counting_introns_type_gp(exon_HOR10350_gp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_intronless_HOR10350_gp, n_intronpoor_HOR10350_gp, n_intronrich_HOR10350_gp, intronless_HOR10350_gp, intronpoor_HOR10350_gp, intronrich_HOR10350_gp = splitting_introns_type(introns_dictionary_HOR10350_gp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plotting_intron_types(n_intronless_HOR10350_gp, n_intronpoor_HOR10350_gp, n_intronrich_HOR10350_gp, 'Genes HOR10350_gp Distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Creating the list of HOR10350_gp gene IDs to check the number of transcripts using command line\n",
    "intronless_file_HOR10350_gp = open('Output/HOR10350_gp_intronlessIDs.txt', 'a')\n",
    "intronpoor_file_HOR10350_gp = open('Output/HOR10350_gp_intronpoorIDs.txt', 'a')\n",
    "intronrich_file_HOR10350_gp = open('Output/HOR10350_gp_intronrichIDs.txt', 'a')\n",
    "for i in range(len(intronless_HOR10350_gp)):\n",
    "    if i == len(intronless_HOR10350_gp) -1:\n",
    "        intronless_file_HOR10350_gp.write(intronless_HOR10350_gp[i])\n",
    "    else:\n",
    "        intronless_file_HOR10350_gp.write(intronless_HOR10350_gp[i] + '\\n')\n",
    "intronless_file_HOR10350_gp.close()\n",
    "\n",
    "for i in range(len(intronpoor_HOR10350_gp)):\n",
    "    if i == len(intronpoor_HOR10350_gp) -1:\n",
    "        intronpoor_file_HOR10350_gp.write(intronpoor_HOR10350_gp[i])\n",
    "    else:\n",
    "        intronpoor_file_HOR10350_gp.write(intronpoor_HOR10350_gp[i] + '\\n')\n",
    "intronpoor_file_HOR10350_gp.close()\n",
    "\n",
    "for i in range(len(intronrich_HOR10350_gp)):\n",
    "    if i == len(intronrich_HOR10350_gp) -1:\n",
    "        intronrich_file_HOR10350_gp.write(intronrich_HOR10350_gp[i])\n",
    "    else:\n",
    "        intronrich_file_HOR10350_gp.write(intronrich_HOR10350_gp[i]+'\\n')\n",
    "intronrich_file_HOR10350_gp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Storing the number of transcripts in intron-less/poor/rich genes within a variable \n",
    "n_mRNA_intronless_HOR10350_gp = ! grep -f Output/HOR10350_gp_intronlessIDs.txt Data/HOR10350_gp_nohashtag.gff3 | awk -F '\\t' '{print $3}' | grep -w 'mRNA' | wc -l\n",
    "n_mRNA_intronpoor_HOR10350_gp = ! grep -f Output/HOR10350_gp_intronpoorIDs.txt Data/HOR10350_gp_nohashtag.gff3 | awk -F '\\t' '{print $3}' | grep -w 'mRNA' | wc -l\n",
    "n_mRNA_intronrich_HOR10350_gp = ! grep -f Output/HOR10350_gp_intronrichIDs.txt Data/HOR10350_gp_nohashtag.gff3 | awk -F '\\t' '{print $3}' | grep -w 'mRNA' | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### --- Checking the average number of transcripts for each gene-type\n",
    "avg_mRNA_intronless_HOR10350_gp = int(n_mRNA_intronless_HOR10350_gp[0])/n_intronless_HOR10350_gp\n",
    "print(avg_mRNA_intronless_HOR10350_gp)\n",
    "avg_mRNA_intronpoor_HOR10350_gp = int(n_mRNA_intronpoor_HOR10350_gp[0])/n_intronpoor_HOR10350_gp\n",
    "print(avg_mRNA_intronpoor_HOR10350_gp)\n",
    "avg_mRNA_intronrich_HOR10350_gp = int(n_mRNA_intronrich_HOR10350_gp[0])/n_intronrich_HOR10350_gp\n",
    "print(avg_mRNA_intronrich_HOR10350_gp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No alternative splicing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Basic statistics of HOR10350_gp introns\n",
    "introns_HOR10350_gp['length'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Plotting the distribution of HOR10350_gp introns length\n",
    "introns_HOR10350_gp['length'].plot.density()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Plotting the boxplot of HOR10350_gp introns length without outliers\n",
    "introns_HOR10350_gp.boxplot(column='length', return_type='axes', showfliers=False) # showfliers = False -> discard outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.10.4 Re-organizing files and directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls Data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir Data/HOR10350_gp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mv Data/HOR10350_gp_* Data/HOR10350_gp/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls Data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls Output/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir Output/HOR10350_gp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mv Output/HOR10350_gp_* Output/HOR10350_gp/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls Output/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.11 HOR13821 - Gene projection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.11.1 Data collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- This will download the raw data to the subdirectory raw under the directory Data\n",
    "! wget -O Data/raw/HOR13821.gff3 https://doi.ipk-gatersleben.de/DOI/c4d433dc-bf7c-4ad9-9368-69bb77837ca5/da44be98-0ede-4283-872a-817d33212ff0/1/DOWNLOAD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.11.2 Processing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- There is no need to import the libraries again\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Removing all hashtags from the gff3 file\n",
    "! sed '/#/d' Data/raw/HOR13821.gff3  > Data/HOR13821_nohashtag.gff3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Changing the gff3 file to a csv format file to import it with pandas\n",
    "! cat Data/HOR13821_nohashtag.gff3 | sed 's/,/--/g' | sed 's/;/--/g' | sed 's/\\t/,/g' | awk -F '--' '{print $1}' > Data/HOR13821_nohashtag.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Transforming the gff3 file to a pandas dataframe to better handle it\n",
    "df_HOR13821 = pd.read_csv('Data/HOR13821_nohashtag.csv', header=None, names = ['chr', 'source', 'type','start','end','score','strand','phase','attributes'])\n",
    "df_HOR13821.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Building a separate dataframe containing all exons\n",
    "exon_HOR13821 = df_HOR13821.loc[df_HOR13821['type'].isin(['exon'])]\n",
    "exon_HOR13821.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Exporting the exon dataframe to a tsv file \n",
    "exon_HOR13821.to_csv('Data/HOR13821_exon.tsv',sep='\\t',index=False,header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Keeping in a separated dataframe the forward strands\n",
    "forw_HOR13821 = df_HOR13821.loc[df_HOR13821['strand'].isin(['+'])]\n",
    "forw_HOR13821.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Keeping in a separated dataframe the reverse strands\n",
    "rev_HOR13821 = df_HOR13821.loc[df_HOR13821['strand'].isin(['-'])]\n",
    "rev_HOR13821.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Keeping in a separated dataframe the UTR regions on the forward strands\n",
    "UTR_forw_HOR13821 = forw_HOR13821.loc[df_HOR13821['type'].isin(['three_prime_UTR','five_prime_UTR'])]\n",
    "UTR_forw_HOR13821.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Keeping in a separated dataframe the UTR regions on the reverse strands\n",
    "UTR_rev_HOR13821 = rev_HOR13821.loc[df_HOR13821['type'].isin(['three_prime_UTR','five_prime_UTR'])]\n",
    "UTR_rev_HOR13821.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No UTRs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.11.3 Extracting introns from the whole genome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Extracting introns from HOR13821\n",
    "extract_tot_introns_gp('Data/HOR13821_exon.tsv', 'Output/HOR13821_introns.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "introns_HOR13821 = pd.read_csv('Output/HOR13821_introns.tsv', sep = '\\t')\n",
    "introns_HOR13821[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Counting introns type in HOR13821\n",
    "introns_dictionary_HOR13821 = counting_introns_type_gp(exon_HOR13821)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_intronless_HOR13821, n_intronpoor_HOR13821, n_intronrich_HOR13821, intronless_HOR13821, intronpoor_HOR13821, intronrich_HOR13821 = splitting_introns_type(introns_dictionary_HOR13821)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting_intron_types(n_intronless_HOR13821, n_intronpoor_HOR13821, n_intronrich_HOR13821, 'Genes HOR13821 Distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Creating the list of HOR13821 gene IDs to check the number of transcripts using command line\n",
    "intronless_file_HOR13821 = open('Output/HOR13821_intronlessIDs.txt', 'a')\n",
    "intronpoor_file_HOR13821 = open('Output/HOR13821_intronpoorIDs.txt', 'a')\n",
    "intronrich_file_HOR13821 = open('Output/HOR13821_intronrichIDs.txt', 'a')\n",
    "for i in range(len(intronless_HOR13821)):\n",
    "    if i == len(intronless_HOR13821) -1:\n",
    "        intronless_file_HOR13821.write(intronless_HOR13821[i])\n",
    "    else:\n",
    "        intronless_file_HOR13821.write(intronless_HOR13821[i] + '\\n')\n",
    "intronless_file_HOR13821.close()\n",
    "\n",
    "for i in range(len(intronpoor_HOR13821)):\n",
    "    if i == len(intronpoor_HOR13821) -1:\n",
    "        intronpoor_file_HOR13821.write(intronpoor_HOR13821[i])\n",
    "    else:\n",
    "        intronpoor_file_HOR13821.write(intronpoor_HOR13821[i] + '\\n')\n",
    "intronpoor_file_HOR13821.close()\n",
    "\n",
    "for i in range(len(intronrich_HOR13821)):\n",
    "    if i == len(intronrich_HOR13821) -1:\n",
    "        intronrich_file_HOR13821.write(intronrich_HOR13821[i])\n",
    "    else:\n",
    "        intronrich_file_HOR13821.write(intronrich_HOR13821[i]+'\\n')\n",
    "intronrich_file_HOR13821.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Storing the number of transcripts in intron-less/poor/rich genes within a variable \n",
    "n_mRNA_intronless_HOR13821 = ! grep -f Output/HOR13821_intronlessIDs.txt Data/HOR13821_nohashtag.gff3 | awk -F '\\t' '{print $3}' | grep -w 'mRNA' | wc -l\n",
    "n_mRNA_intronpoor_HOR13821 = ! grep -f Output/HOR13821_intronpoorIDs.txt Data/HOR13821_nohashtag.gff3 | awk -F '\\t' '{print $3}' | grep -w 'mRNA' | wc -l\n",
    "n_mRNA_intronrich_HOR13821 = ! grep -f Output/HOR13821_intronrichIDs.txt Data/HOR13821_nohashtag.gff3 | awk -F '\\t' '{print $3}' | grep -w 'mRNA' | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Checking the average number of transcripts for each gene-type\n",
    "avg_mRNA_intronless_HOR13821 = int(n_mRNA_intronless_HOR13821[0])/n_intronless_HOR13821\n",
    "print(avg_mRNA_intronless_HOR13821)\n",
    "avg_mRNA_intronpoor_HOR13821 = int(n_mRNA_intronpoor_HOR13821[0])/n_intronpoor_HOR13821\n",
    "print(avg_mRNA_intronpoor_HOR13821)\n",
    "avg_mRNA_intronrich_HOR13821 = int(n_mRNA_intronrich_HOR13821[0])/n_intronrich_HOR13821\n",
    "print(avg_mRNA_intronrich_HOR13821)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No alternative splicing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Basic statistics of HOR13821 introns\n",
    "introns_HOR13821['length'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Plotting the distribution of HOR13821 introns length\n",
    "introns_HOR13821['length'].plot.density()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Plotting the boxplot of HOR13821 introns length without outliers\n",
    "introns_HOR13821.boxplot(column='length', return_type='axes', showfliers=False) # showfliers = False -> discard outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.11.4 Re-organizing files and directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls Data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir Data/HOR13821 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mv Data/HOR13821_* Data/HOR13821/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls Data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls Output/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir Output/HOR13821"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mv Output/HOR13821_* Output/HOR13821/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls Output/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.12 HOR13942 - Gene projection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.12.1 Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- This will download the raw data to the subdirectory raw under the directory Data\n",
    "! wget -O Data/raw/HOR13942.gff3 https://doi.ipk-gatersleben.de/DOI/c4d433dc-bf7c-4ad9-9368-69bb77837ca5/e2980ffc-4e10-4812-a1d5-90b0b27f2b9a/1/DOWNLOAD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.12.2 Processing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- There is no need to import the libraries again\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Removing all hashtags from the gff3 file\n",
    "! sed '/#/d' Data/raw/HOR13942.gff3  > Data/HOR13942_nohashtag.gff3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Changing the gff3 file to a csv format file to import it with pandas\n",
    "! cat Data/HOR13942_nohashtag.gff3 | sed 's/,/--/g' | sed 's/;/--/g' | sed 's/\\t/,/g' | awk -F '--' '{print $1}' > Data/HOR13942_nohashtag.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Transforming the gff3 file to a pandas dataframe to better handle it\n",
    "df_HOR13942 = pd.read_csv('Data/HOR13942_nohashtag.csv', header=None, names = ['chr', 'source', 'type','start','end','score','strand','phase','attributes'])\n",
    "df_HOR13942.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Building a separate dataframe containing all exons\n",
    "exon_HOR13942 = df_HOR13942.loc[df_HOR13942['type'].isin(['exon'])]\n",
    "exon_HOR13942.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Exporting the exon dataframe to a tsv file \n",
    "exon_HOR13942.to_csv('Data/HOR13942_exon.tsv',sep='\\t',index=False,header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Keeping in a separated dataframe the forward strands\n",
    "forw_HOR13942 = df_HOR13942.loc[df_HOR13942['strand'].isin(['+'])]\n",
    "forw_HOR13942.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Keeping in a separated dataframe the reverse strands\n",
    "rev_HOR13942 = df_HOR13942.loc[df_HOR13942['strand'].isin(['-'])]\n",
    "rev_HOR13942.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Keeping in a separated dataframe the UTR regions on the forward strands\n",
    "UTR_forw_HOR13942 = forw_HOR13942.loc[df_HOR13942['type'].isin(['three_prime_UTR','five_prime_UTR'])]\n",
    "UTR_forw_HOR13942.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Keeping in a separated dataframe the UTR regions on the reverse strands\n",
    "UTR_rev_HOR13942 = rev_HOR13942.loc[df_HOR13942['type'].isin(['three_prime_UTR','five_prime_UTR'])]\n",
    "UTR_rev_HOR13942.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No UTRs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.12.3 Extracting introns from the whole genome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Extracting introns from HOR13942\n",
    "extract_tot_introns_gp('Data/HOR13942_exon.tsv', 'Output/HOR13942_introns.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "introns_HOR13942 = pd.read_csv('Output/HOR13942_introns.tsv', sep = '\\t')\n",
    "introns_HOR13942[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Counting introns type in HOR13942\n",
    "introns_dictionary_HOR13942 = counting_introns_type_gp(exon_HOR13942)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_intronless_HOR13942, n_intronpoor_HOR13942, n_intronrich_HOR13942, intronless_HOR13942, intronpoor_HOR13942, intronrich_HOR13942 = splitting_introns_type(introns_dictionary_HOR13942)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting_intron_types(n_intronless_HOR13942, n_intronpoor_HOR13942, n_intronrich_HOR13942, 'Genes HOR13942 Distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Creating the list of HOR13942 gene IDs to check the number of transcripts using command line\n",
    "intronless_file_HOR13942 = open('Output/HOR13942_intronlessIDs.txt', 'a')\n",
    "intronpoor_file_HOR13942 = open('Output/HOR13942_intronpoorIDs.txt', 'a')\n",
    "intronrich_file_HOR13942 = open('Output/HOR13942_intronrichIDs.txt', 'a')\n",
    "for i in range(len(intronless_HOR13942)):\n",
    "    if i == len(intronless_HOR13942) -1:\n",
    "        intronless_file_HOR13942.write(intronless_HOR13942[i])\n",
    "    else:\n",
    "        intronless_file_HOR13942.write(intronless_HOR13942[i] + '\\n')\n",
    "intronless_file_HOR13942.close()\n",
    "\n",
    "for i in range(len(intronpoor_HOR13942)):\n",
    "    if i == len(intronpoor_HOR13942) -1:\n",
    "        intronpoor_file_HOR13942.write(intronpoor_HOR13942[i])\n",
    "    else:\n",
    "        intronpoor_file_HOR13942.write(intronpoor_HOR13942[i] + '\\n')\n",
    "intronpoor_file_HOR13942.close()\n",
    "\n",
    "for i in range(len(intronrich_HOR13942)):\n",
    "    if i == len(intronrich_HOR13942) -1:\n",
    "        intronrich_file_HOR13942.write(intronrich_HOR13942[i])\n",
    "    else:\n",
    "        intronrich_file_HOR13942.write(intronrich_HOR13942[i]+'\\n')\n",
    "intronrich_file_HOR13942.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Storing the number of transcripts in intron-less/poor/rich genes within a variable \n",
    "n_mRNA_intronless_HOR13942 = ! grep -f Output/HOR13942_intronlessIDs.txt Data/HOR13942_nohashtag.gff3 | awk -F '\\t' '{print $3}' | grep -w 'mRNA' | wc -l\n",
    "n_mRNA_intronpoor_HOR13942 = ! grep -f Output/HOR13942_intronpoorIDs.txt Data/HOR13942_nohashtag.gff3 | awk -F '\\t' '{print $3}' | grep -w 'mRNA' | wc -l\n",
    "n_mRNA_intronrich_HOR13942 = ! grep -f Output/HOR13942_intronrichIDs.txt Data/HOR13942_nohashtag.gff3 | awk -F '\\t' '{print $3}' | grep -w 'mRNA' | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Checking the average number of transcripts for each gene-type\n",
    "avg_mRNA_intronless_HOR13942 = int(n_mRNA_intronless_HOR13942[0])/n_intronless_HOR13942\n",
    "print(avg_mRNA_intronless_HOR13942)\n",
    "avg_mRNA_intronpoor_HOR13942 = int(n_mRNA_intronpoor_HOR13942[0])/n_intronpoor_HOR13942\n",
    "print(avg_mRNA_intronpoor_HOR13942)\n",
    "avg_mRNA_intronrich_HOR13942 = int(n_mRNA_intronrich_HOR13942[0])/n_intronrich_HOR13942\n",
    "print(avg_mRNA_intronrich_HOR13942)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Basic statistics of HOR13942 introns\n",
    "introns_HOR13942['length'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Plotting the distribution of HOR13942 introns length\n",
    "introns_HOR13942['length'].plot.density()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Plotting the boxplot of HOR13942 introns length without outliers\n",
    "introns_HOR13942.boxplot(column='length', return_type='axes', showfliers=False) # showfliers = False -> discard outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.12.4 Re-organizing files and directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls Data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir Data/HOR13942"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mv Data/HOR13942_* Data/HOR13942/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls Data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls Output/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir Output/HOR13942"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mv Output/HOR13942_* Output/HOR13942/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls Output/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.13 HOR21599 - Gene projection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.13.1 Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- This will download the raw data to the subdirectory raw under the directory Data\n",
    "! wget -O Data/raw/HOR21599.gff3 https://doi.ipk-gatersleben.de/DOI/c4d433dc-bf7c-4ad9-9368-69bb77837ca5/23c55a21-9a5e-4edf-9ce3-ac3780213e4a/1/DOWNLOAD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.13.2 Processing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- There is no need to import the libraries again\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Removing all hashtags from the gff3 file\n",
    "! sed '/#/d' Data/raw/HOR21599.gff3  > Data/HOR21599_nohashtag.gff3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Changing the gff3 file to a csv format file to import it with pandas\n",
    "! cat Data/HOR21599_nohashtag.gff3 | sed 's/,/--/g' | sed 's/;/--/g' | sed 's/\\t/,/g' | awk -F '--' '{print $1}' > Data/HOR21599_nohashtag.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Transforming the gff3 file to a pandas dataframe to better handle it\n",
    "df_HOR21599 = pd.read_csv('Data/HOR21599_nohashtag.csv', header=None, names = ['chr', 'source', 'type','start','end','score','strand','phase','attributes'])\n",
    "df_HOR21599.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Building a separate dataframe containing all exons\n",
    "exon_HOR21599 = df_HOR21599.loc[df_HOR21599['type'].isin(['exon'])]\n",
    "exon_HOR21599.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Exporting the exon dataframe to a tsv file \n",
    "exon_HOR21599.to_csv('Data/HOR21599_exon.tsv',sep='\\t',index=False,header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Keeping in a separated dataframe the forward strands\n",
    "forw_HOR21599 = df_HOR21599.loc[df_HOR21599['strand'].isin(['+'])]\n",
    "forw_HOR21599.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Keeping in a separated dataframe the reverse strands\n",
    "rev_HOR21599 = df_HOR21599.loc[df_HOR21599['strand'].isin(['-'])]\n",
    "rev_HOR21599.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Keeping in a separated dataframe the UTR regions on the forward strands\n",
    "UTR_forw_HOR21599 = forw_HOR21599.loc[df_HOR21599['type'].isin(['three_prime_UTR','five_prime_UTR'])]\n",
    "UTR_forw_HOR21599.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Keeping in a separated dataframe the UTR regions on the reverse strands\n",
    "UTR_rev_HOR21599 = rev_HOR21599.loc[df_HOR21599['type'].isin(['three_prime_UTR','five_prime_UTR'])]\n",
    "UTR_rev_HOR21599.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No UTRs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.13.3 Extracting introns from the whole genome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Extracting introns from HOR21599\n",
    "extract_tot_introns_gp('Data/HOR21599_exon.tsv', 'Output/HOR21599_introns.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "introns_HOR21599 = pd.read_csv('Output/HOR21599_introns.tsv', sep = '\\t')\n",
    "introns_HOR21599[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Counting introns type in HOR21599\n",
    "introns_dictionary_HOR21599 = counting_introns_type_gp(exon_HOR21599)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_intronless_HOR21599, n_intronpoor_HOR21599, n_intronrich_HOR21599, intronless_HOR21599, intronpoor_HOR21599, intronrich_HOR21599 = splitting_introns_type(introns_dictionary_HOR21599)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting_intron_types(n_intronless_HOR21599, n_intronpoor_HOR21599, n_intronrich_HOR21599, 'Genes HOR21599 Distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Creating the list of HOR21599 gene IDs to check the number of transcripts using command line\n",
    "intronless_file_HOR21599 = open('Output/HOR21599_intronlessIDs.txt', 'a')\n",
    "intronpoor_file_HOR21599 = open('Output/HOR21599_intronpoorIDs.txt', 'a')\n",
    "intronrich_file_HOR21599 = open('Output/HOR21599_intronrichIDs.txt', 'a')\n",
    "for i in range(len(intronless_HOR21599)):\n",
    "    if i == len(intronless_HOR21599) -1:\n",
    "        intronless_file_HOR21599.write(intronless_HOR21599[i])\n",
    "    else:\n",
    "        intronless_file_HOR21599.write(intronless_HOR21599[i] + '\\n')\n",
    "intronless_file_HOR21599.close()\n",
    "\n",
    "for i in range(len(intronpoor_HOR21599)):\n",
    "    if i == len(intronpoor_HOR21599) -1:\n",
    "        intronpoor_file_HOR21599.write(intronpoor_HOR21599[i])\n",
    "    else:\n",
    "        intronpoor_file_HOR21599.write(intronpoor_HOR21599[i] + '\\n')\n",
    "intronpoor_file_HOR21599.close()\n",
    "\n",
    "for i in range(len(intronrich_HOR21599)):\n",
    "    if i == len(intronrich_HOR21599) -1:\n",
    "        intronrich_file_HOR21599.write(intronrich_HOR21599[i])\n",
    "    else:\n",
    "        intronrich_file_HOR21599.write(intronrich_HOR21599[i]+'\\n')\n",
    "intronrich_file_HOR21599.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Storing the number of transcripts in intron-less/poor/rich genes within a variable \n",
    "n_mRNA_intronless_HOR21599 = ! grep -f Output/HOR21599_intronlessIDs.txt Data/HOR21599_nohashtag.gff3 | awk -F '\\t' '{print $3}' | grep -w 'mRNA' | wc -l\n",
    "n_mRNA_intronpoor_HOR21599 = ! grep -f Output/HOR21599_intronpoorIDs.txt Data/HOR21599_nohashtag.gff3 | awk -F '\\t' '{print $3}' | grep -w 'mRNA' | wc -l\n",
    "n_mRNA_intronrich_HOR21599 = ! grep -f Output/HOR21599_intronrichIDs.txt Data/HOR21599_nohashtag.gff3 | awk -F '\\t' '{print $3}' | grep -w 'mRNA' | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Checking the average number of transcripts for each gene-type\n",
    "avg_mRNA_intronless_HOR21599 = int(n_mRNA_intronless_HOR21599[0])/n_intronless_HOR21599\n",
    "print(avg_mRNA_intronless_HOR21599)\n",
    "avg_mRNA_intronpoor_HOR21599 = int(n_mRNA_intronpoor_HOR21599[0])/n_intronpoor_HOR21599\n",
    "print(avg_mRNA_intronpoor_HOR21599)\n",
    "avg_mRNA_intronrich_HOR21599 = int(n_mRNA_intronrich_HOR21599[0])/n_intronrich_HOR21599\n",
    "print(avg_mRNA_intronrich_HOR21599)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No alternative splicing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Basic statistics of HOR21599 introns\n",
    "introns_HOR21599['length'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Plotting the distribution of HOR21599 introns length\n",
    "introns_HOR21599['length'].plot.density()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Plotting the boxplot of HOR21599 introns length without outliers\n",
    "introns_HOR21599.boxplot(column='length', return_type='axes', showfliers=False) # showfliers = False -> discard outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.13.4 Re-organizing files and directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls Data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir Data/HOR21599"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mv Data/HOR21599_* Data/HOR21599/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls Data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls Output/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir Output/HOR21599"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mv Output/HOR21599_* Output/HOR21599/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls Output/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.14  HOR3081 - Gene projection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.14.1 Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- This will download the raw data to the subdirectory raw under the directory Data\n",
    "! wget -O Data/raw/HOR3081.gff3 https://doi.ipk-gatersleben.de/DOI/c4d433dc-bf7c-4ad9-9368-69bb77837ca5/9615c59f-4b06-44bf-ad99-e75c0afb4272/1/DOWNLOAD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.14.2 Processing Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- There is no need to import the libraries again\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Removing all hashtags from the gff3 file\n",
    "! sed '/#/d' Data/raw/HOR3081.gff3  > Data/HOR3081_nohashtag.gff3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Changing the gff3 file to a csv format file to import it with pandas\n",
    "! cat Data/HOR3081_nohashtag.gff3 | sed 's/,/--/g' | sed 's/;/--/g' | sed 's/\\t/,/g' | awk -F '--' '{print $1}' > Data/HOR3081_nohashtag.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Transforming the gff3 file to a pandas dataframe to better handle it\n",
    "df_HOR3081 = pd.read_csv('Data/HOR3081_nohashtag.csv', header=None, names = ['chr', 'source', 'type','start','end','score','strand','phase','attributes'])\n",
    "df_HOR3081.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Building a separate dataframe containing all exons\n",
    "exon_HOR3081 = df_HOR3081.loc[df_HOR3081['type'].isin(['exon'])]\n",
    "exon_HOR3081.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Exporting the exon dataframe to a tsv file \n",
    "exon_HOR3081.to_csv('Data/HOR3081_exon.tsv',sep='\\t',index=False,header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Keeping in a separated dataframe the forward strands\n",
    "forw_HOR3081 = df_HOR3081.loc[df_HOR3081['strand'].isin(['+'])]\n",
    "forw_HOR3081.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Keeping in a separated dataframe the reverse strands\n",
    "rev_HOR3081 = df_HOR3081.loc[df_HOR3081['strand'].isin(['-'])]\n",
    "rev_HOR3081.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Keeping in a separated dataframe the UTR regions on the forward strands\n",
    "UTR_forw_HOR3081 = forw_HOR3081.loc[df_HOR3081['type'].isin(['three_prime_UTR','five_prime_UTR'])]\n",
    "UTR_forw_HOR3081.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Keeping in a separated dataframe the UTR regions on the reverse strands\n",
    "UTR_rev_HOR3081 = rev_HOR3081.loc[df_HOR3081['type'].isin(['three_prime_UTR','five_prime_UTR'])]\n",
    "UTR_rev_HOR3081.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No UTRs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.14.3 Extracting introns from the whole genome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Extracting introns from HOR3081\n",
    "extract_tot_introns_gp('Data/HOR3081_exon.tsv', 'Output/HOR3081_introns.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "introns_HOR3081 = pd.read_csv('Output/HOR3081_introns.tsv', sep = '\\t')\n",
    "introns_HOR3081[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Counting introns type in HOR3081\n",
    "introns_dictionary_HOR3081 = counting_introns_type_gp(exon_HOR3081)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_intronless_HOR3081, n_intronpoor_HOR3081, n_intronrich_HOR3081, intronless_HOR3081, intronpoor_HOR3081, intronrich_HOR3081 = splitting_introns_type(introns_dictionary_HOR3081)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting_intron_types(n_intronless_HOR3081, n_intronpoor_HOR3081, n_intronrich_HOR3081, 'Genes HOR3081 Distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Creating the list of HOR3081 gene IDs to check the number of transcripts using command line\n",
    "intronless_file_HOR3081 = open('Output/HOR3081_intronlessIDs.txt', 'a')\n",
    "intronpoor_file_HOR3081 = open('Output/HOR3081_intronpoorIDs.txt', 'a')\n",
    "intronrich_file_HOR3081 = open('Output/HOR3081_intronrichIDs.txt', 'a')\n",
    "for i in range(len(intronless_HOR3081)):\n",
    "    if i == len(intronless_HOR3081) -1:\n",
    "        intronless_file_HOR3081.write(intronless_HOR3081[i])\n",
    "    else:\n",
    "        intronless_file_HOR3081.write(intronless_HOR3081[i] + '\\n')\n",
    "intronless_file_HOR3081.close()\n",
    "\n",
    "for i in range(len(intronpoor_HOR3081)):\n",
    "    if i == len(intronpoor_HOR3081) -1:\n",
    "        intronpoor_file_HOR3081.write(intronpoor_HOR3081[i])\n",
    "    else:\n",
    "        intronpoor_file_HOR3081.write(intronpoor_HOR3081[i] + '\\n')\n",
    "intronpoor_file_HOR3081.close()\n",
    "\n",
    "for i in range(len(intronrich_HOR3081)):\n",
    "    if i == len(intronrich_HOR3081) -1:\n",
    "        intronrich_file_HOR3081.write(intronrich_HOR3081[i])\n",
    "    else:\n",
    "        intronrich_file_HOR3081.write(intronrich_HOR3081[i]+'\\n')\n",
    "intronrich_file_HOR3081.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Storing the number of transcripts in intron-less/poor/rich genes within a variable \n",
    "n_mRNA_intronless_HOR3081 = ! grep -f Output/HOR3081_intronlessIDs.txt Data/HOR3081_nohashtag.gff3 | awk -F '\\t' '{print $3}' | grep -w 'mRNA' | wc -l\n",
    "n_mRNA_intronpoor_HOR3081 = ! grep -f Output/HOR3081_intronpoorIDs.txt Data/HOR3081_nohashtag.gff3 | awk -F '\\t' '{print $3}' | grep -w 'mRNA' | wc -l\n",
    "n_mRNA_intronrich_HOR3081 = ! grep -f Output/HOR3081_intronrichIDs.txt Data/HOR3081_nohashtag.gff3 | awk -F '\\t' '{print $3}' | grep -w 'mRNA' | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Checking the average number of transcripts for each gene-type\n",
    "avg_mRNA_intronless_HOR3081 = int(n_mRNA_intronless_HOR3081[0])/n_intronless_HOR3081\n",
    "print(avg_mRNA_intronless_HOR3081)\n",
    "avg_mRNA_intronpoor_HOR3081 = int(n_mRNA_intronpoor_HOR3081[0])/n_intronpoor_HOR3081\n",
    "print(avg_mRNA_intronpoor_HOR3081)\n",
    "avg_mRNA_intronrich_HOR3081 = int(n_mRNA_intronrich_HOR3081[0])/n_intronrich_HOR3081\n",
    "print(avg_mRNA_intronrich_HOR3081)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No alternative splicing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Basic statistics of HOR3081 introns\n",
    "introns_HOR3081['length'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Plotting the distribution of HOR3081 introns length\n",
    "introns_HOR3081['length'].plot.density()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Plotting the boxplot of HOR3081 introns length without outliers\n",
    "introns_HOR3081.boxplot(column='length', return_type='axes', showfliers=False) # showfliers = False -> discard outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.14.4 Re-organizing files and directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls Data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir Data/HOR3081"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mv Data/HOR3081_* Data/HOR3081/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls Data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls Output/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir Output/HOR3081 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mv Output/HOR3081_* Output/HOR3081/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls Output/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.15 HOR3365 - Gene projection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.15.1 Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- This will download the raw data to the subdirectory raw under the directory Data\n",
    "! wget -O Data/raw/HOR3365.gff3 https://doi.ipk-gatersleben.de/DOI/c4d433dc-bf7c-4ad9-9368-69bb77837ca5/7c5ccbfb-0a17-4621-8d07-0fb1b16165d0/1/DOWNLOAD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.15.2 Processing Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- There is no need to import the libraries again\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Removing all hashtags from the gff3 file\n",
    "! sed '/#/d' Data/raw/HOR3365.gff3  > Data/HOR3365_nohashtag.gff3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Changing the gff3 file to a csv format file to import it with pandas\n",
    "! cat Data/HOR3365_nohashtag.gff3 | sed 's/,/--/g' | sed 's/;/--/g' | sed 's/\\t/,/g' | awk -F '--' '{print $1}' > Data/HOR3365_nohashtag.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Transforming the gff3 file to a pandas dataframe to better handle it\n",
    "df_HOR3365 = pd.read_csv('Data/HOR3365_nohashtag.csv', header=None, names = ['chr', 'source', 'type','start','end','score','strand','phase','attributes'])\n",
    "df_HOR3365.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Building a separate dataframe containing all exons\n",
    "exon_HOR3365 = df_HOR3365.loc[df_HOR3365['type'].isin(['exon'])]\n",
    "exon_HOR3365.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Exporting the exon dataframe to a tsv file \n",
    "exon_HOR3365.to_csv('Data/HOR3365_exon.tsv',sep='\\t',index=False,header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Keeping in a separated dataframe the forward strands\n",
    "forw_HOR3365 = df_HOR3365.loc[df_HOR3365['strand'].isin(['+'])]\n",
    "forw_HOR3365.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Keeping in a separated dataframe the reverse strands\n",
    "rev_HOR3365 = df_HOR3365.loc[df_HOR3365['strand'].isin(['-'])]\n",
    "rev_HOR3365.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Keeping in a separated dataframe the UTR regions on the forward strands\n",
    "UTR_forw_HOR3365 = forw_HOR3365.loc[df_HOR3365['type'].isin(['three_prime_UTR','five_prime_UTR'])]\n",
    "UTR_forw_HOR3365.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Keeping in a separated dataframe the UTR regions on the reverse strands\n",
    "UTR_rev_HOR3365 = rev_HOR3365.loc[df_HOR3365['type'].isin(['three_prime_UTR','five_prime_UTR'])]\n",
    "UTR_rev_HOR3365.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No UTRs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.15.3 Extracting introns from the whole genome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Extracting introns from HOR3365\n",
    "extract_tot_introns_gp('Data/HOR3365_exon.tsv', 'Output/HOR3365_introns.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "introns_HOR3365 = pd.read_csv('Output/HOR3365_introns.tsv', sep = '\\t')\n",
    "introns_HOR3365[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Counting introns type in HOR3365\n",
    "introns_dictionary_HOR3365 = counting_introns_type_gp(exon_HOR3365)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_intronless_HOR3365, n_intronpoor_HOR3365, n_intronrich_HOR3365, intronless_HOR3365, intronpoor_HOR3365, intronrich_HOR3365 = splitting_introns_type(introns_dictionary_HOR3365)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting_intron_types(n_intronless_HOR3365, n_intronpoor_HOR3365, n_intronrich_HOR3365, 'Genes HOR3365 Distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Creating the list of HOR3365 gene IDs to check the number of transcripts using command line\n",
    "intronless_file_HOR3365 = open('Output/HOR3365_intronlessIDs.txt', 'a')\n",
    "intronpoor_file_HOR3365 = open('Output/HOR3365_intronpoorIDs.txt', 'a')\n",
    "intronrich_file_HOR3365 = open('Output/HOR3365_intronrichIDs.txt', 'a')\n",
    "for i in range(len(intronless_HOR3365)):\n",
    "    if i == len(intronless_HOR3365) -1:\n",
    "        intronless_file_HOR3365.write(intronless_HOR3365[i])\n",
    "    else:\n",
    "        intronless_file_HOR3365.write(intronless_HOR3365[i] + '\\n')\n",
    "intronless_file_HOR3365.close()\n",
    "\n",
    "for i in range(len(intronpoor_HOR3365)):\n",
    "    if i == len(intronpoor_HOR3365) -1:\n",
    "        intronpoor_file_HOR3365.write(intronpoor_HOR3365[i])\n",
    "    else:\n",
    "        intronpoor_file_HOR3365.write(intronpoor_HOR3365[i] + '\\n')\n",
    "intronpoor_file_HOR3365.close()\n",
    "\n",
    "for i in range(len(intronrich_HOR3365)):\n",
    "    if i == len(intronrich_HOR3365) -1:\n",
    "        intronrich_file_HOR3365.write(intronrich_HOR3365[i])\n",
    "    else:\n",
    "        intronrich_file_HOR3365.write(intronrich_HOR3365[i]+'\\n')\n",
    "intronrich_file_HOR3365.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Storing the number of transcripts in intron-less/poor/rich genes within a variable \n",
    "n_mRNA_intronless_HOR3365 = ! grep -f Output/HOR3365_intronlessIDs.txt Data/HOR3365_nohashtag.gff3 | awk -F '\\t' '{print $3}' | grep -w 'mRNA' | wc -l\n",
    "n_mRNA_intronpoor_HOR3365 = ! grep -f Output/HOR3365_intronpoorIDs.txt Data/HOR3365_nohashtag.gff3 | awk -F '\\t' '{print $3}' | grep -w 'mRNA' | wc -l\n",
    "n_mRNA_intronrich_HOR3365 = ! grep -f Output/HOR3365_intronrichIDs.txt Data/HOR3365_nohashtag.gff3 | awk -F '\\t' '{print $3}' | grep -w 'mRNA' | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Checking the average number of transcripts for each gene-type\n",
    "avg_mRNA_intronless_HOR3365 = int(n_mRNA_intronless_HOR3365[0])/n_intronless_HOR3365\n",
    "print(avg_mRNA_intronless_HOR3365)\n",
    "avg_mRNA_intronpoor_HOR3365 = int(n_mRNA_intronpoor_HOR3365[0])/n_intronpoor_HOR3365\n",
    "print(avg_mRNA_intronpoor_HOR3365)\n",
    "avg_mRNA_intronrich_HOR3365 = int(n_mRNA_intronrich_HOR3365[0])/n_intronrich_HOR3365\n",
    "print(avg_mRNA_intronrich_HOR3365)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No alternative splicing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Basic statistics of HOR3365 introns\n",
    "introns_HOR3365['length'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Plotting the distribution of HOR3365 introns length\n",
    "introns_HOR3365['length'].plot.density()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Plotting the boxplot of HOR3365 introns length without outliers\n",
    "introns_HOR3365.boxplot(column='length', return_type='axes', showfliers=False) # showfliers = False -> discard outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.15.4 Re-organizing files and directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls Data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir Data/HOR3365"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mv Data/HOR3365_* Data/HOR3365"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls Data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls Output/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir Output/HOR3365"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mv Output/HOR3365_* Output/HOR3365/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls Output/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.16 HOR7552 - Gene projection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.16.1 Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- This will download the raw data to the subdirectory raw under the directory Data\n",
    "! wget -O Data/raw/HOR7552.gff3 https://doi.ipk-gatersleben.de/DOI/c4d433dc-bf7c-4ad9-9368-69bb77837ca5/c1e60cfc-4331-4c9f-a4bb-22e236900701/1/DOWNLOAD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.16.2 Processing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- There is no need to import the libraries again\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Removing all hashtags from the gff3 file\n",
    "! sed '/#/d' Data/raw/HOR7552.gff3  > Data/HOR7552_nohashtag.gff3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Changing the gff3 file to a csv format file to import it with pandas\n",
    "! cat Data/HOR7552_nohashtag.gff3 | sed 's/,/--/g' | sed 's/;/--/g' | sed 's/\\t/,/g' | awk -F '--' '{print $1}' > Data/HOR7552_nohashtag.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Transforming the gff3 file to a pandas dataframe to better handle it\n",
    "df_HOR7552 = pd.read_csv('Data/HOR7552_nohashtag.csv', header=None, names = ['chr', 'source', 'type','start','end','score','strand','phase','attributes'])\n",
    "df_HOR7552.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Building a separate dataframe containing all exons\n",
    "exon_HOR7552 = df_HOR7552.loc[df_HOR7552['type'].isin(['exon'])]\n",
    "exon_HOR7552.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Exporting the exon dataframe to a tsv file \n",
    "exon_HOR7552.to_csv('Data/HOR7552_exon.tsv',sep='\\t',index=False,header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Keeping in a separated dataframe the forward strands\n",
    "forw_HOR7552 = df_HOR7552.loc[df_HOR7552['strand'].isin(['+'])]\n",
    "forw_HOR7552.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Keeping in a separated dataframe the reverse strands\n",
    "rev_HOR7552 = df_HOR7552.loc[df_HOR7552['strand'].isin(['-'])]\n",
    "rev_HOR7552.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Keeping in a separated dataframe the UTR regions on the forward strands\n",
    "UTR_forw_HOR7552 = forw_HOR7552.loc[df_HOR7552['type'].isin(['three_prime_UTR','five_prime_UTR'])]\n",
    "UTR_forw_HOR7552.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Keeping in a separated dataframe the UTR regions on the reverse strands\n",
    "UTR_rev_HOR7552 = rev_HOR7552.loc[df_HOR7552['type'].isin(['three_prime_UTR','five_prime_UTR'])]\n",
    "UTR_rev_HOR7552.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No UTRs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.16.3 Extracting introns from the whole genome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Extracting introns from HOR7552\n",
    "extract_tot_introns_gp('Data/HOR7552_exon.tsv', 'Output/HOR7552_introns.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "introns_HOR7552 = pd.read_csv('Output/HOR7552_introns.tsv', sep = '\\t')\n",
    "introns_HOR7552[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Counting introns type in HOR7552\n",
    "introns_dictionary_HOR7552 = counting_introns_type_gp(exon_HOR7552)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_intronless_HOR7552, n_intronpoor_HOR7552, n_intronrich_HOR7552, intronless_HOR7552, intronpoor_HOR7552, intronrich_HOR7552 = splitting_introns_type(introns_dictionary_HOR7552)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting_intron_types(n_intronless_HOR7552, n_intronpoor_HOR7552, n_intronrich_HOR7552, 'Genes HOR7552 Distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Creating the list of HOR7552 gene IDs to check the number of transcripts using command line\n",
    "intronless_file_HOR7552 = open('Output/HOR7552_intronlessIDs.txt', 'a')\n",
    "intronpoor_file_HOR7552 = open('Output/HOR7552_intronpoorIDs.txt', 'a')\n",
    "intronrich_file_HOR7552 = open('Output/HOR7552_intronrichIDs.txt', 'a')\n",
    "for i in range(len(intronless_HOR7552)):\n",
    "    if i == len(intronless_HOR7552) -1:\n",
    "        intronless_file_HOR7552.write(intronless_HOR7552[i])\n",
    "    else:\n",
    "        intronless_file_HOR7552.write(intronless_HOR7552[i] + '\\n')\n",
    "intronless_file_HOR7552.close()\n",
    "\n",
    "for i in range(len(intronpoor_HOR7552)):\n",
    "    if i == len(intronpoor_HOR7552) -1:\n",
    "        intronpoor_file_HOR7552.write(intronpoor_HOR7552[i])\n",
    "    else:\n",
    "        intronpoor_file_HOR7552.write(intronpoor_HOR7552[i] + '\\n')\n",
    "intronpoor_file_HOR7552.close()\n",
    "\n",
    "for i in range(len(intronrich_HOR7552)):\n",
    "    if i == len(intronrich_HOR7552) -1:\n",
    "        intronrich_file_HOR7552.write(intronrich_HOR7552[i])\n",
    "    else:\n",
    "        intronrich_file_HOR7552.write(intronrich_HOR7552[i]+'\\n')\n",
    "intronrich_file_HOR7552.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Storing the number of transcripts in intron-less/poor/rich genes within a variable \n",
    "n_mRNA_intronless_HOR7552 = ! grep -f Output/HOR7552_intronlessIDs.txt Data/HOR7552_nohashtag.gff3 | awk -F '\\t' '{print $3}' | grep -w 'mRNA' | wc -l\n",
    "n_mRNA_intronpoor_HOR7552 = ! grep -f Output/HOR7552_intronpoorIDs.txt Data/HOR7552_nohashtag.gff3 | awk -F '\\t' '{print $3}' | grep -w 'mRNA' | wc -l\n",
    "n_mRNA_intronrich_HOR7552 = ! grep -f Output/HOR7552_intronrichIDs.txt Data/HOR7552_nohashtag.gff3 | awk -F '\\t' '{print $3}' | grep -w 'mRNA' | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Checking the average number of transcripts for each gene-type\n",
    "avg_mRNA_intronless_HOR7552 = int(n_mRNA_intronless_HOR7552[0])/n_intronless_HOR7552\n",
    "print(avg_mRNA_intronless_HOR7552)\n",
    "avg_mRNA_intronpoor_HOR7552 = int(n_mRNA_intronpoor_HOR7552[0])/n_intronpoor_HOR7552\n",
    "print(avg_mRNA_intronpoor_HOR7552)\n",
    "avg_mRNA_intronrich_HOR7552 = int(n_mRNA_intronrich_HOR7552[0])/n_intronrich_HOR7552\n",
    "print(avg_mRNA_intronrich_HOR7552)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No alternative splicing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Basic statistics of HOR7552 introns\n",
    "introns_HOR7552['length'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Plotting the distribution of HOR7552 introns length\n",
    "introns_HOR7552['length'].plot.density()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Plotting the boxplot of HOR7552 introns length without outliers\n",
    "introns_HOR7552.boxplot(column='length', return_type='axes', showfliers=False) # showfliers = False -> discard outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.16.4 Re-organizing files and directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls Data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir Data/HOR7552"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mv Data/HOR7552_* Data/HOR7552/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls Data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls Output/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir Output/HOR7552"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mv Output/HOR7552_* Output/HOR7552/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "! ls Output/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.17 HOR8148 - Gene projection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.17.1 Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- This will download the raw data to the subdirectory raw under the directory Data\n",
    "! wget -O Data/raw/HOR8148.gff3 https://doi.ipk-gatersleben.de/DOI/c4d433dc-bf7c-4ad9-9368-69bb77837ca5/178616bc-965a-4c95-b375-8dc0fee67429/1/DOWNLOAD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.17.2 Processing Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- There is no need to import the libraries again\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Removing all hashtags from the gff3 file\n",
    "! sed '/#/d' Data/raw/HOR8148.gff3  > Data/HOR8148_nohashtag.gff3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Changing the gff3 file to a csv format file to import it with pandas\n",
    "! cat Data/HOR8148_nohashtag.gff3 | sed 's/,/--/g' | sed 's/;/--/g' | sed 's/\\t/,/g' | awk -F '--' '{print $1}' > Data/HOR8148_nohashtag.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Transforming the gff3 file to a pandas dataframe to better handle it\n",
    "df_HOR8148 = pd.read_csv('Data/HOR8148_nohashtag.csv', header=None, names = ['chr', 'source', 'type','start','end','score','strand','phase','attributes'])\n",
    "df_HOR8148.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Building a separate dataframe containing all exons\n",
    "exon_HOR8148 = df_HOR8148.loc[df_HOR8148['type'].isin(['exon'])]\n",
    "exon_HOR8148.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Exporting the exon dataframe to a tsv file \n",
    "exon_HOR8148.to_csv('Data/HOR8148_exon.tsv',sep='\\t',index=False,header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Keeping in a separated dataframe the forward strands\n",
    "forw_HOR8148 = df_HOR8148.loc[df_HOR8148['strand'].isin(['+'])]\n",
    "forw_HOR8148.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Keeping in a separated dataframe the reverse strands\n",
    "rev_HOR8148 = df_HOR8148.loc[df_HOR8148['strand'].isin(['-'])]\n",
    "rev_HOR8148.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Keeping in a separated dataframe the UTR regions on the forward strands\n",
    "UTR_forw_HOR8148 = forw_HOR8148.loc[df_HOR8148['type'].isin(['three_prime_UTR','five_prime_UTR'])]\n",
    "UTR_forw_HOR8148.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Keeping in a separated dataframe the UTR regions on the reverse strands\n",
    "UTR_rev_HOR8148 = rev_HOR8148.loc[df_HOR8148['type'].isin(['three_prime_UTR','five_prime_UTR'])]\n",
    "UTR_rev_HOR8148.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No UTRs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.17.3 Extracting introns from the whole genome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Extracting introns from HOR8148\n",
    "extract_tot_introns_gp('Data/HOR8148_exon.tsv', 'Output/HOR8148_introns.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "introns_HOR8148 = pd.read_csv('Output/HOR8148_introns.tsv', sep = '\\t')\n",
    "introns_HOR8148[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Counting introns type in HOR8148\n",
    "introns_dictionary_HOR8148 = counting_introns_type_gp(exon_HOR8148)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_intronless_HOR8148, n_intronpoor_HOR8148, n_intronrich_HOR8148, intronless_HOR8148, intronpoor_HOR8148, intronrich_HOR8148 = splitting_introns_type(introns_dictionary_HOR8148)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting_intron_types(n_intronless_HOR8148, n_intronpoor_HOR8148, n_intronrich_HOR8148, 'Genes HOR8148 Distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Creating the list of HOR8148 gene IDs to check the number of transcripts using command line\n",
    "intronless_file_HOR8148 = open('Output/HOR8148_intronlessIDs.txt', 'a')\n",
    "intronpoor_file_HOR8148 = open('Output/HOR8148_intronpoorIDs.txt', 'a')\n",
    "intronrich_file_HOR8148 = open('Output/HOR8148_intronrichIDs.txt', 'a')\n",
    "for i in range(len(intronless_HOR8148)):\n",
    "    if i == len(intronless_HOR8148) -1:\n",
    "        intronless_file_HOR8148.write(intronless_HOR8148[i])\n",
    "    else:\n",
    "        intronless_file_HOR8148.write(intronless_HOR8148[i] + '\\n')\n",
    "intronless_file_HOR8148.close()\n",
    "\n",
    "for i in range(len(intronpoor_HOR8148)):\n",
    "    if i == len(intronpoor_HOR8148) -1:\n",
    "        intronpoor_file_HOR8148.write(intronpoor_HOR8148[i])\n",
    "    else:\n",
    "        intronpoor_file_HOR8148.write(intronpoor_HOR8148[i] + '\\n')\n",
    "intronpoor_file_HOR8148.close()\n",
    "\n",
    "for i in range(len(intronrich_HOR8148)):\n",
    "    if i == len(intronrich_HOR8148) -1:\n",
    "        intronrich_file_HOR8148.write(intronrich_HOR8148[i])\n",
    "    else:\n",
    "        intronrich_file_HOR8148.write(intronrich_HOR8148[i]+'\\n')\n",
    "intronrich_file_HOR8148.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Storing the number of transcripts in intron-less/poor/rich genes within a variable \n",
    "n_mRNA_intronless_HOR8148 = ! grep -f Output/HOR8148_intronlessIDs.txt Data/HOR8148_nohashtag.gff3 | awk -F '\\t' '{print $3}' | grep -w 'mRNA' | wc -l\n",
    "n_mRNA_intronpoor_HOR8148 = ! grep -f Output/HOR8148_intronpoorIDs.txt Data/HOR8148_nohashtag.gff3 | awk -F '\\t' '{print $3}' | grep -w 'mRNA' | wc -l\n",
    "n_mRNA_intronrich_HOR8148 = ! grep -f Output/HOR8148_intronrichIDs.txt Data/HOR8148_nohashtag.gff3 | awk -F '\\t' '{print $3}' | grep -w 'mRNA' | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Checking the average number of transcripts for each gene-type\n",
    "avg_mRNA_intronless_HOR8148 = int(n_mRNA_intronless_HOR8148[0])/n_intronless_HOR8148\n",
    "print(avg_mRNA_intronless_HOR8148)\n",
    "avg_mRNA_intronpoor_HOR8148 = int(n_mRNA_intronpoor_HOR8148[0])/n_intronpoor_HOR8148\n",
    "print(avg_mRNA_intronpoor_HOR8148)\n",
    "avg_mRNA_intronrich_HOR8148 = int(n_mRNA_intronrich_HOR8148[0])/n_intronrich_HOR8148\n",
    "print(avg_mRNA_intronrich_HOR8148)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No alternative splicing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Basic statistics of HOR8148 introns\n",
    "introns_HOR8148['length'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Plotting the distribution of HOR8148 introns length\n",
    "introns_HOR8148['length'].plot.density()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Plotting the boxplot of HOR8148 introns length without outliers\n",
    "introns_HOR8148.boxplot(column='length', return_type='axes', showfliers=False) # showfliers = False -> discard outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.17.4 Re-organizing files and directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls Data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir Data/HOR8148"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mv Data/HOR8148_* Data/HOR8148/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls Output/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir Output/HOR8148"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mv Output/HOR8148_* Output/HOR8148/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls Output/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.18 HOR9043 - Gene projection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.18.1 Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- This will download the raw data to the subdirectory raw under the directory Data\n",
    "! wget -O Data/raw/HOR9043.gff3 https://doi.ipk-gatersleben.de/DOI/c4d433dc-bf7c-4ad9-9368-69bb77837ca5/8f5a2569-f234-4001-97df-66bcd54c4b9d/1/DOWNLOAD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.18.2 Processing Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- There is no need to import the libraries again\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Removing all hashtags from the gff3 file\n",
    "! sed '/#/d' Data/raw/HOR9043.gff3  > Data/HOR9043_nohashtag.gff3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Changing the gff3 file to a csv format file to import it with pandas\n",
    "! cat Data/HOR9043_nohashtag.gff3 | sed 's/,/--/g' | sed 's/;/--/g' | sed 's/\\t/,/g' | awk -F '--' '{print $1}' > Data/HOR9043_nohashtag.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Transforming the gff3 file to a pandas dataframe to better handle it\n",
    "df_HOR9043 = pd.read_csv('Data/HOR9043_nohashtag.csv', header=None, names = ['chr', 'source', 'type','start','end','score','strand','phase','attributes'])\n",
    "df_HOR9043.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Building a separate dataframe containing all exons\n",
    "exon_HOR9043 = df_HOR9043.loc[df_HOR9043['type'].isin(['exon'])]\n",
    "exon_HOR9043.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Exporting the exon dataframe to a tsv file \n",
    "exon_HOR9043.to_csv('Data/HOR9043_exon.tsv',sep='\\t',index=False,header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Keeping in a separated dataframe the forward strands\n",
    "forw_HOR9043 = df_HOR9043.loc[df_HOR9043['strand'].isin(['+'])]\n",
    "forw_HOR9043.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Keeping in a separated dataframe the reverse strands\n",
    "rev_HOR9043 = df_HOR9043.loc[df_HOR9043['strand'].isin(['-'])]\n",
    "rev_HOR9043.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Keeping in a separated dataframe the UTR regions on the forward strands\n",
    "UTR_forw_HOR9043 = forw_HOR9043.loc[df_HOR9043['type'].isin(['three_prime_UTR','five_prime_UTR'])]\n",
    "UTR_forw_HOR9043.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Keeping in a separated dataframe the UTR regions on the reverse strands\n",
    "UTR_rev_HOR9043 = rev_HOR9043.loc[df_HOR9043['type'].isin(['three_prime_UTR','five_prime_UTR'])]\n",
    "UTR_rev_HOR9043.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No UTRs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.18.3 Extracting introns from the whole genome "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Extracting introns from HOR9043\n",
    "extract_tot_introns_gp('Data/HOR9043_exon.tsv', 'Output/HOR9043_introns.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "introns_HOR9043 = pd.read_csv('Output/HOR9043_introns.tsv', sep = '\\t')\n",
    "introns_HOR9043[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Counting introns type in HOR9043\n",
    "introns_dictionary_HOR9043 = counting_introns_type_gp(exon_HOR9043)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_intronless_HOR9043, n_intronpoor_HOR9043, n_intronrich_HOR9043, intronless_HOR9043, intronpoor_HOR9043, intronrich_HOR9043 = splitting_introns_type(introns_dictionary_HOR9043)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting_intron_types(n_intronless_HOR9043, n_intronpoor_HOR9043, n_intronrich_HOR9043, 'Genes HOR9043 Distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Creating the list of HOR9043 gene IDs to check the number of transcripts using command line\n",
    "intronless_file_HOR9043 = open('Output/HOR9043_intronlessIDs.txt', 'a')\n",
    "intronpoor_file_HOR9043 = open('Output/HOR9043_intronpoorIDs.txt', 'a')\n",
    "intronrich_file_HOR9043 = open('Output/HOR9043_intronrichIDs.txt', 'a')\n",
    "for i in range(len(intronless_HOR9043)):\n",
    "    if i == len(intronless_HOR9043) -1:\n",
    "        intronless_file_HOR9043.write(intronless_HOR9043[i])\n",
    "    else:\n",
    "        intronless_file_HOR9043.write(intronless_HOR9043[i] + '\\n')\n",
    "intronless_file_HOR9043.close()\n",
    "\n",
    "for i in range(len(intronpoor_HOR9043)):\n",
    "    if i == len(intronpoor_HOR9043) -1:\n",
    "        intronpoor_file_HOR9043.write(intronpoor_HOR9043[i])\n",
    "    else:\n",
    "        intronpoor_file_HOR9043.write(intronpoor_HOR9043[i] + '\\n')\n",
    "intronpoor_file_HOR9043.close()\n",
    "\n",
    "for i in range(len(intronrich_HOR9043)):\n",
    "    if i == len(intronrich_HOR9043) -1:\n",
    "        intronrich_file_HOR9043.write(intronrich_HOR9043[i])\n",
    "    else:\n",
    "        intronrich_file_HOR9043.write(intronrich_HOR9043[i]+'\\n')\n",
    "intronrich_file_HOR9043.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Storing the number of transcripts in intron-less/poor/rich genes within a variable \n",
    "n_mRNA_intronless_HOR9043 = ! grep -f Output/HOR9043_intronlessIDs.txt Data/HOR9043_nohashtag.gff3 | awk -F '\\t' '{print $3}' | grep -w 'mRNA' | wc -l\n",
    "n_mRNA_intronpoor_HOR9043 = ! grep -f Output/HOR9043_intronpoorIDs.txt Data/HOR9043_nohashtag.gff3 | awk -F '\\t' '{print $3}' | grep -w 'mRNA' | wc -l\n",
    "n_mRNA_intronrich_HOR9043 = ! grep -f Output/HOR9043_intronrichIDs.txt Data/HOR9043_nohashtag.gff3 | awk -F '\\t' '{print $3}' | grep -w 'mRNA' | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Checking the average number of transcripts for each gene-type\n",
    "avg_mRNA_intronless_HOR9043 = int(n_mRNA_intronless_HOR9043[0])/n_intronless_HOR9043\n",
    "print(avg_mRNA_intronless_HOR9043)\n",
    "avg_mRNA_intronpoor_HOR9043 = int(n_mRNA_intronpoor_HOR9043[0])/n_intronpoor_HOR9043\n",
    "print(avg_mRNA_intronpoor_HOR9043)\n",
    "avg_mRNA_intronrich_HOR9043 = int(n_mRNA_intronrich_HOR9043[0])/n_intronrich_HOR9043\n",
    "print(avg_mRNA_intronrich_HOR9043)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Basic statistics of HOR9043 introns\n",
    "introns_HOR9043['length'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Plotting the distribution of HOR9043 introns length\n",
    "introns_HOR9043['length'].plot.density()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Plotting the boxplot of HOR9043 introns length without outliers\n",
    "introns_HOR9043.boxplot(column='length', return_type='axes', showfliers=False) # showfliers = False -> discard outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.18.4 Re-organizing files and directories "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls Data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir Data/HOR9043"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mv Data/HOR9043_* Data/HOR9043/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls Data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls Output/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir Output/HOR9043"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mv Output/HOR9043_* Output/HOR9043/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls Output/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.19 Igri - Gene projection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.19.1 Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- This will download the raw data to the subdirectory raw under the directory Data\n",
    "! wget -O Data/raw/Igri.gff3 https://doi.ipk-gatersleben.de/DOI/c4d433dc-bf7c-4ad9-9368-69bb77837ca5/053b94a0-5d6e-4339-b2d5-3de486760c32/1/DOWNLOAD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.19.2 Processing Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- There is no need to import the libraries again\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Removing all hashtags from the gff3 file\n",
    "! sed '/#/d' Data/raw/Igri.gff3  > Data/Igri_nohashtag.gff3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Changing the gff3 file to a csv format file to import it with pandas\n",
    "! cat Data/Igri_nohashtag.gff3 | sed 's/,/--/g' | sed 's/;/--/g' | sed 's/\\t/,/g' | awk -F '--' '{print $1}' > Data/Igri_nohashtag.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Transforming the gff3 file to a pandas dataframe to better handle it\n",
    "df_Igri = pd.read_csv('Data/Igri_nohashtag.csv', header=None, names = ['chr', 'source', 'type','start','end','score','strand','phase','attributes'])\n",
    "df_Igri.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Building a separate dataframe containing all exons\n",
    "exon_Igri = df_Igri.loc[df_Igri['type'].isin(['exon'])]\n",
    "exon_Igri.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Exporting the exon dataframe to a tsv file \n",
    "exon_Igri.to_csv('Data/Igri_exon.tsv',sep='\\t',index=False,header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Keeping in a separated dataframe the forward strands\n",
    "forw_Igri = df_Igri.loc[df_Igri['strand'].isin(['+'])]\n",
    "forw_Igri.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Keeping in a separated dataframe the reverse strands\n",
    "rev_Igri = df_Igri.loc[df_Igri['strand'].isin(['-'])]\n",
    "rev_Igri.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Keeping in a separated dataframe the UTR regions on the forward strands\n",
    "UTR_forw_Igri = forw_Igri.loc[df_Igri['type'].isin(['three_prime_UTR','five_prime_UTR'])]\n",
    "UTR_forw_Igri.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Keeping in a separated dataframe the UTR regions on the reverse strands\n",
    "UTR_rev_Igri = rev_Igri.loc[df_Igri['type'].isin(['three_prime_UTR','five_prime_UTR'])]\n",
    "UTR_rev_Igri.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No UTRs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.19.3 Extracting introns from the whole genome "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Extracting introns from Igri\n",
    "extract_tot_introns_gp('Data/Igri_exon.tsv', 'Output/Igri_introns.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "introns_Igri = pd.read_csv('Output/Igri_introns.tsv', sep = '\\t')\n",
    "introns_Igri[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Counting introns type in Igri\n",
    "introns_dictionary_Igri = counting_introns_type_gp(exon_Igri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_intronless_Igri, n_intronpoor_Igri, n_intronrich_Igri, intronless_Igri, intronpoor_Igri, intronrich_Igri = splitting_introns_type(introns_dictionary_Igri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting_intron_types(n_intronless_Igri, n_intronpoor_Igri, n_intronrich_Igri, 'Genes Igri Distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Creating the list of Igri gene IDs to check the number of transcripts using command line\n",
    "intronless_file_Igri = open('Output/Igri_intronlessIDs.txt', 'a')\n",
    "intronpoor_file_Igri = open('Output/Igri_intronpoorIDs.txt', 'a')\n",
    "intronrich_file_Igri = open('Output/Igri_intronrichIDs.txt', 'a')\n",
    "for i in range(len(intronless_Igri)):\n",
    "    if i == len(intronless_Igri) -1:\n",
    "        intronless_file_Igri.write(intronless_Igri[i])\n",
    "    else:\n",
    "        intronless_file_Igri.write(intronless_Igri[i] + '\\n')\n",
    "intronless_file_Igri.close()\n",
    "\n",
    "for i in range(len(intronpoor_Igri)):\n",
    "    if i == len(intronpoor_Igri) -1:\n",
    "        intronpoor_file_Igri.write(intronpoor_Igri[i])\n",
    "    else:\n",
    "        intronpoor_file_Igri.write(intronpoor_Igri[i] + '\\n')\n",
    "intronpoor_file_Igri.close()\n",
    "\n",
    "for i in range(len(intronrich_Igri)):\n",
    "    if i == len(intronrich_Igri) -1:\n",
    "        intronrich_file_Igri.write(intronrich_Igri[i])\n",
    "    else:\n",
    "        intronrich_file_Igri.write(intronrich_Igri[i]+'\\n')\n",
    "intronrich_file_Igri.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Storing the number of transcripts in intron-less/poor/rich genes within a variable \n",
    "n_mRNA_intronless_Igri = ! grep -f Output/Igri_intronlessIDs.txt Data/Igri_nohashtag.gff3 | awk -F '\\t' '{print $3}' | grep -w 'mRNA' | wc -l\n",
    "n_mRNA_intronpoor_Igri = ! grep -f Output/Igri_intronpoorIDs.txt Data/Igri_nohashtag.gff3 | awk -F '\\t' '{print $3}' | grep -w 'mRNA' | wc -l\n",
    "n_mRNA_intronrich_Igri = ! grep -f Output/Igri_intronrichIDs.txt Data/Igri_nohashtag.gff3 | awk -F '\\t' '{print $3}' | grep -w 'mRNA' | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Checking the average number of transcripts for each gene-type\n",
    "avg_mRNA_intronless_Igri = int(n_mRNA_intronless_Igri[0])/n_intronless_Igri\n",
    "print(avg_mRNA_intronless_Igri)\n",
    "avg_mRNA_intronpoor_Igri = int(n_mRNA_intronpoor_Igri[0])/n_intronpoor_Igri\n",
    "print(avg_mRNA_intronpoor_Igri)\n",
    "avg_mRNA_intronrich_Igri = int(n_mRNA_intronrich_Igri[0])/n_intronrich_Igri\n",
    "print(avg_mRNA_intronrich_Igri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Basic statistics of Igri introns\n",
    "introns_Igri['length'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Plotting the distribution of Igri introns length\n",
    "introns_Igri['length'].plot.density()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Plotting the boxplot of Igri introns length without outliers\n",
    "introns_Igri.boxplot(column='length', return_type='axes', showfliers=False) # showfliers = False -> discard outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.19.4 Re-organizing files and directories "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls Data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir Data/Igri "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mv Data/Igri_* Data/Igri/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls Data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls Output/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir Output/Igri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mv Output/Igri_* Output/Igri/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls Output/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.20 Morex - Gene projection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.20.1 Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- This will download the raw data to the subdirectory raw under the directory Data\n",
    "! wget -O Data/raw/Morex_gp.gff3 https://doi.ipk-gatersleben.de/DOI/c4d433dc-bf7c-4ad9-9368-69bb77837ca5/d8559e36-1879-406f-88de-f55786ce39eb/1/DOWNLOAD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.20.2 Processing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- There is no need to import the libraries again\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Removing all hashtags from the gff3 file\n",
    "! sed '/#/d' Data/raw/Morex_gp.gff3  > Data/Morex_gp_nohashtag.gff3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Changing the gff3 file to a csv format file to import it with pandas\n",
    "! cat Data/Morex_gp_nohashtag.gff3 | sed 's/,/--/g' | sed 's/;/--/g' | sed 's/\\t/,/g' | awk -F '--' '{print $1}' > Data/Morex_gp_nohashtag.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Transforming the gff3 file to a pandas dataframe to better handle it\n",
    "df_Morex_gp = pd.read_csv('Data/Morex_gp_nohashtag.csv', header=None, names = ['chr', 'source', 'type','start','end','score','strand','phase','attributes'])\n",
    "df_Morex_gp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Building a separate dataframe containing all exons\n",
    "exon_Morex_gp = df_Morex_gp.loc[df_Morex_gp['type'].isin(['exon'])]\n",
    "exon_Morex_gp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Exporting the exon dataframe to a tsv file \n",
    "exon_Morex_gp.to_csv('Data/Morex_gp_exon.tsv',sep='\\t',index=False,header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Keeping in a separated dataframe the forward strands\n",
    "forw_Morex_gp = df_Morex_gp.loc[df_Morex_gp['strand'].isin(['+'])]\n",
    "forw_Morex_gp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Keeping in a separated dataframe the reverse strands\n",
    "rev_Morex_gp = df_Morex_gp.loc[df_Morex_gp['strand'].isin(['-'])]\n",
    "rev_Morex_gp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Keeping in a separated dataframe the UTR regions on the forward strands\n",
    "UTR_forw_Morex_gp = forw_Morex_gp.loc[df_Morex_gp['type'].isin(['three_prime_UTR','five_prime_UTR'])]\n",
    "UTR_forw_Morex_gp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Keeping in a separated dataframe the UTR regions on the reverse strands\n",
    "UTR_rev_Morex_gp = rev_Morex_gp.loc[df_Morex_gp['type'].isin(['three_prime_UTR','five_prime_UTR'])]\n",
    "UTR_rev_Morex_gp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No UTRs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.20.3 Extracting introns from the whole genome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Extracting introns from Morex_gp\n",
    "extract_tot_introns_gp('Data/Morex_gp_exon.tsv', 'Output/Morex_gp_introns.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "introns_Morex_gp = pd.read_csv('Output/Morex_gp_introns.tsv', sep = '\\t')\n",
    "introns_Morex_gp[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Counting introns type in Morex_gp\n",
    "introns_dictionary_Morex_gp = counting_introns_type_gp(exon_Morex_gp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_intronless_Morex_gp, n_intronpoor_Morex_gp, n_intronrich_Morex_gp, intronless_Morex_gp, intronpoor_Morex_gp, intronrich_Morex_gp = splitting_introns_type(introns_dictionary_Morex_gp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting_intron_types(n_intronless_Morex_gp, n_intronpoor_Morex_gp, n_intronrich_Morex_gp, 'Genes Morex_gp Distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Creating the list of Morex_gp gene IDs to check the number of transcripts using command line\n",
    "intronless_file_Morex_gp = open('Output/Morex_gp_intronlessIDs.txt', 'a')\n",
    "intronpoor_file_Morex_gp = open('Output/Morex_gp_intronpoorIDs.txt', 'a')\n",
    "intronrich_file_Morex_gp = open('Output/Morex_gp_intronrichIDs.txt', 'a')\n",
    "for i in range(len(intronless_Morex_gp)):\n",
    "    if i == len(intronless_Morex_gp) -1:\n",
    "        intronless_file_Morex_gp.write(intronless_Morex_gp[i])\n",
    "    else:\n",
    "        intronless_file_Morex_gp.write(intronless_Morex_gp[i] + '\\n')\n",
    "intronless_file_Morex_gp.close()\n",
    "\n",
    "for i in range(len(intronpoor_Morex_gp)):\n",
    "    if i == len(intronpoor_Morex_gp) -1:\n",
    "        intronpoor_file_Morex_gp.write(intronpoor_Morex_gp[i])\n",
    "    else:\n",
    "        intronpoor_file_Morex_gp.write(intronpoor_Morex_gp[i] + '\\n')\n",
    "intronpoor_file_Morex_gp.close()\n",
    "\n",
    "for i in range(len(intronrich_Morex_gp)):\n",
    "    if i == len(intronrich_Morex_gp) -1:\n",
    "        intronrich_file_Morex_gp.write(intronrich_Morex_gp[i])\n",
    "    else:\n",
    "        intronrich_file_Morex_gp.write(intronrich_Morex_gp[i]+'\\n')\n",
    "intronrich_file_Morex_gp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Storing the number of transcripts in intron-less/poor/rich genes within a variable \n",
    "n_mRNA_intronless_Morex_gp = ! grep -f Output/Morex_gp_intronlessIDs.txt Data/Morex_gp_nohashtag.gff3 | awk -F '\\t' '{print $3}' | grep -w 'mRNA' | wc -l\n",
    "n_mRNA_intronpoor_Morex_gp = ! grep -f Output/Morex_gp_intronpoorIDs.txt Data/Morex_gp_nohashtag.gff3 | awk -F '\\t' '{print $3}' | grep -w 'mRNA' | wc -l\n",
    "n_mRNA_intronrich_Morex_gp = ! grep -f Output/Morex_gp_intronrichIDs.txt Data/Morex_gp_nohashtag.gff3 | awk -F '\\t' '{print $3}' | grep -w 'mRNA' | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Checking the average number of transcripts for each gene-type\n",
    "avg_mRNA_intronless_Morex_gp = int(n_mRNA_intronless_Morex_gp[0])/n_intronless_Morex_gp\n",
    "print(avg_mRNA_intronless_Morex_gp)\n",
    "avg_mRNA_intronpoor_Morex_gp = int(n_mRNA_intronpoor_Morex_gp[0])/n_intronpoor_Morex_gp\n",
    "print(avg_mRNA_intronpoor_Morex_gp)\n",
    "avg_mRNA_intronrich_Morex_gp = int(n_mRNA_intronrich_Morex_gp[0])/n_intronrich_Morex_gp\n",
    "print(avg_mRNA_intronrich_Morex_gp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No alternative splicing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Basic statistics of Morex_gp introns\n",
    "introns_Morex_gp['length'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Plotting the distribution of Morex_gp introns length\n",
    "introns_Morex_gp['length'].plot.density()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Plotting the boxplot of Morex_gp introns length without outliers\n",
    "introns_Morex_gp.boxplot(column='length', return_type='axes', showfliers=False) # showfliers = False -> discard outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.20.4 Re-organizing files and directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls Data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir Data/Morex_gp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mv Data/Morex_gp_* Data/Morex_gp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls Data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls Output/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir Output/Morex_gp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mv Output/Morex_gp_* Output/Morex_gp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls Output/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.21 OUN333 - Gene projection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.21.1 Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- This will download the raw data to the subdirectory raw under the directory Data\n",
    "! wget -O Data/raw/OUN333.gff3 https://doi.ipk-gatersleben.de/DOI/c4d433dc-bf7c-4ad9-9368-69bb77837ca5/9b5ea42c-6b27-4bd7-a66e-3210ded3ece5/1/DOWNLOAD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.21.2 Processing Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- There is no need to import the libraries again\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Removing all hashtags from the gff3 file\n",
    "! sed '/#/d' Data/raw/OUN333.gff3  > Data/OUN333_nohashtag.gff3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Changing the gff3 file to a csv format file to import it with pandas\n",
    "! cat Data/OUN333_nohashtag.gff3 | sed 's/,/--/g' | sed 's/;/--/g' | sed 's/\\t/,/g' | awk -F '--' '{print $1}' > Data/OUN333_nohashtag.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Transforming the gff3 file to a pandas dataframe to better handle it\n",
    "df_OUN333 = pd.read_csv('Data/OUN333_nohashtag.csv', header=None, names = ['chr', 'source', 'type','start','end','score','strand','phase','attributes'])\n",
    "df_OUN333.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Building a separate dataframe containing all exons\n",
    "exon_OUN333 = df_OUN333.loc[df_OUN333['type'].isin(['exon'])]\n",
    "exon_OUN333.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Exporting the exon dataframe to a tsv file \n",
    "exon_OUN333.to_csv('Data/OUN333_exon.tsv',sep='\\t',index=False,header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Keeping in a separated dataframe the forward strands\n",
    "forw_OUN333 = df_OUN333.loc[df_OUN333['strand'].isin(['+'])]\n",
    "forw_OUN333.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Keeping in a separated dataframe the reverse strands\n",
    "rev_OUN333 = df_OUN333.loc[df_OUN333['strand'].isin(['-'])]\n",
    "rev_OUN333.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Keeping in a separated dataframe the UTR regions on the forward strands\n",
    "UTR_forw_OUN333 = forw_OUN333.loc[df_OUN333['type'].isin(['three_prime_UTR','five_prime_UTR'])]\n",
    "UTR_forw_OUN333.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Keeping in a separated dataframe the UTR regions on the reverse strands\n",
    "UTR_rev_OUN333 = rev_OUN333.loc[df_OUN333['type'].isin(['three_prime_UTR','five_prime_UTR'])]\n",
    "UTR_rev_OUN333.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No UTRs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.21.3 Extracting introns from the whole genome "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Extracting introns from OUN333\n",
    "extract_tot_introns_gp('Data/OUN333_exon.tsv', 'Output/OUN333_introns.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "introns_OUN333 = pd.read_csv('Output/OUN333_introns.tsv', sep = '\\t')\n",
    "introns_OUN333[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Counting introns type in OUN333\n",
    "introns_dictionary_OUN333 = counting_introns_type_gp(exon_OUN333)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_intronless_OUN333, n_intronpoor_OUN333, n_intronrich_OUN333, intronless_OUN333, intronpoor_OUN333, intronrich_OUN333 = splitting_introns_type(introns_dictionary_OUN333)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting_intron_types(n_intronless_OUN333, n_intronpoor_OUN333, n_intronrich_OUN333, 'Genes OUN333 Distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Creating the list of OUN333 gene IDs to check the number of transcripts using command line\n",
    "intronless_file_OUN333 = open('Output/OUN333_intronlessIDs.txt', 'a')\n",
    "intronpoor_file_OUN333 = open('Output/OUN333_intronpoorIDs.txt', 'a')\n",
    "intronrich_file_OUN333 = open('Output/OUN333_intronrichIDs.txt', 'a')\n",
    "for i in range(len(intronless_OUN333)):\n",
    "    if i == len(intronless_OUN333) -1:\n",
    "        intronless_file_OUN333.write(intronless_OUN333[i])\n",
    "    else:\n",
    "        intronless_file_OUN333.write(intronless_OUN333[i] + '\\n')\n",
    "intronless_file_OUN333.close()\n",
    "\n",
    "for i in range(len(intronpoor_OUN333)):\n",
    "    if i == len(intronpoor_OUN333) -1:\n",
    "        intronpoor_file_OUN333.write(intronpoor_OUN333[i])\n",
    "    else:\n",
    "        intronpoor_file_OUN333.write(intronpoor_OUN333[i] + '\\n')\n",
    "intronpoor_file_OUN333.close()\n",
    "\n",
    "for i in range(len(intronrich_OUN333)):\n",
    "    if i == len(intronrich_OUN333) -1:\n",
    "        intronrich_file_OUN333.write(intronrich_OUN333[i])\n",
    "    else:\n",
    "        intronrich_file_OUN333.write(intronrich_OUN333[i]+'\\n')\n",
    "intronrich_file_OUN333.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Storing the number of transcripts in intron-less/poor/rich genes within a variable \n",
    "n_mRNA_intronless_OUN333 = ! grep -f Output/OUN333_intronlessIDs.txt Data/OUN333_nohashtag.gff3 | awk -F '\\t' '{print $3}' | grep -w 'mRNA' | wc -l\n",
    "n_mRNA_intronpoor_OUN333 = ! grep -f Output/OUN333_intronpoorIDs.txt Data/OUN333_nohashtag.gff3 | awk -F '\\t' '{print $3}' | grep -w 'mRNA' | wc -l\n",
    "n_mRNA_intronrich_OUN333 = ! grep -f Output/OUN333_intronrichIDs.txt Data/OUN333_nohashtag.gff3 | awk -F '\\t' '{print $3}' | grep -w 'mRNA' | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### --- Checking the average number of transcripts for each gene-type\n",
    "avg_mRNA_intronless_OUN333 = int(n_mRNA_intronless_OUN333[0])/n_intronless_OUN333\n",
    "print(avg_mRNA_intronless_OUN333)\n",
    "avg_mRNA_intronpoor_OUN333 = int(n_mRNA_intronpoor_OUN333[0])/n_intronpoor_OUN333\n",
    "print(avg_mRNA_intronpoor_OUN333)\n",
    "avg_mRNA_intronrich_OUN333 = int(n_mRNA_intronrich_OUN333[0])/n_intronrich_OUN333\n",
    "print(avg_mRNA_intronrich_OUN333)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No alternative splicing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Basic statistics of OUN333 introns\n",
    "introns_OUN333['length'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Plotting the distribution of OUN333 introns length\n",
    "introns_OUN333['length'].plot.density()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Plotting the boxplot of OUN333 introns length without outliers\n",
    "introns_OUN333.boxplot(column='length', return_type='axes', showfliers=False) # showfliers = False -> discard outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.21.4 Re-organizing files and directories "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls Data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir Data/OUN333"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mv Data/OUN333_* Data/OUN333"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls Data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls Output/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir Output/OUN333"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mv Output/OUN333_* Output/OUN333"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls Output/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.22 RGT_Planet - Gene projection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.22.1 Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- This will download the raw data to the subdirectory raw under the directory Data\n",
    "! wget -O Data/raw/RGT_Planet.gff3 https://doi.ipk-gatersleben.de/DOI/c4d433dc-bf7c-4ad9-9368-69bb77837ca5/92f038bd-4112-42a0-aa90-431940f82159/1/DOWNLOAD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.22.2 Processing Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- There is no need to import the libraries again\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Removing all hashtags from the gff3 file\n",
    "! sed '/#/d' Data/raw/RGT_Planet.gff3  > Data/RGT_Planet_nohashtag.gff3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Changing the gff3 file to a csv format file to import it with pandas\n",
    "! cat Data/RGT_Planet_nohashtag.gff3 | sed 's/,/--/g' | sed 's/;/--/g' | sed 's/\\t/,/g' | awk -F '--' '{print $1}' > Data/RGT_Planet_nohashtag.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Transforming the gff3 file to a pandas dataframe to better handle it\n",
    "df_RGT_Planet = pd.read_csv('Data/RGT_Planet_nohashtag.csv', header=None, names = ['chr', 'source', 'type','start','end','score','strand','phase','attributes'])\n",
    "df_RGT_Planet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Building a separate dataframe containing all exons\n",
    "exon_RGT_Planet = df_RGT_Planet.loc[df_RGT_Planet['type'].isin(['exon'])]\n",
    "exon_RGT_Planet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Exporting the exon dataframe to a tsv file \n",
    "exon_RGT_Planet.to_csv('Data/RGT_Planet_exon.tsv',sep='\\t',index=False,header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Keeping in a separated dataframe the forward strands\n",
    "forw_RGT_Planet = df_RGT_Planet.loc[df_RGT_Planet['strand'].isin(['+'])]\n",
    "forw_RGT_Planet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Keeping in a separated dataframe the reverse strands\n",
    "rev_RGT_Planet = df_RGT_Planet.loc[df_RGT_Planet['strand'].isin(['-'])]\n",
    "rev_RGT_Planet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Keeping in a separated dataframe the UTR regions on the forward strands\n",
    "UTR_forw_RGT_Planet = forw_RGT_Planet.loc[df_RGT_Planet['type'].isin(['three_prime_UTR','five_prime_UTR'])]\n",
    "UTR_forw_RGT_Planet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Keeping in a separated dataframe the UTR regions on the reverse strands\n",
    "UTR_rev_RGT_Planet = rev_RGT_Planet.loc[df_RGT_Planet['type'].isin(['three_prime_UTR','five_prime_UTR'])]\n",
    "UTR_rev_RGT_Planet.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No UTRs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.22.3 Extracting introns from the whole genome "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Extracting introns from RGT_Planet\n",
    "extract_tot_introns_gp('Data/RGT_Planet_exon.tsv', 'Output/RGT_Planet_introns.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "introns_RGT_Planet = pd.read_csv('Output/RGT_Planet_introns.tsv', sep = '\\t')\n",
    "introns_RGT_Planet[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Counting introns type in RGT_Planet\n",
    "introns_dictionary_RGT_Planet = counting_introns_type_gp(exon_RGT_Planet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_intronless_RGT_Planet, n_intronpoor_RGT_Planet, n_intronrich_RGT_Planet, intronless_RGT_Planet, intronpoor_RGT_Planet, intronrich_RGT_Planet = splitting_introns_type(introns_dictionary_RGT_Planet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting_intron_types(n_intronless_RGT_Planet, n_intronpoor_RGT_Planet, n_intronrich_RGT_Planet, 'Genes RGT_Planet Distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Creating the list of RGT_Planet gene IDs to check the number of transcripts using command line\n",
    "intronless_file_RGT_Planet = open('Output/RGT_Planet_intronlessIDs.txt', 'a')\n",
    "intronpoor_file_RGT_Planet = open('Output/RGT_Planet_intronpoorIDs.txt', 'a')\n",
    "intronrich_file_RGT_Planet = open('Output/RGT_Planet_intronrichIDs.txt', 'a')\n",
    "for i in range(len(intronless_RGT_Planet)):\n",
    "    if i == len(intronless_RGT_Planet) -1:\n",
    "        intronless_file_RGT_Planet.write(intronless_RGT_Planet[i])\n",
    "    else:\n",
    "        intronless_file_RGT_Planet.write(intronless_RGT_Planet[i] + '\\n')\n",
    "intronless_file_RGT_Planet.close()\n",
    "\n",
    "for i in range(len(intronpoor_RGT_Planet)):\n",
    "    if i == len(intronpoor_RGT_Planet) -1:\n",
    "        intronpoor_file_RGT_Planet.write(intronpoor_RGT_Planet[i])\n",
    "    else:\n",
    "        intronpoor_file_RGT_Planet.write(intronpoor_RGT_Planet[i] + '\\n')\n",
    "intronpoor_file_RGT_Planet.close()\n",
    "\n",
    "for i in range(len(intronrich_RGT_Planet)):\n",
    "    if i == len(intronrich_RGT_Planet) -1:\n",
    "        intronrich_file_RGT_Planet.write(intronrich_RGT_Planet[i])\n",
    "    else:\n",
    "        intronrich_file_RGT_Planet.write(intronrich_RGT_Planet[i]+'\\n')\n",
    "intronrich_file_RGT_Planet.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Storing the number of transcripts in intron-less/poor/rich genes within a variable \n",
    "n_mRNA_intronless_RGT_Planet = ! grep -f Output/RGT_Planet_intronlessIDs.txt Data/RGT_Planet_nohashtag.gff3 | awk -F '\\t' '{print $3}' | grep -w 'mRNA' | wc -l\n",
    "n_mRNA_intronpoor_RGT_Planet = ! grep -f Output/RGT_Planet_intronpoorIDs.txt Data/RGT_Planet_nohashtag.gff3 | awk -F '\\t' '{print $3}' | grep -w 'mRNA' | wc -l\n",
    "n_mRNA_intronrich_RGT_Planet = ! grep -f Output/RGT_Planet_intronrichIDs.txt Data/RGT_Planet_nohashtag.gff3 | awk -F '\\t' '{print $3}' | grep -w 'mRNA' | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### --- Checking the average number of transcripts for each gene-type\n",
    "avg_mRNA_intronless_RGT_Planet = int(n_mRNA_intronless_RGT_Planet[0])/n_intronless_RGT_Planet\n",
    "print(avg_mRNA_intronless_RGT_Planet)\n",
    "avg_mRNA_intronpoor_RGT_Planet = int(n_mRNA_intronpoor_RGT_Planet[0])/n_intronpoor_RGT_Planet\n",
    "print(avg_mRNA_intronpoor_RGT_Planet)\n",
    "avg_mRNA_intronrich_RGT_Planet = int(n_mRNA_intronrich_RGT_Planet[0])/n_intronrich_RGT_Planet\n",
    "print(avg_mRNA_intronrich_RGT_Planet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No alternative splicing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Basic statistics of RGT_Planet introns\n",
    "introns_RGT_Planet['length'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Plotting the distribution of RGT_Planet introns length\n",
    "introns_RGT_Planet['length'].plot.density()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Plotting the boxplot of RGT_Planet introns length without outliers\n",
    "introns_RGT_Planet.boxplot(column='length', return_type='axes', showfliers=False) # showfliers = False -> discard outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.22.4 Re-organizing files and directories "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls Data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir Data/RGT_Planet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mv Data/RGT_Planet_* Data/RGT_Planet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls Data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls Output/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir Output/RGT_Planet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mv Output/RGT_Planet_* Output/RGT_Planet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls Output/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.23 ZDM01467 - Gene projection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.23.1 Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### --- This will download the raw data to the subdirectory raw under the directory Data\n",
    "! wget -O Data/raw/ZDM01467.gff3 https://doi.ipk-gatersleben.de/DOI/c4d433dc-bf7c-4ad9-9368-69bb77837ca5/6e7e8cf3-08d2-4f25-8dac-4eb70f2241dd/1/DOWNLOAD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.23.2 Processing Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- There is no need to import the libraries again\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Removing all hashtags from the gff3 file\n",
    "! sed '/#/d' Data/raw/ZDM01467.gff3  > Data/ZDM01467_nohashtag.gff3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Changing the gff3 file to a csv format file to import it with pandas\n",
    "! cat Data/ZDM01467_nohashtag.gff3 | sed 's/,/--/g' | sed 's/;/--/g' | sed 's/\\t/,/g' | awk -F '--' '{print $1}' > Data/ZDM01467_nohashtag.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Transforming the gff3 file to a pandas dataframe to better handle it\n",
    "df_ZDM01467 = pd.read_csv('Data/ZDM01467_nohashtag.csv', header=None, names = ['chr', 'source', 'type','start','end','score','strand','phase','attributes'])\n",
    "df_ZDM01467.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Building a separate dataframe containing all exons\n",
    "exon_ZDM01467 = df_ZDM01467.loc[df_ZDM01467['type'].isin(['exon'])]\n",
    "exon_ZDM01467.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Exporting the exon dataframe to a tsv file \n",
    "exon_ZDM01467.to_csv('Data/ZDM01467_exon.tsv',sep='\\t',index=False,header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Keeping in a separated dataframe the forward strands\n",
    "forw_ZDM01467 = df_ZDM01467.loc[df_ZDM01467['strand'].isin(['+'])]\n",
    "forw_ZDM01467.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Keeping in a separated dataframe the reverse strands\n",
    "rev_ZDM01467 = df_ZDM01467.loc[df_ZDM01467['strand'].isin(['-'])]\n",
    "rev_ZDM01467.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Keeping in a separated dataframe the UTR regions on the forward strands\n",
    "UTR_forw_ZDM01467 = forw_ZDM01467.loc[df_ZDM01467['type'].isin(['three_prime_UTR','five_prime_UTR'])]\n",
    "UTR_forw_ZDM01467.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Keeping in a separated dataframe the UTR regions on the reverse strands\n",
    "UTR_rev_ZDM01467 = rev_ZDM01467.loc[df_ZDM01467['type'].isin(['three_prime_UTR','five_prime_UTR'])]\n",
    "UTR_rev_ZDM01467.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No UTRs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.23.3 Extracting introns from the whole genome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Extracting introns from ZDM01467\n",
    "extract_tot_introns_gp('Data/ZDM01467_exon.tsv', 'Output/ZDM01467_introns.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "introns_ZDM01467 = pd.read_csv('Output/ZDM01467_introns.tsv', sep = '\\t')\n",
    "introns_ZDM01467[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Counting introns type in ZDM01467\n",
    "introns_dictionary_ZDM01467 = counting_introns_type_gp(exon_ZDM01467)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_intronless_ZDM01467, n_intronpoor_ZDM01467, n_intronrich_ZDM01467, intronless_ZDM01467, intronpoor_ZDM01467, intronrich_ZDM01467 = splitting_introns_type(introns_dictionary_ZDM01467)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting_intron_types(n_intronless_ZDM01467, n_intronpoor_ZDM01467, n_intronrich_ZDM01467, 'Genes ZDM01467 Distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Creating the list of ZDM01467 gene IDs to check the number of transcripts using command line\n",
    "intronless_file_ZDM01467 = open('Output/ZDM01467_intronlessIDs.txt', 'a')\n",
    "intronpoor_file_ZDM01467 = open('Output/ZDM01467_intronpoorIDs.txt', 'a')\n",
    "intronrich_file_ZDM01467 = open('Output/ZDM01467_intronrichIDs.txt', 'a')\n",
    "for i in range(len(intronless_ZDM01467)):\n",
    "    if i == len(intronless_ZDM01467) -1:\n",
    "        intronless_file_ZDM01467.write(intronless_ZDM01467[i])\n",
    "    else:\n",
    "        intronless_file_ZDM01467.write(intronless_ZDM01467[i] + '\\n')\n",
    "intronless_file_ZDM01467.close()\n",
    "\n",
    "for i in range(len(intronpoor_ZDM01467)):\n",
    "    if i == len(intronpoor_ZDM01467) -1:\n",
    "        intronpoor_file_ZDM01467.write(intronpoor_ZDM01467[i])\n",
    "    else:\n",
    "        intronpoor_file_ZDM01467.write(intronpoor_ZDM01467[i] + '\\n')\n",
    "intronpoor_file_ZDM01467.close()\n",
    "\n",
    "for i in range(len(intronrich_ZDM01467)):\n",
    "    if i == len(intronrich_ZDM01467) -1:\n",
    "        intronrich_file_ZDM01467.write(intronrich_ZDM01467[i])\n",
    "    else:\n",
    "        intronrich_file_ZDM01467.write(intronrich_ZDM01467[i]+'\\n')\n",
    "intronrich_file_ZDM01467.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Storing the number of transcripts in intron-less/poor/rich genes within a variable \n",
    "n_mRNA_intronless_ZDM01467 = ! grep -f Output/ZDM01467_intronlessIDs.txt Data/ZDM01467_nohashtag.gff3 | awk -F '\\t' '{print $3}' | grep -w 'mRNA' | wc -l\n",
    "n_mRNA_intronpoor_ZDM01467 = ! grep -f Output/ZDM01467_intronpoorIDs.txt Data/ZDM01467_nohashtag.gff3 | awk -F '\\t' '{print $3}' | grep -w 'mRNA' | wc -l\n",
    "n_mRNA_intronrich_ZDM01467 = ! grep -f Output/ZDM01467_intronrichIDs.txt Data/ZDM01467_nohashtag.gff3 | awk -F '\\t' '{print $3}' | grep -w 'mRNA' | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### --- Checking the average number of transcripts for each gene-type\n",
    "avg_mRNA_intronless_ZDM01467 = int(n_mRNA_intronless_ZDM01467[0])/n_intronless_ZDM01467\n",
    "print(avg_mRNA_intronless_ZDM01467)\n",
    "avg_mRNA_intronpoor_ZDM01467 = int(n_mRNA_intronpoor_ZDM01467[0])/n_intronpoor_ZDM01467\n",
    "print(avg_mRNA_intronpoor_ZDM01467)\n",
    "avg_mRNA_intronrich_ZDM01467 = int(n_mRNA_intronrich_ZDM01467[0])/n_intronrich_ZDM01467\n",
    "print(avg_mRNA_intronrich_ZDM01467)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No alternative splicing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Basic statistics of ZDM01467 introns\n",
    "introns_ZDM01467['length'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Plotting the distribution of ZDM01467 introns length\n",
    "introns_ZDM01467['length'].plot.density()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Plotting the boxplot of ZDM01467 introns length without outliers\n",
    "introns_ZDM01467.boxplot(column='length', return_type='axes', showfliers=False) # showfliers = False -> discard outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.23.4 Re-organizing files and directories "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls Data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir Data/ZDM01467"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mv Data/ZDM01467_* Data/ZDM01467"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls Data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls Output/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir Output/ZDM01467"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mv Output/ZDM01467_* Output/ZDM01467"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls Output/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.24 ZDM02064 - Gene projection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.24.1 Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- This will download the raw data to the subdirectory raw under the directory Data\n",
    "! wget -O Data/raw/ZDM02064.gff3 https://doi.ipk-gatersleben.de/DOI/c4d433dc-bf7c-4ad9-9368-69bb77837ca5/68d247e5-6cb3-4ba6-bcd6-89fa8e69a6c6/1/DOWNLOAD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.24.2 Processing Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- There is no need to import the libraries again\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Removing all hashtags from the gff3 file\n",
    "! sed '/#/d' Data/raw/ZDM02064.gff3  > Data/ZDM02064_nohashtag.gff3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Changing the gff3 file to a csv format file to import it with pandas\n",
    "! cat Data/ZDM02064_nohashtag.gff3 | sed 's/,/--/g' | sed 's/;/--/g' | sed 's/\\t/,/g' | awk -F '--' '{print $1}' > Data/ZDM02064_nohashtag.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Transforming the gff3 file to a pandas dataframe to better handle it\n",
    "df_ZDM02064 = pd.read_csv('Data/ZDM02064_nohashtag.csv', header=None, names = ['chr', 'source', 'type','start','end','score','strand','phase','attributes'])\n",
    "df_ZDM02064.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Building a separate dataframe containing all exons\n",
    "exon_ZDM02064 = df_ZDM02064.loc[df_ZDM02064['type'].isin(['exon'])]\n",
    "exon_ZDM02064.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Exporting the exon dataframe to a tsv file \n",
    "exon_ZDM02064.to_csv('Data/ZDM02064_exon.tsv',sep='\\t',index=False,header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Keeping in a separated dataframe the forward strands\n",
    "forw_ZDM02064 = df_ZDM02064.loc[df_ZDM02064['strand'].isin(['+'])]\n",
    "forw_ZDM02064.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Keeping in a separated dataframe the reverse strands\n",
    "rev_ZDM02064 = df_ZDM02064.loc[df_ZDM02064['strand'].isin(['-'])]\n",
    "rev_ZDM02064.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Keeping in a separated dataframe the UTR regions on the forward strands\n",
    "UTR_forw_ZDM02064 = forw_ZDM02064.loc[df_ZDM02064['type'].isin(['three_prime_UTR','five_prime_UTR'])]\n",
    "UTR_forw_ZDM02064.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Keeping in a separated dataframe the UTR regions on the reverse strands\n",
    "UTR_rev_ZDM02064 = rev_ZDM02064.loc[df_ZDM02064['type'].isin(['three_prime_UTR','five_prime_UTR'])]\n",
    "UTR_rev_ZDM02064.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No UTRs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.24.3 Extracting introns from the whole genome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Extracting introns from ZDM02064\n",
    "extract_tot_introns_gp('Data/ZDM02064_exon.tsv', 'Output/ZDM02064_introns.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "introns_ZDM02064 = pd.read_csv('Output/ZDM02064_introns.tsv', sep = '\\t')\n",
    "introns_ZDM02064[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Counting introns type in ZDM02064\n",
    "introns_dictionary_ZDM02064 = counting_introns_type_gp(exon_ZDM02064)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_intronless_ZDM02064, n_intronpoor_ZDM02064, n_intronrich_ZDM02064, intronless_ZDM02064, intronpoor_ZDM02064, intronrich_ZDM02064 = splitting_introns_type(introns_dictionary_ZDM02064)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting_intron_types(n_intronless_ZDM02064, n_intronpoor_ZDM02064, n_intronrich_ZDM02064, 'Genes ZDM02064 Distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Creating the list of ZDM02064 gene IDs to check the number of transcripts using command line\n",
    "intronless_file_ZDM02064 = open('Output/ZDM02064_intronlessIDs.txt', 'a')\n",
    "intronpoor_file_ZDM02064 = open('Output/ZDM02064_intronpoorIDs.txt', 'a')\n",
    "intronrich_file_ZDM02064 = open('Output/ZDM02064_intronrichIDs.txt', 'a')\n",
    "for i in range(len(intronless_ZDM02064)):\n",
    "    if i == len(intronless_ZDM02064) -1:\n",
    "        intronless_file_ZDM02064.write(intronless_ZDM02064[i])\n",
    "    else:\n",
    "        intronless_file_ZDM02064.write(intronless_ZDM02064[i] + '\\n')\n",
    "intronless_file_ZDM02064.close()\n",
    "\n",
    "for i in range(len(intronpoor_ZDM02064)):\n",
    "    if i == len(intronpoor_ZDM02064) -1:\n",
    "        intronpoor_file_ZDM02064.write(intronpoor_ZDM02064[i])\n",
    "    else:\n",
    "        intronpoor_file_ZDM02064.write(intronpoor_ZDM02064[i] + '\\n')\n",
    "intronpoor_file_ZDM02064.close()\n",
    "\n",
    "for i in range(len(intronrich_ZDM02064)):\n",
    "    if i == len(intronrich_ZDM02064) -1:\n",
    "        intronrich_file_ZDM02064.write(intronrich_ZDM02064[i])\n",
    "    else:\n",
    "        intronrich_file_ZDM02064.write(intronrich_ZDM02064[i]+'\\n')\n",
    "intronrich_file_ZDM02064.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Storing the number of transcripts in intron-less/poor/rich genes within a variable \n",
    "n_mRNA_intronless_ZDM02064 = ! grep -f Output/ZDM02064_intronlessIDs.txt Data/ZDM02064_nohashtag.gff3 | awk -F '\\t' '{print $3}' | grep -w 'mRNA' | wc -l\n",
    "n_mRNA_intronpoor_ZDM02064 = ! grep -f Output/ZDM02064_intronpoorIDs.txt Data/ZDM02064_nohashtag.gff3 | awk -F '\\t' '{print $3}' | grep -w 'mRNA' | wc -l\n",
    "n_mRNA_intronrich_ZDM02064 = ! grep -f Output/ZDM02064_intronrichIDs.txt Data/ZDM02064_nohashtag.gff3 | awk -F '\\t' '{print $3}' | grep -w 'mRNA' | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Checking the average number of transcripts for each gene-type\n",
    "avg_mRNA_intronless_ZDM02064 = int(n_mRNA_intronless_ZDM02064[0])/n_intronless_ZDM02064\n",
    "print(avg_mRNA_intronless_ZDM02064)\n",
    "avg_mRNA_intronpoor_ZDM02064 = int(n_mRNA_intronpoor_ZDM02064[0])/n_intronpoor_ZDM02064\n",
    "print(avg_mRNA_intronpoor_ZDM02064)\n",
    "avg_mRNA_intronrich_ZDM02064 = int(n_mRNA_intronrich_ZDM02064[0])/n_intronrich_ZDM02064\n",
    "print(avg_mRNA_intronrich_ZDM02064)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No alternative splicing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Basic statistics of ZDM02064 introns\n",
    "introns_ZDM02064['length'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Plotting the distribution of ZDM02064 introns length\n",
    "introns_ZDM02064['length'].plot.density()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Plotting the boxplot of ZDM02064 introns length without outliers\n",
    "introns_ZDM02064.boxplot(column='length', return_type='axes', showfliers=False) # showfliers = False -> discard outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.24.4 Re-organizing files and directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls Data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir Data/ZDM02064"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mv Data/ZDM02064_* Data/ZDM02064"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls Data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls Output/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir Output/ZDM02064"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mv Output/ZDM02064_* Output/ZDM02064"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls Output/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Extracting from fasta the corresponding introns UTR sequences in Hv_MorexHC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 878,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>type</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID=HORVU.MOREX.r3.1HG0000070.1</td>\n",
       "      <td>intron five_prime_UTR</td>\n",
       "      <td>146750</td>\n",
       "      <td>146980</td>\n",
       "      <td>232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID=HORVU.MOREX.r3.1HG0000080.1</td>\n",
       "      <td>intron five_prime_UTR</td>\n",
       "      <td>153530</td>\n",
       "      <td>153625</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID=HORVU.MOREX.r3.1HG0000620.1</td>\n",
       "      <td>intron five_prime_UTR</td>\n",
       "      <td>1614154</td>\n",
       "      <td>1615780</td>\n",
       "      <td>1628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID=HORVU.MOREX.r3.1HG0000620.2</td>\n",
       "      <td>intron five_prime_UTR</td>\n",
       "      <td>1614154</td>\n",
       "      <td>1615780</td>\n",
       "      <td>1628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID=HORVU.MOREX.r3.1HG0000620.3</td>\n",
       "      <td>intron five_prime_UTR</td>\n",
       "      <td>1614665</td>\n",
       "      <td>1615780</td>\n",
       "      <td>1117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5044</th>\n",
       "      <td>ID=HORVU.MOREX.r3.7HG0752050.1</td>\n",
       "      <td>intron five_prime_UTR</td>\n",
       "      <td>628813527</td>\n",
       "      <td>628813619</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5045</th>\n",
       "      <td>ID=HORVU.MOREX.r3.7HG0752790.1</td>\n",
       "      <td>intron three_prime_UTR</td>\n",
       "      <td>631981108</td>\n",
       "      <td>631981202</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5046</th>\n",
       "      <td>ID=HORVU.MOREX.r3.7HG0752950.1</td>\n",
       "      <td>intron five_prime_UTR</td>\n",
       "      <td>632146924</td>\n",
       "      <td>632147308</td>\n",
       "      <td>386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5047</th>\n",
       "      <td>ID=HORVU.MOREX.r3.UnG0753140.1</td>\n",
       "      <td>intron five_prime_UTR</td>\n",
       "      <td>475717</td>\n",
       "      <td>475945</td>\n",
       "      <td>230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5048</th>\n",
       "      <td>ID=HORVU.MOREX.r3.UnG0753140.1</td>\n",
       "      <td>intron five_prime_UTR</td>\n",
       "      <td>476070</td>\n",
       "      <td>480556</td>\n",
       "      <td>4488</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5049 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  ID                    type      start  \\\n",
       "0     ID=HORVU.MOREX.r3.1HG0000070.1   intron five_prime_UTR     146750   \n",
       "1     ID=HORVU.MOREX.r3.1HG0000080.1   intron five_prime_UTR     153530   \n",
       "2     ID=HORVU.MOREX.r3.1HG0000620.1   intron five_prime_UTR    1614154   \n",
       "3     ID=HORVU.MOREX.r3.1HG0000620.2   intron five_prime_UTR    1614154   \n",
       "4     ID=HORVU.MOREX.r3.1HG0000620.3   intron five_prime_UTR    1614665   \n",
       "...                              ...                     ...        ...   \n",
       "5044  ID=HORVU.MOREX.r3.7HG0752050.1   intron five_prime_UTR  628813527   \n",
       "5045  ID=HORVU.MOREX.r3.7HG0752790.1  intron three_prime_UTR  631981108   \n",
       "5046  ID=HORVU.MOREX.r3.7HG0752950.1   intron five_prime_UTR  632146924   \n",
       "5047  ID=HORVU.MOREX.r3.UnG0753140.1   intron five_prime_UTR     475717   \n",
       "5048  ID=HORVU.MOREX.r3.UnG0753140.1   intron five_prime_UTR     476070   \n",
       "\n",
       "            end  length  \n",
       "0        146980     232  \n",
       "1        153625      97  \n",
       "2       1615780    1628  \n",
       "3       1615780    1628  \n",
       "4       1615780    1117  \n",
       "...         ...     ...  \n",
       "5044  628813619      94  \n",
       "5045  631981202      96  \n",
       "5046  632147308     386  \n",
       "5047     475945     230  \n",
       "5048     480556    4488  \n",
       "\n",
       "[5049 rows x 5 columns]"
      ]
     },
     "execution_count": 878,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### --- Re-generating the full UTR introns dataframe\n",
    "introns_UTR_forw_Hv_MorexHC, introns_UTR_rev_Hv_MorexHC = pd.read_csv('Output/Hv_Morex_longread/Hv_MorexHC_UTRforw_introns.tsv', sep='\\t'), pd.read_csv('Output/Hv_Morex_longread/Hv_MorexHC_UTRrev_introns.tsv', sep = '\\t')\n",
    "frames_Hv_MorexHC = [introns_UTR_forw_Hv_MorexHC, introns_UTR_rev_Hv_MorexHC]\n",
    "introns_UTR_Hv_MorexHC = pd.concat(frames_Hv_MorexHC).reset_index(drop=True)\n",
    "introns_UTR_Hv_MorexHC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 879,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-09-04 12:40:44--  https://doi.ipk-gatersleben.de/DOI/b2f47dfb-47ff-4114-89ae-bad8dcc515a1/b6e6a2e5-2746-4522-8465-019c8f56df7f/1/DOWNLOAD\n",
      "Resolving doi.ipk-gatersleben.de (doi.ipk-gatersleben.de)... 194.94.136.144\n",
      "Connecting to doi.ipk-gatersleben.de (doi.ipk-gatersleben.de)|194.94.136.144|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 4296032540 (4,0G) [text/plain]\n",
      "Saving to: ‘Data/raw/Barley_MorexV3_pseudomolecules.fasta’\n",
      "\n",
      "Data/raw/Barley_Mor 100%[===================>]   4,00G  1,26MB/s    in 53m 25s \n",
      "\n",
      "2021-09-04 13:34:10 (1,28 MB/s) - ‘Data/raw/Barley_MorexV3_pseudomolecules.fasta’ saved [4296032540/4296032540]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### --- Downloading the fast from we will extract the sequences corresponding to the introns UTR.\n",
    "### --- The next line has been commented due to the fact I previously downloaded this file. \n",
    "\n",
    "! wget -O Data/raw/Barley_MorexV3_pseudomolecules.fasta https://doi.ipk-gatersleben.de/DOI/b2f47dfb-47ff-4114-89ae-bad8dcc515a1/b6e6a2e5-2746-4522-8465-019c8f56df7f/1/DOWNLOAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 880,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">chr1H\r\n",
      "GTTCCCGCTTCGATCCAAACATTTCGAGAACCAGGGGTCCGGTTATGTGGAACTCGTCAA\r\n",
      "AACACGCAGTTTTGGCCTATTCCGGCGAGTTTAGTAAGGTACTACTCACTGATTTTGGTT\r\n",
      "GCCCCTATGATTCGAACGTTTTGGGAACCCCGAGGTCCGATTACGGGGAACTCGTCAAAA\r\n",
      "CTCACAGTTTTGTCCTATTCTGGCCAGTTTTGTATGCTATTACTCACTGATTTTGGGTCC\r\n",
      "CGCTGTGATCGAACTTTTCGGAAACCCCAGGTTTCGGGTCCGGTTACGGGGAACTCGTCA\r\n",
      "AAACTCACAGTTTTGGTCTATTCCGGCCAGTTTTGTTCGCTATTAGTCACTGATTTTGGG\r\n",
      "TCGTGGTGCCATCCGAACGTTTCGTGAACCCCGGGGTCGAGTTATGGGGAAATCATGAAA\r\n",
      "ACTCGCAGTTTTGGCCTTTTCCCCCAGTTTTTTATGCTATTACTCACTGATTTTAGGTCC\r\n",
      "CACTGCGATACAAATTTCTCAAGAACCGAGGGGTCCGGTTACCTGGAACTCATCGAAACA\r\n"
     ]
    }
   ],
   "source": [
    "### --- Check the file just downloaded \n",
    "! head Data/raw/Barley_MorexV3_pseudomolecules.fasta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 881,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:>chr1H\n",
      "8608435:>chr2H\n",
      "19701532:>chr3H\n",
      "30060142:>chr4H\n",
      "40232369:>chr5H\n",
      "50036015:>chr6H\n",
      "59399258:>chr7H\n",
      "69941602:>chrUn\n"
     ]
    }
   ],
   "source": [
    "### --- Check where the occurence of >chr_number are within the file\n",
    "! grep -n '>chr' Data/raw/Barley_MorexV3_pseudomolecules.fasta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 882,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tail: error writing 'standard output': Broken pipe\n",
      "tail: error writing 'standard output': Broken pipe\n",
      "tail: error writing 'standard output': Broken pipe\n",
      "tail: error writing 'standard output': Broken pipe\n",
      "tail: error writing 'standard output': Broken pipe\n",
      "tail: error writing 'standard output': Broken pipe\n"
     ]
    }
   ],
   "source": [
    "### --- Based on the previous output divide the total fasta in smaller fasta containing information about 1 chromosome each\n",
    "### --- I directly run them from the terminal and not within the Notebook due to the fact within the Notebook I obtained a Broken pipe error\n",
    "\n",
    "! head -8608434 Data/raw/Barley_MorexV3_pseudomolecules.fasta > Data/Barley_MorexV3_pseudomolecules_chr1.fasta\n",
    "! tail -n +8608435 Data/raw/Barley_MorexV3_pseudomolecules.fasta | head -11093097 > Data/Barley_MorexV3_pseudomolecules_chr2.fasta\n",
    "! tail -n +19701532 Data/raw/Barley_MorexV3_pseudomolecules.fasta | head -10358610 > Data/Barley_MorexV3_pseudomolecules_chr3.fasta\n",
    "! tail -n +30060142 Data/raw/Barley_MorexV3_pseudomolecules.fasta | head -10172227 > Data/Barley_MorexV3_pseudomolecules_chr4.fasta\n",
    "! tail -n +40232369 Data/raw/Barley_MorexV3_pseudomolecules.fasta | head -9803646 > Data/Barley_MorexV3_pseudomolecules_chr5.fasta\n",
    "! tail -n +50036015 Data/raw/Barley_MorexV3_pseudomolecules.fasta | head -9363243 > Data/Barley_MorexV3_pseudomolecules_chr6.fasta\n",
    "! tail -n +59399258 Data/raw/Barley_MorexV3_pseudomolecules.fasta | head -10542344 > Data/Barley_MorexV3_pseudomolecules_chr7.fasta\n",
    "! tail -n +69941602 Data/raw/Barley_MorexV3_pseudomolecules.fasta > Data/Barley_MorexV3_pseudomolecules_chrUn.fasta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 883,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Writing the dataframe to a tsv file\n",
    "introns_UTR_Hv_MorexHC.to_csv('Output/Hv_Morex_longread/Hv_MorexHC_UTRtot.tsv', sep='\\t', header = True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 884,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID\ttype\tstart\tend\tlength\r\n",
      "ID=HORVU.MOREX.r3.1HG0000070.1\tintron five_prime_UTR\t146750\t146980\t232\r\n",
      "ID=HORVU.MOREX.r3.1HG0000080.1\tintron five_prime_UTR\t153530\t153625\t97\r\n",
      "ID=HORVU.MOREX.r3.1HG0000620.1\tintron five_prime_UTR\t1614154\t1615780\t1628\r\n",
      "ID=HORVU.MOREX.r3.1HG0000620.2\tintron five_prime_UTR\t1614154\t1615780\t1628\r\n",
      "ID=HORVU.MOREX.r3.1HG0000620.3\tintron five_prime_UTR\t1614665\t1615780\t1117\r\n",
      "ID=HORVU.MOREX.r3.1HG0000670.1\tintron five_prime_UTR\t1725555\t1726142\t589\r\n",
      "ID=HORVU.MOREX.r3.1HG0000990.1\tintron five_prime_UTR\t2301295\t2301473\t180\r\n",
      "ID=HORVU.MOREX.r3.1HG0002160.1\tintron five_prime_UTR\t4509034\t4509755\t723\r\n",
      "ID=HORVU.MOREX.r3.1HG0002160.2\tintron five_prime_UTR\t4509646\t4509755\t111\r\n"
     ]
    }
   ],
   "source": [
    "! head Output/Hv_Morex_longread/Hv_MorexHC_UTRtot.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 885,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Creating the file with the coordinates \n",
    "! cat Output/Hv_Morex_longread/Hv_MorexHC_UTRtot.tsv | tail -n+2 | awk -F '\\t' '{print $1,$3, $4}' > Output/Hv_Morex_longread/Hv_MorexHC_UTRintrons_coords.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 886,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID=HORVU.MOREX.r3.1HG0000070.1 146750 146980\r\n",
      "ID=HORVU.MOREX.r3.1HG0000080.1 153530 153625\r\n",
      "ID=HORVU.MOREX.r3.1HG0000620.1 1614154 1615780\r\n",
      "ID=HORVU.MOREX.r3.1HG0000620.2 1614154 1615780\r\n",
      "ID=HORVU.MOREX.r3.1HG0000620.3 1614665 1615780\r\n",
      "ID=HORVU.MOREX.r3.1HG0000670.1 1725555 1726142\r\n",
      "ID=HORVU.MOREX.r3.1HG0000990.1 2301295 2301473\r\n",
      "ID=HORVU.MOREX.r3.1HG0002160.1 4509034 4509755\r\n",
      "ID=HORVU.MOREX.r3.1HG0002160.2 4509646 4509755\r\n",
      "ID=HORVU.MOREX.r3.1HG0002450.1 5067209 5067686\r\n"
     ]
    }
   ],
   "source": [
    "! head Output/Hv_Morex_longread/Hv_MorexHC_UTRintrons_coords.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 887,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Importing a library to check the time spent running processes\n",
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 888,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_fasta_from_coords(coordinates, chr1, chr2, chr3, chr4, chr5, chr6, chr7, chrUn, f_out):\n",
    "    t_zero = timer() # Checking the computational time\n",
    "    out = open(f_out, 'a')\n",
    "    with open(coordinates) as coords:\n",
    "        for line in coords:\n",
    "            line = line.split()\n",
    "            seq = ''\n",
    "            if '.1H' in line[0]:     # Ceck if the coordinates refers to chr1\n",
    "                first_line = int(line[1])/60 +1     # This is due to the fasta file having 60 characters/row\n",
    "                last_line = int(line[2])/60 +1\n",
    "                interval = int(last_line) - int(first_line)\n",
    "                start = int(float(str(first_line-int(first_line))[1:])*60)      # Decimal part * 60 to know at which character of the line start\n",
    "                end = int(float(str(last_line - int(last_line))[1:])*60) + interval*60    # Same as before but to know where it ends\n",
    "                with open (chr1) as fasta:\n",
    "                    lines = fasta.readlines()\n",
    "                    for i in range(int(first_line), int(last_line)+1):\n",
    "                        f_line = lines[i]\n",
    "                        f_line = f_line.rstrip()\n",
    "                        seq += f_line\n",
    "                    seq = seq[start:end+1]\n",
    "                    out.write('>chr1'+':'+line[1]+':'+line[2]+':'+line[0])\n",
    "                    out.write('\\n'+seq+'\\n')\n",
    "            \n",
    "            elif '.2H' in line[0]:\n",
    "                first_line = int(line[1])/60 +1\n",
    "                last_line = int(line[2])/60 +1\n",
    "                interval = int(last_line) - int(first_line)\n",
    "                start = int(float(str(first_line-int(first_line))[1:])*60)\n",
    "                end = int(float(str(last_line - int(last_line))[1:])*60) + interval*60\n",
    "                with open (chr2) as fasta:\n",
    "                    lines = fasta.readlines()\n",
    "                    for i in range(int(first_line), int(last_line)+1):\n",
    "                        f_line = lines[i]\n",
    "                        f_line = f_line.rstrip()\n",
    "                        seq += f_line\n",
    "                    seq = seq[start:end+1]\n",
    "                    out.write('>chr2'+':'+line[1]+':'+line[2]+':'+line[0])\n",
    "                    out.write('\\n'+seq+'\\n')\n",
    "            \n",
    "            elif '.3H' in line[0]:\n",
    "                first_line = int(line[1])/60 +1\n",
    "                last_line = int(line[2])/60 +1\n",
    "                interval = int(last_line) - int(first_line)\n",
    "                start = int(float(str(first_line-int(first_line))[1:])*60)\n",
    "                end = int(float(str(last_line - int(last_line))[1:])*60) + interval*60\n",
    "                with open (chr3) as fasta:\n",
    "                    lines = fasta.readlines()\n",
    "                    for i in range(int(first_line), int(last_line)+1):\n",
    "                        f_line = lines[i]\n",
    "                        f_line = f_line.rstrip()\n",
    "                        seq += f_line\n",
    "                    seq = seq[start:end+1]\n",
    "                    out.write('>chr3'+':'+line[1]+':'+line[2]+':'+line[0])\n",
    "                    out.write('\\n'+seq+'\\n')\n",
    "\n",
    "            elif '.4H' in line[0]:\n",
    "                first_line = int(line[1])/60 +1\n",
    "                last_line = int(line[2])/60 +1\n",
    "                interval = int(last_line) - int(first_line)\n",
    "                start = int(float(str(first_line-int(first_line))[1:])*60)\n",
    "                end = int(float(str(last_line - int(last_line))[1:])*60) + interval*60\n",
    "                with open (chr4) as fasta:\n",
    "                    lines = fasta.readlines()\n",
    "                    for i in range(int(first_line), int(last_line)+1):\n",
    "                        f_line = lines[i]\n",
    "                        f_line = f_line.rstrip()\n",
    "                        seq += f_line\n",
    "                    seq = seq[start:end+1]\n",
    "                    out.write('>chr4'+':'+line[1]+':'+line[2]+':'+line[0])\n",
    "                    out.write('\\n'+seq+'\\n')\n",
    "\n",
    "            elif '.5H' in line[0]:\n",
    "                first_line = int(line[1])/60 +1\n",
    "                last_line = int(line[2])/60 +1\n",
    "                interval = int(last_line) - int(first_line)\n",
    "                start = int(float(str(first_line-int(first_line))[1:])*60)\n",
    "                end = int(float(str(last_line - int(last_line))[1:])*60) + interval*60\n",
    "                with open (chr5) as fasta:\n",
    "                    lines = fasta.readlines()\n",
    "                    for i in range(int(first_line), int(last_line)+1):\n",
    "                        f_line = lines[i]\n",
    "                        f_line = f_line.rstrip()\n",
    "                        seq += f_line\n",
    "                    seq = seq[start:end+1]\n",
    "                    out.write('>chr5'+':'+line[1]+':'+line[2]+':'+line[0])\n",
    "                    out.write('\\n'+seq+'\\n')\n",
    "\n",
    "            elif '.6H' in line[0]:\n",
    "                first_line = int(line[1])/60 +1\n",
    "                last_line = int(line[2])/60 +1\n",
    "                interval = int(last_line) - int(first_line)\n",
    "                start = int(float(str(first_line-int(first_line))[1:])*60)\n",
    "                end = int(float(str(last_line - int(last_line))[1:])*60) + interval*60\n",
    "                with open (chr6) as fasta:\n",
    "                    lines = fasta.readlines()\n",
    "                    for i in range(int(first_line), int(last_line)+1):\n",
    "                        f_line = lines[i]\n",
    "                        f_line = f_line.rstrip()\n",
    "                        seq += f_line\n",
    "                    seq = seq[start:end+1]\n",
    "                    out.write('>chr6'+':'+line[1]+':'+line[2]+':'+line[0])\n",
    "                    out.write('\\n'+seq+'\\n')\n",
    "        \n",
    "            elif '.7H' in line[0]:\n",
    "                first_line = int(line[1])/60 +1\n",
    "                last_line = int(line[2])/60 +1\n",
    "                interval = int(last_line) - int(first_line)\n",
    "                start = int(float(str(first_line-int(first_line))[1:])*60)\n",
    "                end = int(float(str(last_line - int(last_line))[1:])*60) + interval*60\n",
    "                with open (chr7) as fasta:\n",
    "                    lines = fasta.readlines()\n",
    "                    for i in range(int(first_line), int(last_line)+1):\n",
    "                        f_line = lines[i]\n",
    "                        f_line = f_line.rstrip()\n",
    "                        seq += f_line\n",
    "                    seq = seq[start:end+1]\n",
    "                    out.write('>chr7'+':'+line[1]+':'+line[2]+':'+line[0])\n",
    "                    out.write('\\n'+seq+'\\n')\n",
    "\n",
    "            elif '.Un' in line[0]:\n",
    "                first_line = int(line[1])/60 +1\n",
    "                last_line = int(line[2])/60 +1\n",
    "                interval = int(last_line) - int(first_line)\n",
    "                start = int(float(str(first_line-int(first_line))[1:])*60)\n",
    "                end = int(float(str(last_line - int(last_line))[1:])*60) + interval*60\n",
    "                with open (chrUn) as fasta:\n",
    "                    lines = fasta.readlines()\n",
    "                    for i in range(int(first_line), int(last_line)+1):\n",
    "                        f_line = lines[i]\n",
    "                        f_line = f_line.rstrip()\n",
    "                        seq += f_line\n",
    "                    seq = seq[start:end+1]\n",
    "                    out.write('>chrUn'+':'+line[1]+':'+line[2]+':'+line[0])\n",
    "                    out.write('\\n'+seq+'\\n')\n",
    "\n",
    "\n",
    "    out.close()\n",
    "    tot = timer() - t_zero\n",
    "    print('Running time (minutes): %.3f' % (tot/60))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 889,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_out = 'Output/Hv_Morex_longread/Hv_MorexHC_UTR_introns.fasta'\n",
    "coords = 'Output/Hv_Morex_longread/Hv_MorexHC_UTRintrons_coords.txt'\n",
    "chr1 = 'Data/Barley_MorexV3_pseudomolecules_chr1.fasta'\n",
    "chr2 = 'Data/Barley_MorexV3_pseudomolecules_chr2.fasta'\n",
    "chr3 = 'Data/Barley_MorexV3_pseudomolecules_chr3.fasta'\n",
    "chr4 = 'Data/Barley_MorexV3_pseudomolecules_chr4.fasta'\n",
    "chr5 = 'Data/Barley_MorexV3_pseudomolecules_chr5.fasta'\n",
    "chr6 = 'Data/Barley_MorexV3_pseudomolecules_chr6.fasta'\n",
    "chr7 = 'Data/Barley_MorexV3_pseudomolecules_chr7.fasta'\n",
    "chrUn = 'Data/Barley_MorexV3_pseudomolecules_chrUn.fasta'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 890,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running time (minutes): 112.362\n"
     ]
    }
   ],
   "source": [
    "extract_fasta_from_coords(coords, chr1, chr2, chr3, chr4, chr5, chr6, chr7, chrUn, f_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 891,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">chr1:146750:146980:ID=HORVU.MOREX.r3.1HG0000070.1\r\n",
      "TACGTACTCACTCGTGTCCTCCTCGGATGCGCTACTCTGCCTCTGCTCAAGCCTAGCTCCAAATCGGAGATCAGATCGGATCGGACCAGATCTTGTTTTCTTTCTTTCTTTCTTCTTCAAGATCCCGATCCCCGCCACCCTAAACACACCACACCACACCACGCGTCGCCGACGAATTCGTCCCAAGACTTGTCCACACGGAAATCCATCGGTTTGTTCTGCTTCTTCAG\r\n",
      ">chr1:153530:153625:ID=HORVU.MOREX.r3.1HG0000080.1\r\n",
      "TACCTACCACTTCACTTCAGTTCAACCTGATGCTGAATGTGAATTCAGTCCACACTCACACTCACTAATTCAGTTCAAACTGATGTTTTTTGCAG\r\n",
      ">chr1:1614154:1615780:ID=HORVU.MOREX.r3.1HG0000620.1\r\n",
      "GTGAGCGCCGCACTCCTCCCCCGATTCGCGCCTCGTCCCTGCCTTGAAGCCAAGATCAGTTTTTTATTTACTTGCTTGGCATAAGCAACTTCCCCCTCTCCTCTCCTCTCTTGCGTGCGGCCGCGGGTTGCTTGCAGTGCGGGGGAAGGAGGATGGAGAGGAAGGAGAAGTGGTGGGATGGGGATGTGGATTTCTTTGTTTGTTTGCTTGCTTTCTGCAGTGAAGGTCGGGATTGGAATCGCGGCCGCGGCGCTGGCTTTGCCTTGCTCCTCAGCTTATGCTTCTCCCTCTTCCTTCCCTTCCGCCGGGGGAGAAGCAACCGGCACGGCTGCTCTCCCCTCCCCTGCTTAGCCGCCTATTTCAACCCAGTTCATGGCCTAGTCACCACCACCACAACACAAGCTGCTGCTGCTGCTGCTGCTCCCACATTACTCCTCCACCAACCCCCACAAACCCTAGCTTCTTCTTCCTCCTCCTCTGCTCCCTCTTCTTCTTGTTCTTGCTGCTGCTGGTGAGTCGCTGCTCTCAACCGATCTCCCCCTCCCCCTCCCCCAACCCGTCGCTTTCGCTTCGATTGCCCCCCAAATGCAGCCCCCTCTCTTCCAATTCCACTCCGCAGCGAGCAAAGGGTGGGGTTCGATTTGTTCCTCTTCTTGGTCGAGCTTCCTTCCCCTCCTCCGTTTTCGATCTGCGGTTTCCGCCAGTACTATTATTCTACTACTTACCCTCCGCCTCTGGCCACGGGCATAGATTTGGGCTCCCATCCTCTTCTACTTACTACAGTACCACTCAATGGGTCATGGCCTCGCACCGCCGCTTAATCAAATCCCACACACACACGCGGCTTCCCCAATAAATTACTCTCCTTGTTGTTGATGCAGTACTACTACTACTGGTTGCATAATAAAATAGGCCCGTCGAGTTCCAACAACAAGATCGACAGATTGTCTGGCGTCCTTATCTTGTTTCTACCCCCTGAAAGCCCTAGAAAGCACCCAGCTTTTCCATTTTACTATCATCCTTCTTATTATCATACCATTGTTCCGGGAGGAACAGCTTTAGATTTATTTTTTCCCGGTCCGCACCGCCCCGCCCTCCTCCGCTGACCAACTTTTTCGGTCGTCTCCTTCTCCTTCTTCTTCCCCTTCCCCACCGCACCATTCCGACGGGCCTTTTCCTCCCCGGAATCCATCCGGCCAGAAACGGAAGTGGGCTCCCATTTCTTGAGGGGGGAGCCGTTTCATCCCCTTCTGCCTCCCTCGGCACCCTTCCCATCCGTGAGATTCTCCTGCCCGTTTTTCCGTTGGAAAAAAAAACCCTGCTAGGCCACGGCGTTGCAATGCTTCCTAAAATTAGCACGTAATCTATCAGGGGGGGTTTCACCTTAAATCAGGGTTTATTGAATTTTACTTTTGTTATTGTTAGCGCATTGCGTTTGTTTGCCCATCTCATCGAATTTAGGGGGCGGCACGCATGCGTGCGGTTGCTGGGGCACTAGGGCTTTCTGTTTCGGGCCGGCGACGTCCCGGGACAGCAAGGCAGTTGCATTATCTGCTTGTTTGTTTGGTTGGTTCTTTCTTTCTTTCACCTTGTTGTCCAGTAATTGAATTGATTCTTGACCTGGCAGG\r\n",
      ">chr1:1614154:1615780:ID=HORVU.MOREX.r3.1HG0000620.2\r\n",
      "GTGAGCGCCGCACTCCTCCCCCGATTCGCGCCTCGTCCCTGCCTTGAAGCCAAGATCAGTTTTTTATTTACTTGCTTGGCATAAGCAACTTCCCCCTCTCCTCTCCTCTCTTGCGTGCGGCCGCGGGTTGCTTGCAGTGCGGGGGAAGGAGGATGGAGAGGAAGGAGAAGTGGTGGGATGGGGATGTGGATTTCTTTGTTTGTTTGCTTGCTTTCTGCAGTGAAGGTCGGGATTGGAATCGCGGCCGCGGCGCTGGCTTTGCCTTGCTCCTCAGCTTATGCTTCTCCCTCTTCCTTCCCTTCCGCCGGGGGAGAAGCAACCGGCACGGCTGCTCTCCCCTCCCCTGCTTAGCCGCCTATTTCAACCCAGTTCATGGCCTAGTCACCACCACCACAACACAAGCTGCTGCTGCTGCTGCTGCTCCCACATTACTCCTCCACCAACCCCCACAAACCCTAGCTTCTTCTTCCTCCTCCTCTGCTCCCTCTTCTTCTTGTTCTTGCTGCTGCTGGTGAGTCGCTGCTCTCAACCGATCTCCCCCTCCCCCTCCCCCAACCCGTCGCTTTCGCTTCGATTGCCCCCCAAATGCAGCCCCCTCTCTTCCAATTCCACTCCGCAGCGAGCAAAGGGTGGGGTTCGATTTGTTCCTCTTCTTGGTCGAGCTTCCTTCCCCTCCTCCGTTTTCGATCTGCGGTTTCCGCCAGTACTATTATTCTACTACTTACCCTCCGCCTCTGGCCACGGGCATAGATTTGGGCTCCCATCCTCTTCTACTTACTACAGTACCACTCAATGGGTCATGGCCTCGCACCGCCGCTTAATCAAATCCCACACACACACGCGGCTTCCCCAATAAATTACTCTCCTTGTTGTTGATGCAGTACTACTACTACTGGTTGCATAATAAAATAGGCCCGTCGAGTTCCAACAACAAGATCGACAGATTGTCTGGCGTCCTTATCTTGTTTCTACCCCCTGAAAGCCCTAGAAAGCACCCAGCTTTTCCATTTTACTATCATCCTTCTTATTATCATACCATTGTTCCGGGAGGAACAGCTTTAGATTTATTTTTTCCCGGTCCGCACCGCCCCGCCCTCCTCCGCTGACCAACTTTTTCGGTCGTCTCCTTCTCCTTCTTCTTCCCCTTCCCCACCGCACCATTCCGACGGGCCTTTTCCTCCCCGGAATCCATCCGGCCAGAAACGGAAGTGGGCTCCCATTTCTTGAGGGGGGAGCCGTTTCATCCCCTTCTGCCTCCCTCGGCACCCTTCCCATCCGTGAGATTCTCCTGCCCGTTTTTCCGTTGGAAAAAAAAACCCTGCTAGGCCACGGCGTTGCAATGCTTCCTAAAATTAGCACGTAATCTATCAGGGGGGGTTTCACCTTAAATCAGGGTTTATTGAATTTTACTTTTGTTATTGTTAGCGCATTGCGTTTGTTTGCCCATCTCATCGAATTTAGGGGGCGGCACGCATGCGTGCGGTTGCTGGGGCACTAGGGCTTTCTGTTTCGGGCCGGCGACGTCCCGGGACAGCAAGGCAGTTGCATTATCTGCTTGTTTGTTTGGTTGGTTCTTTCTTTCTTTCACCTTGTTGTCCAGTAATTGAATTGATTCTTGACCTGGCAGG\r\n",
      ">chr1:1614665:1615780:ID=HORVU.MOREX.r3.1HG0000620.3\r\n",
      "GTGAGTCGCTGCTCTCAACCGATCTCCCCCTCCCCCTCCCCCAACCCGTCGCTTTCGCTTCGATTGCCCCCCAAATGCAGCCCCCTCTCTTCCAATTCCACTCCGCAGCGAGCAAAGGGTGGGGTTCGATTTGTTCCTCTTCTTGGTCGAGCTTCCTTCCCCTCCTCCGTTTTCGATCTGCGGTTTCCGCCAGTACTATTATTCTACTACTTACCCTCCGCCTCTGGCCACGGGCATAGATTTGGGCTCCCATCCTCTTCTACTTACTACAGTACCACTCAATGGGTCATGGCCTCGCACCGCCGCTTAATCAAATCCCACACACACACGCGGCTTCCCCAATAAATTACTCTCCTTGTTGTTGATGCAGTACTACTACTACTGGTTGCATAATAAAATAGGCCCGTCGAGTTCCAACAACAAGATCGACAGATTGTCTGGCGTCCTTATCTTGTTTCTACCCCCTGAAAGCCCTAGAAAGCACCCAGCTTTTCCATTTTACTATCATCCTTCTTATTATCATACCATTGTTCCGGGAGGAACAGCTTTAGATTTATTTTTTCCCGGTCCGCACCGCCCCGCCCTCCTCCGCTGACCAACTTTTTCGGTCGTCTCCTTCTCCTTCTTCTTCCCCTTCCCCACCGCACCATTCCGACGGGCCTTTTCCTCCCCGGAATCCATCCGGCCAGAAACGGAAGTGGGCTCCCATTTCTTGAGGGGGGAGCCGTTTCATCCCCTTCTGCCTCCCTCGGCACCCTTCCCATCCGTGAGATTCTCCTGCCCGTTTTTCCGTTGGAAAAAAAAACCCTGCTAGGCCACGGCGTTGCAATGCTTCCTAAAATTAGCACGTAATCTATCAGGGGGGGTTTCACCTTAAATCAGGGTTTATTGAATTTTACTTTTGTTATTGTTAGCGCATTGCGTTTGTTTGCCCATCTCATCGAATTTAGGGGGCGGCACGCATGCGTGCGGTTGCTGGGGCACTAGGGCTTTCTGTTTCGGGCCGGCGACGTCCCGGGACAGCAAGGCAGTTGCATTATCTGCTTGTTTGTTTGGTTGGTTCTTTCTTTCTTTCACCTTGTTGTCCAGTAATTGAATTGATTCTTGACCTGGCAGG\r\n"
     ]
    }
   ],
   "source": [
    "! head Output/Hv_Morex_longread/Hv_MorexHC_UTR_introns.fasta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 Blasting the extracted sequences toward the 20 genome of the gene_projection directory within the pan-genome study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 892,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is needed to install local BLAST is not already installed\n",
    "# Uncomment the following to make it run\n",
    "\n",
    "# sudo apt-get install ncbi-blast+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 893,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-09-04 15:29:08--  https://doi.ipk-gatersleben.de/DOI/c4d433dc-bf7c-4ad9-9368-69bb77837ca5/ebaa1e2d-e3a0-4353-a23d-399740c503cb/1/DOWNLOAD\n",
      "Resolving doi.ipk-gatersleben.de (doi.ipk-gatersleben.de)... 194.94.136.144\n",
      "Connecting to doi.ipk-gatersleben.de (doi.ipk-gatersleben.de)|194.94.136.144|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 48684804 (46M) [text/plain]\n",
      "Saving to: ‘Data/Akashinriki/Akarashinriki.cds.fasta’\n",
      "\n",
      "Data/Akashinriki/Ak 100%[===================>]  46,43M  1,11MB/s    in 44s     \n",
      "\n",
      "2021-09-04 15:29:53 (1,06 MB/s) - ‘Data/Akashinriki/Akarashinriki.cds.fasta’ saved [48684804/48684804]\n",
      "\n",
      "--2021-09-04 15:29:53--  https://doi.ipk-gatersleben.de/DOI/c4d433dc-bf7c-4ad9-9368-69bb77837ca5/e8736e9b-893f-4bd0-8e82-f46975819d97/1/DOWNLOAD\n",
      "Resolving doi.ipk-gatersleben.de (doi.ipk-gatersleben.de)... 194.94.136.144\n",
      "Connecting to doi.ipk-gatersleben.de (doi.ipk-gatersleben.de)|194.94.136.144|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 49088436 (47M) [text/plain]\n",
      "Saving to: ‘Data/B1K/B1K.cds.fasta’\n",
      "\n",
      "Data/B1K/B1K.cds.fa 100%[===================>]  46,81M  1,24MB/s    in 41s     \n",
      "\n",
      "2021-09-04 15:30:34 (1,14 MB/s) - ‘Data/B1K/B1K.cds.fasta’ saved [49088436/49088436]\n",
      "\n",
      "--2021-09-04 15:30:35--  https://doi.ipk-gatersleben.de/DOI/c4d433dc-bf7c-4ad9-9368-69bb77837ca5/dc5b1041-4d3a-4324-9252-e6ce2aab2854/1/DOWNLOAD\n",
      "Resolving doi.ipk-gatersleben.de (doi.ipk-gatersleben.de)... 194.94.136.144\n",
      "Connecting to doi.ipk-gatersleben.de (doi.ipk-gatersleben.de)|194.94.136.144|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 50910962 (49M) [text/plain]\n",
      "Saving to: ‘Data/Barke_gp/Barke_gp.cds.fasta’\n",
      "\n",
      "Data/Barke_gp/Barke 100%[===================>]  48,55M  1,22MB/s    in 45s     \n",
      "\n",
      "2021-09-04 15:31:20 (1,08 MB/s) - ‘Data/Barke_gp/Barke_gp.cds.fasta’ saved [50910962/50910962]\n",
      "\n",
      "--2021-09-04 15:31:20--  https://doi.ipk-gatersleben.de/DOI/c4d433dc-bf7c-4ad9-9368-69bb77837ca5/7e11b599-d142-4eb4-bac0-20aec793a95f/1/DOWNLOAD\n",
      "Resolving doi.ipk-gatersleben.de (doi.ipk-gatersleben.de)... 194.94.136.144\n",
      "Connecting to doi.ipk-gatersleben.de (doi.ipk-gatersleben.de)|194.94.136.144|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 46880132 (45M) [text/plain]\n",
      "Saving to: ‘Data/Golden_Promise/Golden_Promise.cds.fasta’\n",
      "\n",
      "Data/Golden_Promise 100%[===================>]  44,71M  1,02MB/s    in 40s     \n",
      "\n",
      "2021-09-04 15:32:00 (1,13 MB/s) - ‘Data/Golden_Promise/Golden_Promise.cds.fasta’ saved [46880132/46880132]\n",
      "\n",
      "--2021-09-04 15:32:00--  https://doi.ipk-gatersleben.de/DOI/c4d433dc-bf7c-4ad9-9368-69bb77837ca5/9f1e0fb5-ea24-431c-9888-c777c53b9e36/1/DOWNLOAD\n",
      "Resolving doi.ipk-gatersleben.de (doi.ipk-gatersleben.de)... 194.94.136.144\n",
      "Connecting to doi.ipk-gatersleben.de (doi.ipk-gatersleben.de)|194.94.136.144|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 51478673 (49M) [text/plain]\n",
      "Saving to: ‘Data/Hockett/Hockett.cds.fasta’\n",
      "\n",
      "Data/Hockett/Hocket 100%[===================>]  49,09M  1,16MB/s    in 42s     \n",
      "\n",
      "2021-09-04 15:32:42 (1,17 MB/s) - ‘Data/Hockett/Hockett.cds.fasta’ saved [51478673/51478673]\n",
      "\n",
      "--2021-09-04 15:32:43--  https://doi.ipk-gatersleben.de/DOI/c4d433dc-bf7c-4ad9-9368-69bb77837ca5/9584516c-393d-482b-a9f8-b8c81932cf7c/1/DOWNLOAD\n",
      "Resolving doi.ipk-gatersleben.de (doi.ipk-gatersleben.de)... 194.94.136.144\n",
      "Connecting to doi.ipk-gatersleben.de (doi.ipk-gatersleben.de)|194.94.136.144|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 50679637 (48M) [text/plain]\n",
      "Saving to: ‘Data/HOR10350_gp/HOR10350_gp.cds.fasta’\n",
      "\n",
      "Data/HOR10350_gp/HO 100%[===================>]  48,33M  1,28MB/s    in 42s     \n",
      "\n",
      "2021-09-04 15:33:25 (1,14 MB/s) - ‘Data/HOR10350_gp/HOR10350_gp.cds.fasta’ saved [50679637/50679637]\n",
      "\n",
      "--2021-09-04 15:33:26--  https://doi.ipk-gatersleben.de/DOI/c4d433dc-bf7c-4ad9-9368-69bb77837ca5/cbe49c93-fd2b-4e3a-94ff-eb65e87c9c2e/1/DOWNLOAD\n",
      "Resolving doi.ipk-gatersleben.de (doi.ipk-gatersleben.de)... 194.94.136.144\n",
      "Connecting to doi.ipk-gatersleben.de (doi.ipk-gatersleben.de)|194.94.136.144|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 49185933 (47M) [text/plain]\n",
      "Saving to: ‘Data/HOR13821/HOR13821.cds.fasta’\n",
      "\n",
      "Data/HOR13821/HOR13 100%[===================>]  46,91M  1,49MB/s    in 44s     \n",
      "\n",
      "2021-09-04 15:34:10 (1,06 MB/s) - ‘Data/HOR13821/HOR13821.cds.fasta’ saved [49185933/49185933]\n",
      "\n",
      "--2021-09-04 15:34:10--  https://doi.ipk-gatersleben.de/DOI/c4d433dc-bf7c-4ad9-9368-69bb77837ca5/953362d2-cb3d-4aa7-bdc6-878c356379ee/1/DOWNLOAD\n",
      "Resolving doi.ipk-gatersleben.de (doi.ipk-gatersleben.de)... 194.94.136.144\n",
      "Connecting to doi.ipk-gatersleben.de (doi.ipk-gatersleben.de)|194.94.136.144|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 48963435 (47M) [text/plain]\n",
      "Saving to: ‘Data/HOR13942/HOR13942.cds.fasta’\n",
      "\n",
      "Data/HOR13942/HOR13 100%[===================>]  46,69M  1,16MB/s    in 52s     \n",
      "\n",
      "2021-09-04 15:35:02 (925 KB/s) - ‘Data/HOR13942/HOR13942.cds.fasta’ saved [48963435/48963435]\n",
      "\n",
      "--2021-09-04 15:35:03--  https://doi.ipk-gatersleben.de/DOI/c4d433dc-bf7c-4ad9-9368-69bb77837ca5/3c8b0f43-a125-4008-8dc2-7c52bedd6bd9/1/DOWNLOAD\n",
      "Resolving doi.ipk-gatersleben.de (doi.ipk-gatersleben.de)... 194.94.136.144\n",
      "Connecting to doi.ipk-gatersleben.de (doi.ipk-gatersleben.de)|194.94.136.144|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 48937610 (47M) [text/plain]\n",
      "Saving to: ‘Data/HOR21599/HOR21599.cds.fasta’\n",
      "\n",
      "Data/HOR21599/HOR21 100%[===================>]  46,67M  1,39MB/s    in 35s     \n",
      "\n",
      "2021-09-04 15:35:38 (1,33 MB/s) - ‘Data/HOR21599/HOR21599.cds.fasta’ saved [48937610/48937610]\n",
      "\n",
      "--2021-09-04 15:35:38--  https://doi.ipk-gatersleben.de/DOI/c4d433dc-bf7c-4ad9-9368-69bb77837ca5/7ffd1f73-0d68-42ea-b8b4-a1cc3b265303/1/DOWNLOAD\n",
      "Resolving doi.ipk-gatersleben.de (doi.ipk-gatersleben.de)... 194.94.136.144\n",
      "Connecting to doi.ipk-gatersleben.de (doi.ipk-gatersleben.de)|194.94.136.144|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 49641707 (47M) [text/plain]\n",
      "Saving to: ‘Data/HOR3081/HOR3081.cds.fasta’\n",
      "\n",
      "Data/HOR3081/HOR308 100%[===================>]  47,34M  1,43MB/s    in 36s     \n",
      "\n",
      "2021-09-04 15:36:15 (1,30 MB/s) - ‘Data/HOR3081/HOR3081.cds.fasta’ saved [49641707/49641707]\n",
      "\n",
      "--2021-09-04 15:36:15--  https://doi.ipk-gatersleben.de/DOI/c4d433dc-bf7c-4ad9-9368-69bb77837ca5/49cf0f92-692c-4c72-b6d7-933a74d1b9d2/1/DOWNLOAD\n",
      "Resolving doi.ipk-gatersleben.de (doi.ipk-gatersleben.de)... 194.94.136.144\n",
      "Connecting to doi.ipk-gatersleben.de (doi.ipk-gatersleben.de)|194.94.136.144|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 50123547 (48M) [text/plain]\n",
      "Saving to: ‘Data/HOR3365/HOR3365.cds.fasta’\n",
      "\n",
      "Data/HOR3365/HOR336 100%[===================>]  47,80M  1,49MB/s    in 31s     \n",
      "\n",
      "2021-09-04 15:36:46 (1,54 MB/s) - ‘Data/HOR3365/HOR3365.cds.fasta’ saved [50123547/50123547]\n",
      "\n",
      "--2021-09-04 15:36:47--  https://doi.ipk-gatersleben.de/DOI/c4d433dc-bf7c-4ad9-9368-69bb77837ca5/473af275-bc69-476f-9d89-320261caa9cf/1/DOWNLOAD\n",
      "Resolving doi.ipk-gatersleben.de (doi.ipk-gatersleben.de)... 194.94.136.144\n",
      "Connecting to doi.ipk-gatersleben.de (doi.ipk-gatersleben.de)|194.94.136.144|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 49027494 (47M) [text/plain]\n",
      "Saving to: ‘Data/HOR7552/HOR7552.cds.fasta’\n",
      "\n",
      "Data/HOR7552/HOR755 100%[===================>]  46,76M  1,09MB/s    in 39s     \n",
      "\n",
      "2021-09-04 15:37:26 (1,21 MB/s) - ‘Data/HOR7552/HOR7552.cds.fasta’ saved [49027494/49027494]\n",
      "\n",
      "--2021-09-04 15:37:26--  https://doi.ipk-gatersleben.de/DOI/c4d433dc-bf7c-4ad9-9368-69bb77837ca5/f7358a73-1a6e-4c3b-9a25-73651ea486bc/1/DOWNLOAD\n",
      "Resolving doi.ipk-gatersleben.de (doi.ipk-gatersleben.de)... 194.94.136.144\n",
      "Connecting to doi.ipk-gatersleben.de (doi.ipk-gatersleben.de)|194.94.136.144|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 49364097 (47M) [text/plain]\n",
      "Saving to: ‘Data/HOR8148/HOR8148.cds.fasta’\n",
      "\n",
      "Data/HOR8148/HOR814 100%[===================>]  47,08M  1,16MB/s    in 42s     \n",
      "\n",
      "2021-09-04 15:38:08 (1,12 MB/s) - ‘Data/HOR8148/HOR8148.cds.fasta’ saved [49364097/49364097]\n",
      "\n",
      "--2021-09-04 15:38:08--  https://doi.ipk-gatersleben.de/DOI/c4d433dc-bf7c-4ad9-9368-69bb77837ca5/32caa1cd-19ee-416c-8fcc-c3a78f18f89b/1/DOWNLOAD\n",
      "Resolving doi.ipk-gatersleben.de (doi.ipk-gatersleben.de)... 194.94.136.144\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to doi.ipk-gatersleben.de (doi.ipk-gatersleben.de)|194.94.136.144|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 49403158 (47M) [text/plain]\n",
      "Saving to: ‘Data/HOR9043/HOR9043.cds.fasta’\n",
      "\n",
      "Data/HOR9043/HOR904 100%[===================>]  47,11M  1,19MB/s    in 48s     \n",
      "\n",
      "2021-09-04 15:38:56 (1014 KB/s) - ‘Data/HOR9043/HOR9043.cds.fasta’ saved [49403158/49403158]\n",
      "\n",
      "--2021-09-04 15:38:56--  https://doi.ipk-gatersleben.de/DOI/c4d433dc-bf7c-4ad9-9368-69bb77837ca5/af253083-ebd3-459a-9fe8-b1257ccc7aab/1/DOWNLOAD\n",
      "Resolving doi.ipk-gatersleben.de (doi.ipk-gatersleben.de)... 194.94.136.144\n",
      "Connecting to doi.ipk-gatersleben.de (doi.ipk-gatersleben.de)|194.94.136.144|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 49687390 (47M) [text/plain]\n",
      "Saving to: ‘Data/Igri/Igri.cds.fasta’\n",
      "\n",
      "Data/Igri/Igri.cds. 100%[===================>]  47,38M  1,47MB/s    in 31s     \n",
      "\n",
      "2021-09-04 15:39:28 (1,52 MB/s) - ‘Data/Igri/Igri.cds.fasta’ saved [49687390/49687390]\n",
      "\n",
      "--2021-09-04 15:39:28--  https://doi.ipk-gatersleben.de/DOI/c4d433dc-bf7c-4ad9-9368-69bb77837ca5/fad42b36-9503-462b-9b39-fe6c431c5caa/1/DOWNLOAD\n",
      "Resolving doi.ipk-gatersleben.de (doi.ipk-gatersleben.de)... 194.94.136.144\n",
      "Connecting to doi.ipk-gatersleben.de (doi.ipk-gatersleben.de)|194.94.136.144|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 50933261 (49M) [text/plain]\n",
      "Saving to: ‘Data/Morex_gp/Morex_gp.cds.fasta’\n",
      "\n",
      "Data/Morex_gp/Morex 100%[===================>]  48,57M  1,21MB/s    in 33s     \n",
      "\n",
      "2021-09-04 15:40:01 (1,48 MB/s) - ‘Data/Morex_gp/Morex_gp.cds.fasta’ saved [50933261/50933261]\n",
      "\n",
      "--2021-09-04 15:40:01--  https://doi.ipk-gatersleben.de/DOI/c4d433dc-bf7c-4ad9-9368-69bb77837ca5/6e097aae-16b4-4f9d-a02f-8f4c96b9f85e/1/DOWNLOAD\n",
      "Resolving doi.ipk-gatersleben.de (doi.ipk-gatersleben.de)... 194.94.136.144\n",
      "Connecting to doi.ipk-gatersleben.de (doi.ipk-gatersleben.de)|194.94.136.144|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 49133906 (47M) [text/plain]\n",
      "Saving to: ‘Data/OUN333/OUN333.cds.fasta’\n",
      "\n",
      "Data/OUN333/OUN333. 100%[===================>]  46,86M  1,30MB/s    in 38s     \n",
      "\n",
      "2021-09-04 15:40:40 (1,23 MB/s) - ‘Data/OUN333/OUN333.cds.fasta’ saved [49133906/49133906]\n",
      "\n",
      "--2021-09-04 15:40:40--  https://doi.ipk-gatersleben.de/DOI/c4d433dc-bf7c-4ad9-9368-69bb77837ca5/c7f4868c-15c7-4435-8cf0-4341b7aad14b/1/DOWNLOAD\n",
      "Resolving doi.ipk-gatersleben.de (doi.ipk-gatersleben.de)... 194.94.136.144\n",
      "Connecting to doi.ipk-gatersleben.de (doi.ipk-gatersleben.de)|194.94.136.144|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 49940386 (48M) [text/plain]\n",
      "Saving to: ‘Data/RGT_Planet/RGT_Planet.cds.fasta’\n",
      "\n",
      "Data/RGT_Planet/RGT 100%[===================>]  47,63M  1,75MB/s    in 50s     \n",
      "\n",
      "2021-09-04 15:41:31 (967 KB/s) - ‘Data/RGT_Planet/RGT_Planet.cds.fasta’ saved [49940386/49940386]\n",
      "\n",
      "--2021-09-04 15:41:31--  https://doi.ipk-gatersleben.de/DOI/c4d433dc-bf7c-4ad9-9368-69bb77837ca5/97c4fcfc-8510-4ac1-a879-668927c0f566/1/DOWNLOAD\n",
      "Resolving doi.ipk-gatersleben.de (doi.ipk-gatersleben.de)... 194.94.136.144\n",
      "Connecting to doi.ipk-gatersleben.de (doi.ipk-gatersleben.de)|194.94.136.144|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 48923002 (47M) [text/plain]\n",
      "Saving to: ‘Data/ZDM01467/ZDM01467.cds.fasta’\n",
      "\n",
      "Data/ZDM01467/ZDM01 100%[===================>]  46,66M  1,43MB/s    in 32s     \n",
      "\n",
      "2021-09-04 15:42:03 (1,48 MB/s) - ‘Data/ZDM01467/ZDM01467.cds.fasta’ saved [48923002/48923002]\n",
      "\n",
      "--2021-09-04 15:42:03--  https://doi.ipk-gatersleben.de/DOI/c4d433dc-bf7c-4ad9-9368-69bb77837ca5/c28021d8-dc64-4127-ab48-d259583cbbc5/1/DOWNLOAD\n",
      "Resolving doi.ipk-gatersleben.de (doi.ipk-gatersleben.de)... 194.94.136.144\n",
      "Connecting to doi.ipk-gatersleben.de (doi.ipk-gatersleben.de)|194.94.136.144|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 49606219 (47M) [text/plain]\n",
      "Saving to: ‘Data/ZDM02064/ZDM02064.cds.fasta’\n",
      "\n",
      "Data/ZDM02064/ZDM02 100%[===================>]  47,31M   873KB/s    in 44s     \n",
      "\n",
      "2021-09-04 15:42:47 (1,08 MB/s) - ‘Data/ZDM02064/ZDM02064.cds.fasta’ saved [49606219/49606219]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### --- Downloading cds.fasta of the 20 genome of the pangenome study contained in the gene_projection directory\n",
    "! wget -O Data/Akashinriki/Akashinriki.cds.fasta https://doi.ipk-gatersleben.de/DOI/c4d433dc-bf7c-4ad9-9368-69bb77837ca5/ebaa1e2d-e3a0-4353-a23d-399740c503cb/1/DOWNLOAD\n",
    "! wget -O Data/B1K/B1K.cds.fasta https://doi.ipk-gatersleben.de/DOI/c4d433dc-bf7c-4ad9-9368-69bb77837ca5/e8736e9b-893f-4bd0-8e82-f46975819d97/1/DOWNLOAD\n",
    "! wget -O Data/Barke_gp/Barke_gp.cds.fasta https://doi.ipk-gatersleben.de/DOI/c4d433dc-bf7c-4ad9-9368-69bb77837ca5/dc5b1041-4d3a-4324-9252-e6ce2aab2854/1/DOWNLOAD\n",
    "! wget -O Data/Golden_Promise/Golden_Promise.cds.fasta https://doi.ipk-gatersleben.de/DOI/c4d433dc-bf7c-4ad9-9368-69bb77837ca5/7e11b599-d142-4eb4-bac0-20aec793a95f/1/DOWNLOAD\n",
    "! wget -O Data/Hockett/Hockett.cds.fasta https://doi.ipk-gatersleben.de/DOI/c4d433dc-bf7c-4ad9-9368-69bb77837ca5/9f1e0fb5-ea24-431c-9888-c777c53b9e36/1/DOWNLOAD\n",
    "! wget -O Data/HOR10350_gp/HOR10350_gp.cds.fasta https://doi.ipk-gatersleben.de/DOI/c4d433dc-bf7c-4ad9-9368-69bb77837ca5/9584516c-393d-482b-a9f8-b8c81932cf7c/1/DOWNLOAD\n",
    "! wget -O Data/HOR13821/HOR13821.cds.fasta https://doi.ipk-gatersleben.de/DOI/c4d433dc-bf7c-4ad9-9368-69bb77837ca5/cbe49c93-fd2b-4e3a-94ff-eb65e87c9c2e/1/DOWNLOAD\n",
    "! wget -O Data/HOR13942/HOR13942.cds.fasta https://doi.ipk-gatersleben.de/DOI/c4d433dc-bf7c-4ad9-9368-69bb77837ca5/953362d2-cb3d-4aa7-bdc6-878c356379ee/1/DOWNLOAD\n",
    "! wget -O Data/HOR21599/HOR21599.cds.fasta https://doi.ipk-gatersleben.de/DOI/c4d433dc-bf7c-4ad9-9368-69bb77837ca5/3c8b0f43-a125-4008-8dc2-7c52bedd6bd9/1/DOWNLOAD\n",
    "! wget -O Data/HOR3081/HOR3081.cds.fasta https://doi.ipk-gatersleben.de/DOI/c4d433dc-bf7c-4ad9-9368-69bb77837ca5/7ffd1f73-0d68-42ea-b8b4-a1cc3b265303/1/DOWNLOAD\n",
    "! wget -O Data/HOR3365/HOR3365.cds.fasta https://doi.ipk-gatersleben.de/DOI/c4d433dc-bf7c-4ad9-9368-69bb77837ca5/49cf0f92-692c-4c72-b6d7-933a74d1b9d2/1/DOWNLOAD\n",
    "! wget -O Data/HOR7552/HOR7552.cds.fasta https://doi.ipk-gatersleben.de/DOI/c4d433dc-bf7c-4ad9-9368-69bb77837ca5/473af275-bc69-476f-9d89-320261caa9cf/1/DOWNLOAD\n",
    "! wget -O Data/HOR8148/HOR8148.cds.fasta https://doi.ipk-gatersleben.de/DOI/c4d433dc-bf7c-4ad9-9368-69bb77837ca5/f7358a73-1a6e-4c3b-9a25-73651ea486bc/1/DOWNLOAD\n",
    "! wget -O Data/HOR9043/HOR9043.cds.fasta https://doi.ipk-gatersleben.de/DOI/c4d433dc-bf7c-4ad9-9368-69bb77837ca5/32caa1cd-19ee-416c-8fcc-c3a78f18f89b/1/DOWNLOAD\n",
    "! wget -O Data/Igri/Igri.cds.fasta https://doi.ipk-gatersleben.de/DOI/c4d433dc-bf7c-4ad9-9368-69bb77837ca5/af253083-ebd3-459a-9fe8-b1257ccc7aab/1/DOWNLOAD\n",
    "! wget -O Data/Morex_gp/Morex_gp.cds.fasta https://doi.ipk-gatersleben.de/DOI/c4d433dc-bf7c-4ad9-9368-69bb77837ca5/fad42b36-9503-462b-9b39-fe6c431c5caa/1/DOWNLOAD\n",
    "! wget -O Data/OUN333/OUN333.cds.fasta https://doi.ipk-gatersleben.de/DOI/c4d433dc-bf7c-4ad9-9368-69bb77837ca5/6e097aae-16b4-4f9d-a02f-8f4c96b9f85e/1/DOWNLOAD\n",
    "! wget -O Data/RGT_Planet/RGT_Planet.cds.fasta https://doi.ipk-gatersleben.de/DOI/c4d433dc-bf7c-4ad9-9368-69bb77837ca5/c7f4868c-15c7-4435-8cf0-4341b7aad14b/1/DOWNLOAD\n",
    "! wget -O Data/ZDM01467/ZDM01467.cds.fasta https://doi.ipk-gatersleben.de/DOI/c4d433dc-bf7c-4ad9-9368-69bb77837ca5/97c4fcfc-8510-4ac1-a879-668927c0f566/1/DOWNLOAD\n",
    "! wget -O Data/ZDM02064/ZDM02064.cds.fasta https://doi.ipk-gatersleben.de/DOI/c4d433dc-bf7c-4ad9-9368-69bb77837ca5/c28021d8-dc64-4127-ab48-d259583cbbc5/1/DOWNLOAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 902,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Building a new DB, current time: 09/04/2021 15:48:00\n",
      "New DB name:   /home/barley/Test/Data/Akashinriki/Akashinriki_db\n",
      "New DB title:  Data/Akashinriki/Akashinriki.cds.fasta\n",
      "Sequence type: Nucleotide\n",
      "Keep MBits: T\n",
      "Maximum file size: 1000000000B\n",
      "Adding sequences from FASTA; added 44446 sequences in 1.53034 seconds.\n",
      "\n",
      "\n",
      "Building a new DB, current time: 09/04/2021 15:48:01\n",
      "New DB name:   /home/barley/Test/Data/B1K/B1K_db\n",
      "New DB title:  Data/B1K/B1K.cds.fasta\n",
      "Sequence type: Nucleotide\n",
      "Deleted existing Nucleotide BLAST database named /home/barley/Test/Data/B1K/B1K_db\n",
      "Keep MBits: T\n",
      "Maximum file size: 1000000000B\n",
      "Adding sequences from FASTA; added 44566 sequences in 1.37258 seconds.\n",
      "\n",
      "\n",
      "Building a new DB, current time: 09/04/2021 15:48:03\n",
      "New DB name:   /home/barley/Test/Data/Barke_gp/Barke_gp_db\n",
      "New DB title:  Data/Barke_gp/Barke_gp.cds.fasta\n",
      "Sequence type: Nucleotide\n",
      "Deleted existing Nucleotide BLAST database named /home/barley/Test/Data/Barke_gp/Barke_gp_db\n",
      "Keep MBits: T\n",
      "Maximum file size: 1000000000B\n",
      "Adding sequences from FASTA; added 45999 sequences in 1.35398 seconds.\n",
      "\n",
      "\n",
      "Building a new DB, current time: 09/04/2021 15:48:05\n",
      "New DB name:   /home/barley/Test/Data/Golden_Promise/Golden_Promise_db\n",
      "New DB title:  Data/Golden_Promise/Golden_Promise.cds.fasta\n",
      "Sequence type: Nucleotide\n",
      "Deleted existing Nucleotide BLAST database named /home/barley/Test/Data/Golden_Promise/Golden_Promise_db\n",
      "Keep MBits: T\n",
      "Maximum file size: 1000000000B\n",
      "Adding sequences from FASTA; added 42464 sequences in 1.40405 seconds.\n",
      "\n",
      "\n",
      "Building a new DB, current time: 09/04/2021 15:48:06\n",
      "New DB name:   /home/barley/Test/Data/Hockett/Hockett_db\n",
      "New DB title:  Data/Hockett/Hockett.cds.fasta\n",
      "Sequence type: Nucleotide\n",
      "Deleted existing Nucleotide BLAST database named /home/barley/Test/Data/Hockett/Hockett_db\n",
      "Keep MBits: T\n",
      "Maximum file size: 1000000000B\n",
      "Adding sequences from FASTA; added 46450 sequences in 1.47993 seconds.\n",
      "\n",
      "\n",
      "Building a new DB, current time: 09/04/2021 15:48:08\n",
      "New DB name:   /home/barley/Test/Data/HOR10350_gp/HOR10350_gp_db\n",
      "New DB title:  Data/HOR10350_gp/HOR10350_gp.cds.fasta\n",
      "Sequence type: Nucleotide\n",
      "Deleted existing Nucleotide BLAST database named /home/barley/Test/Data/HOR10350_gp/HOR10350_gp_db\n",
      "Keep MBits: T\n",
      "Maximum file size: 1000000000B\n",
      "Adding sequences from FASTA; added 45810 sequences in 1.39575 seconds.\n",
      "\n",
      "\n",
      "Building a new DB, current time: 09/04/2021 15:48:10\n",
      "New DB name:   /home/barley/Test/Data/HOR13821/HOR13821_db\n",
      "New DB title:  Data/HOR13821/HOR13821.cds.fasta\n",
      "Sequence type: Nucleotide\n",
      "Deleted existing Nucleotide BLAST database named /home/barley/Test/Data/HOR13821/HOR13821_db\n",
      "Keep MBits: T\n",
      "Maximum file size: 1000000000B\n",
      "Adding sequences from FASTA; added 44714 sequences in 1.48714 seconds.\n",
      "\n",
      "\n",
      "Building a new DB, current time: 09/04/2021 15:48:12\n",
      "New DB name:   /home/barley/Test/Data/HOR13942/HOR13942_db\n",
      "New DB title:  Data/HOR13942/HOR13942.cds.fasta\n",
      "Sequence type: Nucleotide\n",
      "Deleted existing Nucleotide BLAST database named /home/barley/Test/Data/HOR13942/HOR13942_db\n",
      "Keep MBits: T\n",
      "Maximum file size: 1000000000B\n",
      "Adding sequences from FASTA; added 44718 sequences in 1.46269 seconds.\n",
      "\n",
      "\n",
      "Building a new DB, current time: 09/04/2021 15:48:13\n",
      "New DB name:   /home/barley/Test/Data/HOR21599/HOR21599_db\n",
      "New DB title:  Data/HOR21599/HOR21599.cds.fasta\n",
      "Sequence type: Nucleotide\n",
      "Deleted existing Nucleotide BLAST database named /home/barley/Test/Data/HOR21599/HOR21599_db\n",
      "Keep MBits: T\n",
      "Maximum file size: 1000000000B\n",
      "Adding sequences from FASTA; added 44456 sequences in 1.19854 seconds.\n",
      "\n",
      "\n",
      "Building a new DB, current time: 09/04/2021 15:48:15\n",
      "New DB name:   /home/barley/Test/Data/HOR3081/HOR3081_db\n",
      "New DB title:  Data/HOR3081/HOR3081.cds.fasta\n",
      "Sequence type: Nucleotide\n",
      "Deleted existing Nucleotide BLAST database named /home/barley/Test/Data/HOR3081/HOR3081_db\n",
      "Keep MBits: T\n",
      "Maximum file size: 1000000000B\n",
      "Adding sequences from FASTA; added 45146 sequences in 1.28387 seconds.\n",
      "\n",
      "\n",
      "Building a new DB, current time: 09/04/2021 15:48:16\n",
      "New DB name:   /home/barley/Test/Data/HOR3365/HOR3365_db\n",
      "New DB title:  Data/HOR3365/HOR3365.cds.fasta\n",
      "Sequence type: Nucleotide\n",
      "Deleted existing Nucleotide BLAST database named /home/barley/Test/Data/HOR3365/HOR3365_db\n",
      "Keep MBits: T\n",
      "Maximum file size: 1000000000B\n",
      "Adding sequences from FASTA; added 47588 sequences in 1.17326 seconds.\n",
      "\n",
      "\n",
      "Building a new DB, current time: 09/04/2021 15:48:18\n",
      "New DB name:   /home/barley/Test/Data/HOR7552/HOR7552_db\n",
      "New DB title:  Data/HOR7552/HOR7552.cds.fasta\n",
      "Sequence type: Nucleotide\n",
      "Deleted existing Nucleotide BLAST database named /home/barley/Test/Data/HOR7552/HOR7552_db\n",
      "Keep MBits: T\n",
      "Maximum file size: 1000000000B\n",
      "Adding sequences from FASTA; added 44641 sequences in 1.16607 seconds.\n",
      "\n",
      "\n",
      "Building a new DB, current time: 09/04/2021 15:48:19\n",
      "New DB name:   /home/barley/Test/Data/HOR8148/HOR8148_db\n",
      "New DB title:  Data/HOR8148/HOR8148.cds.fasta\n",
      "Sequence type: Nucleotide\n",
      "Deleted existing Nucleotide BLAST database named /home/barley/Test/Data/HOR8148/HOR8148_db\n",
      "Keep MBits: T\n",
      "Maximum file size: 1000000000B\n",
      "Adding sequences from FASTA; added 45026 sequences in 1.27416 seconds.\n",
      "\n",
      "\n",
      "Building a new DB, current time: 09/04/2021 15:48:21\n",
      "New DB name:   /home/barley/Test/Data/HOR9043/HOR9043_db\n",
      "New DB title:  Data/HOR9043/HOR9043.cds.fasta\n",
      "Sequence type: Nucleotide\n",
      "Deleted existing Nucleotide BLAST database named /home/barley/Test/Data/HOR9043/HOR9043_db\n",
      "Keep MBits: T\n",
      "Maximum file size: 1000000000B\n",
      "Adding sequences from FASTA; added 45028 sequences in 1.37326 seconds.\n",
      "\n",
      "\n",
      "Building a new DB, current time: 09/04/2021 15:48:22\n",
      "New DB name:   /home/barley/Test/Data/Igri/Igri_db\n",
      "New DB title:  Data/Igri/Igri.cds.fasta\n",
      "Sequence type: Nucleotide\n",
      "Deleted existing Nucleotide BLAST database named /home/barley/Test/Data/Igri/Igri_db\n",
      "Keep MBits: T\n",
      "Maximum file size: 1000000000B\n",
      "Adding sequences from FASTA; added 45213 sequences in 1.38143 seconds.\n",
      "\n",
      "\n",
      "Building a new DB, current time: 09/04/2021 15:48:24\n",
      "New DB name:   /home/barley/Test/Data/Morex_gp/Morex_gp_db\n",
      "New DB title:  Data/Morex_gp/Morex_gp.cds.fasta\n",
      "Sequence type: Nucleotide\n",
      "Deleted existing Nucleotide BLAST database named /home/barley/Test/Data/Morex_gp/Morex_gp_db\n",
      "Keep MBits: T\n",
      "Maximum file size: 1000000000B\n",
      "Adding sequences from FASTA; added 46294 sequences in 1.30657 seconds.\n",
      "\n",
      "\n",
      "Building a new DB, current time: 09/04/2021 15:48:26\n",
      "New DB name:   /home/barley/Test/Data/OUN333/OUN333_db\n",
      "New DB title:  Data/OUN333/OUN333.cds.fasta\n",
      "Sequence type: Nucleotide\n",
      "Deleted existing Nucleotide BLAST database named /home/barley/Test/Data/OUN333/OUN333_db\n",
      "Keep MBits: T\n",
      "Maximum file size: 1000000000B\n",
      "Adding sequences from FASTA; added 44699 sequences in 1.2774 seconds.\n",
      "\n",
      "\n",
      "Building a new DB, current time: 09/04/2021 15:48:27\n",
      "New DB name:   /home/barley/Test/Data/RGT_Planet/RGT_Planet_db\n",
      "New DB title:  Data/RGT_Planet/RGT_Planet.cds.fasta\n",
      "Sequence type: Nucleotide\n",
      "Deleted existing Nucleotide BLAST database named /home/barley/Test/Data/RGT_Planet/RGT_Planet_db\n",
      "Keep MBits: T\n",
      "Maximum file size: 1000000000B\n",
      "Adding sequences from FASTA; added 45413 sequences in 1.3672 seconds.\n",
      "\n",
      "\n",
      "Building a new DB, current time: 09/04/2021 15:48:29\n",
      "New DB name:   /home/barley/Test/Data/ZDM01467/ZDM01467_db\n",
      "New DB title:  Data/ZDM01467/ZDM01467.cds.fasta\n",
      "Sequence type: Nucleotide\n",
      "Deleted existing Nucleotide BLAST database named /home/barley/Test/Data/ZDM01467/ZDM01467_db\n",
      "Keep MBits: T\n",
      "Maximum file size: 1000000000B\n",
      "Adding sequences from FASTA; added 44746 sequences in 1.4191 seconds.\n",
      "\n",
      "\n",
      "Building a new DB, current time: 09/04/2021 15:48:31\n",
      "New DB name:   /home/barley/Test/Data/ZDM02064/ZDM02064_db\n",
      "New DB title:  Data/ZDM02064/ZDM02064.cds.fasta\n",
      "Sequence type: Nucleotide\n",
      "Deleted existing Nucleotide BLAST database named /home/barley/Test/Data/ZDM02064/ZDM02064_db\n",
      "Keep MBits: T\n",
      "Maximum file size: 1000000000B\n",
      "Adding sequences from FASTA; added 45050 sequences in 1.536 seconds.\n"
     ]
    }
   ],
   "source": [
    "### --- Making a database for each of the fasta previously downloaded\n",
    "! makeblastdb -in Data/Akashinriki/Akashinriki.cds.fasta -dbtype nucl -parse_seqids -out Data/Akashinriki/Akashinriki_db\n",
    "! makeblastdb -in Data/B1K/B1K.cds.fasta -dbtype nucl -parse_seqids -out Data/B1K/B1K_db\n",
    "! makeblastdb -in Data/Barke_gp/Barke_gp.cds.fasta -dbtype nucl -parse_seqids -out Data/Barke_gp/Barke_gp_db\n",
    "! makeblastdb -in Data/Golden_Promise/Golden_Promise.cds.fasta -dbtype nucl -parse_seqids -out Data/Golden_Promise/Golden_Promise_db\n",
    "! makeblastdb -in Data/Hockett/Hockett.cds.fasta -dbtype nucl -parse_seqids -out Data/Hockett/Hockett_db\n",
    "! makeblastdb -in Data/HOR10350_gp/HOR10350_gp.cds.fasta -dbtype nucl -parse_seqids -out Data/HOR10350_gp/HOR10350_gp_db\n",
    "! makeblastdb -in Data/HOR13821/HOR13821.cds.fasta -dbtype nucl -parse_seqids -out Data/HOR13821/HOR13821_db\n",
    "! makeblastdb -in Data/HOR13942/HOR13942.cds.fasta -dbtype nucl -parse_seqids -out Data/HOR13942/HOR13942_db\n",
    "! makeblastdb -in Data/HOR21599/HOR21599.cds.fasta -dbtype nucl -parse_seqids -out Data/HOR21599/HOR21599_db\n",
    "! makeblastdb -in Data/HOR3081/HOR3081.cds.fasta -dbtype nucl -parse_seqids -out Data/HOR3081/HOR3081_db\n",
    "! makeblastdb -in Data/HOR3365/HOR3365.cds.fasta -dbtype nucl -parse_seqids -out Data/HOR3365/HOR3365_db\n",
    "! makeblastdb -in Data/HOR7552/HOR7552.cds.fasta -dbtype nucl -parse_seqids -out Data/HOR7552/HOR7552_db\n",
    "! makeblastdb -in Data/HOR8148/HOR8148.cds.fasta -dbtype nucl -parse_seqids -out Data/HOR8148/HOR8148_db\n",
    "! makeblastdb -in Data/HOR9043/HOR9043.cds.fasta -dbtype nucl -parse_seqids -out Data/HOR9043/HOR9043_db\n",
    "! makeblastdb -in Data/Igri/Igri.cds.fasta -dbtype nucl -parse_seqids -out Data/Igri/Igri_db\n",
    "! makeblastdb -in Data/Morex_gp/Morex_gp.cds.fasta -dbtype nucl -parse_seqids -out Data/Morex_gp/Morex_gp_db\n",
    "! makeblastdb -in Data/OUN333/OUN333.cds.fasta -dbtype nucl -parse_seqids -out Data/OUN333/OUN333_db\n",
    "! makeblastdb -in Data/RGT_Planet/RGT_Planet.cds.fasta -dbtype nucl -parse_seqids -out Data/RGT_Planet/RGT_Planet_db\n",
    "! makeblastdb -in Data/ZDM01467/ZDM01467.cds.fasta -dbtype nucl -parse_seqids -out Data/ZDM01467/ZDM01467_db\n",
    "! makeblastdb -in Data/ZDM02064/ZDM02064.cds.fasta -dbtype nucl -parse_seqids -out Data/ZDM02064/ZDM02064_db\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 904,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Blasting my query towards each of the database previously created\n",
    "### --- Default outfmt values \"6 qseqid sseqid pident length mismatch gapopen qstart qend sstart send evalue bitscore\"\n",
    "### --- https://www.metagenomics.wiki/tools/blast/blastn-output-format-6\n",
    "! blastn -db Data/Akashinriki/Akashinriki_db -query Output/Hv_Morex_longread/Hv_MorexHC_UTR_introns.fasta -outfmt 6 -out Output/Akashinriki/results_Akashinriki.out\n",
    "! blastn -db Data/B1K/B1K_db -query Output/Hv_Morex_longread/Hv_MorexHC_UTR_introns.fasta -outfmt 6 -out Output/B1K/results_B1K.out\n",
    "! blastn -db Data/Barke_gp/Barke_gp_db -query Output/Hv_Morex_longread/Hv_MorexHC_UTR_introns.fasta -outfmt 6 -out Output/Barke_gp/results_Barke_gp.out\n",
    "! blastn -db Data/Golden_Promise/Golden_Promise_db -query Output/Hv_Morex_longread/Hv_MorexHC_UTR_introns.fasta -outfmt 6 -out Output/Golden_Promise/results_Golden_Promise.out\n",
    "! blastn -db Data/Hockett/Hockett_db -query Output/Hv_Morex_longread/Hv_MorexHC_UTR_introns.fasta -outfmt 6 -out Output/Hockett/results_Hockett.out\n",
    "! blastn -db Data/HOR10350_gp/HOR10350_gp_db -query Output/Hv_Morex_longread/Hv_MorexHC_UTR_introns.fasta -outfmt 6 -out Output/HOR10350_gp/results_HOR10350_gp.out\n",
    "! blastn -db Data/HOR13821/HOR13821_db -query Output/Hv_Morex_longread/Hv_MorexHC_UTR_introns.fasta -outfmt 6 -out Output/HOR13821/results_HOR13821.out\n",
    "! blastn -db Data/HOR13942/HOR13942_db -query Output/Hv_Morex_longread/Hv_MorexHC_UTR_introns.fasta -outfmt 6 -out Output/HOR13942/results_HOR13942.out\n",
    "! blastn -db Data/HOR21599/HOR21599_db -query Output/Hv_Morex_longread/Hv_MorexHC_UTR_introns.fasta -outfmt 6 -out Output/HOR21599/results_HOR21599.out\n",
    "! blastn -db Data/HOR3081/HOR3081_db -query Output/Hv_Morex_longread/Hv_MorexHC_UTR_introns.fasta -outfmt 6 -out Output/HOR3081/results_HOR3081.out\n",
    "! blastn -db Data/HOR3365/HOR3365_db -query Output/Hv_Morex_longread/Hv_MorexHC_UTR_introns.fasta -outfmt 6 -out Output/HOR3365/results_HOR3365.out\n",
    "! blastn -db Data/HOR7552/HOR7552_db -query Output/Hv_Morex_longread/Hv_MorexHC_UTR_introns.fasta -outfmt 6 -out Output/HOR7552/results_HOR7552.out\n",
    "! blastn -db Data/HOR8148/HOR8148_db -query Output/Hv_Morex_longread/Hv_MorexHC_UTR_introns.fasta -outfmt 6 -out Output/HOR8148/results_HOR8148.out\n",
    "! blastn -db Data/HOR9043/HOR9043_db -query Output/Hv_Morex_longread/Hv_MorexHC_UTR_introns.fasta -outfmt 6 -out Output/HOR9043/results_HOR9043.out\n",
    "! blastn -db Data/Igri/Igri_db -query Output/Hv_Morex_longread/Hv_MorexHC_UTR_introns.fasta -outfmt 6 -out Output/Igri/results_Igri.out\n",
    "! blastn -db Data/Morex_gp/Morex_gp_db -query Output/Hv_Morex_longread/Hv_MorexHC_UTR_introns.fasta -outfmt 6 -out Output/Morex_gp/results_Morex_gp.out\n",
    "! blastn -db Data/OUN333/OUN333_db -query Output/Hv_Morex_longread/Hv_MorexHC_UTR_introns.fasta -outfmt 6 -out Output/OUN333/results_OUN333.out\n",
    "! blastn -db Data/RGT_Planet/RGT_Planet_db -query Output/Hv_Morex_longread/Hv_MorexHC_UTR_introns.fasta -outfmt 6 -out Output/RGT_Planet/results_RGT_Planet.out\n",
    "! blastn -db Data/ZDM01467/ZDM01467_db -query Output/Hv_Morex_longread/Hv_MorexHC_UTR_introns.fasta -outfmt 6 -out Output/ZDM01467/results_ZDM01467.out\n",
    "! blastn -db Data/ZDM02064/ZDM02064_db -query Output/Hv_Morex_longread/Hv_MorexHC_UTR_introns.fasta -outfmt 6 -out Output/ZDM02064/results_ZDM02064.out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract hits among the 20 genomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 905,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    8492 Output/Golden_Promise/results_Golden_Promise.out\r\n",
      "    9138 Output/Akashinriki/results_Akashinriki.out\r\n",
      "    9329 Output/HOR7552/results_HOR7552.out\r\n",
      "    9351 Output/HOR9043/results_HOR9043.out\r\n",
      "    9390 Output/OUN333/results_OUN333.out\r\n",
      "    9406 Output/HOR13942/results_HOR13942.out\r\n",
      "    9453 Output/HOR21599/results_HOR21599.out\r\n",
      "    9465 Output/HOR8148/results_HOR8148.out\r\n",
      "    9467 Output/ZDM01467/results_ZDM01467.out\r\n",
      "    9515 Output/HOR3365/results_HOR3365.out\r\n",
      "    9674 Output/HOR13821/results_HOR13821.out\r\n",
      "    9826 Output/Morex_gp/results_Morex_gp.out\r\n",
      "    9874 Output/RGT_Planet/results_RGT_Planet.out\r\n",
      "    9899 Output/HOR3081/results_HOR3081.out\r\n",
      "    9986 Output/Igri/results_Igri.out\r\n",
      "   10313 Output/Hockett/results_Hockett.out\r\n",
      "   10315 Output/ZDM02064/results_ZDM02064.out\r\n",
      "   10525 Output/HOR10350_gp/results_HOR10350_gp.out\r\n",
      "   10542 Output/B1K/results_B1K.out\r\n",
      "   10809 Output/Barke_gp/results_Barke_gp.out\r\n",
      "  194769 total\r\n"
     ]
    }
   ],
   "source": [
    "### --- Checking how many hits are within every blastn result\n",
    "! wc -l Output/*/results_*.out | sort -g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 906,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- This function is meant to extract the query seq-id giving hits\n",
    "def extract_blast_hits(blast_out):\n",
    "    hits = []\n",
    "    with open(blast_out) as f:\n",
    "        for line in f:\n",
    "            line = line.split()\n",
    "            hit = line[0].split(':')[3] # Extracting the Hv_MorexHC ID\n",
    "            if hit in hits: continue\n",
    "            hits.append(hit)\n",
    "    return hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 907,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Output/Akashinriki/results_Akashinriki.out',\n",
       " 'Output/B1K/results_B1K.out',\n",
       " 'Output/Barke_gp/results_Barke_gp.out',\n",
       " 'Output/Golden_Promise/results_Golden_Promise.out',\n",
       " 'Output/Hockett/results_Hockett.out',\n",
       " 'Output/HOR10350_gp/results_HOR10350_gp.out',\n",
       " 'Output/HOR13821/results_HOR13821.out',\n",
       " 'Output/HOR13942/results_HOR13942.out',\n",
       " 'Output/HOR21599/results_HOR21599.out',\n",
       " 'Output/HOR3081/results_HOR3081.out',\n",
       " 'Output/HOR3365/results_HOR3365.out',\n",
       " 'Output/HOR7552/results_HOR7552.out',\n",
       " 'Output/HOR8148/results_HOR8148.out',\n",
       " 'Output/HOR9043/results_HOR9043.out',\n",
       " 'Output/Igri/results_Igri.out',\n",
       " 'Output/Morex_gp/results_Morex_gp.out',\n",
       " 'Output/OUN333/results_OUN333.out',\n",
       " 'Output/RGT_Planet/results_RGT_Planet.out',\n",
       " 'Output/ZDM01467/results_ZDM01467.out',\n",
       " 'Output/ZDM02064/results_ZDM02064.out']"
      ]
     },
     "execution_count": 907,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blast_out_list = ! ls Output/*/results_*.out \n",
    "blast_out_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 908,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### --- This is meant to run the function extract_blast_hits on all the genomes and create 20 variables storing the list of unique IDs\n",
    "### --- Furthemore I convert the list to a set\n",
    "for x in (blast_out_list):\n",
    "    globals()['hits_%s' % x.split('/')[1]] = extract_blast_hits(x)\n",
    "    globals()['hits_%s' % x.split('/')[1]] = set(globals()['hits_%s' % x.split('/')[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 909,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set does not allow duplicates, all duplicates converting a list to a set will be removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 910,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Using sets I can use the intersection function already implented saving only elements common to all sets taken under examination\n",
    "common_hits = hits_Akashinriki.intersection(hits_B1K,hits_Barke_gp, hits_Golden_Promise,hits_Hockett, hits_HOR10350_gp, hits_HOR13821, hits_HOR13942, hits_HOR21599, hits_HOR3081, hits_HOR3365, hits_HOR7552, hits_HOR8148, hits_HOR9043, hits_Igri, hits_Morex_gp, hits_OUN333, hits_RGT_Planet, hits_ZDM01467, hits_ZDM02064)\n",
    "pd.DataFrame(common_hits).rename(columns = {0: 'ID'}).to_csv('Output/common_blast_hits.txt', index = False, header = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 911,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "246\r\n"
     ]
    }
   ],
   "source": [
    "! cat Output/common_blast_hits.txt | sort -u | wc -l"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
